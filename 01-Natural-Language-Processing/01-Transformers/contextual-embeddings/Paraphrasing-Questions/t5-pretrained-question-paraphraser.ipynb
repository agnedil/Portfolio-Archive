{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARAPHRASING QUESTIONS\n",
    "Source: https://towardsdatascience.com/paraphrase-any-question-with-t5-text-to-text-transfer-transformer-pretrained-model-and-cbb9e35f1555\n",
    "\n",
    "1) Use a pre-trained model from the article to generate paraphrased questions for any given question  \n",
    "2) Use my training code and dataset to replicate the results on your own GPU machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==1.4.0\n",
    "!pip install transformers==2.9.0\n",
    "!pip install pytorch_lightning==0.7.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download pretrained paraphrasing model from S3 and unzip in current directory\n",
    "import zipfile\n",
    "import requests, zipfile, io\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "zip_file_url = \"https://datascience-models-ramsri.s3.amazonaws.com/t5_paraphraser.zip\"\n",
    "folder_path = zip_file_url.split(\"/\")[-1].replace(\".zip\",\"\")\n",
    "\n",
    "if not os.path.exists(folder_path):\n",
    "    r = requests.get(zip_file_url)\n",
    "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "    z.extractall('./t5_paraphraser')\n",
    "else:\n",
    "    print (\"Folder available: \",folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device  cpu\n",
      "\n",
      "Original Question ::\n",
      "Which course should I take to get started in data science?\n",
      "\n",
      "\n",
      "Paraphrased Questions :: \n",
      "0: What should I learn to become a data scientist?\n",
      "1: How do I get started with data science?\n",
      "2: How would you start a data science career?\n",
      "3: How can I start learning data science?\n",
      "4: How do you get started in data science?\n",
      "5: What's the best course for data science?\n",
      "6: Which course should I start with for data science?\n",
      "7: What courses should I follow to get started in data science?\n",
      "8: What degree should be taken by a data scientist?\n",
      "9: Which course should I follow to become a Data Scientist?\n"
     ]
    }
   ],
   "source": [
    "# Paraphrase any question\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "  torch.manual_seed(seed)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('./t5_paraphraser')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (\"device \",device)\n",
    "model = model.to(device)\n",
    "\n",
    "sentence = \"Which course should I take to get started in data science?\"\n",
    "# sentence = \"What are the ingredients required to bake a perfect cake?\"\n",
    "# sentence = \"What is the best possible approach to learn aeronautical engineering?\"\n",
    "# sentence = \"Do apples taste better than oranges in general?\"\n",
    "\n",
    "\n",
    "text =  \"paraphrase: \" + sentence + \" </s>\"\n",
    "\n",
    "\n",
    "max_len = 256\n",
    "\n",
    "encoding = tokenizer.encode_plus(text,pad_to_max_length=True, return_tensors=\"pt\")\n",
    "input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "\n",
    "# set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n",
    "beam_outputs = model.generate(\n",
    "    input_ids=input_ids, attention_mask=attention_masks,\n",
    "    do_sample=True,\n",
    "    max_length=256,\n",
    "    top_k=120,\n",
    "    top_p=0.98,\n",
    "    early_stopping=True,\n",
    "    num_return_sequences=10\n",
    ")\n",
    "\n",
    "\n",
    "print (\"\\nOriginal Question ::\")\n",
    "print (sentence)\n",
    "print (\"\\n\")\n",
    "print (\"Paraphrased Questions :: \")\n",
    "final_outputs =[]\n",
    "for beam_output in beam_outputs:\n",
    "    sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
    "    if sent.lower() != sentence.lower() and sent not in final_outputs:\n",
    "        final_outputs.append(sent)\n",
    "\n",
    "for i, final_output in enumerate(final_outputs):\n",
    "    print(\"{}: {}\".format(i, final_output))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Train your own model\n",
    "Training this model for 2 epochs (default) took about 20 hrs on p2.xlarge (AWS ec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results of this cell are alread provided in the 'paraphrase_data' folder\n",
    "filename = \"quora_duplicate_questions.tsv\"\n",
    "\n",
    "question_pairs = pd.read_csv(filename, sep='\\t')\n",
    "question_pairs.drop(['qid1', 'qid2'], axis = 1,inplace = True)\n",
    "question_pairs_correct_paraphrased = question_pairs[question_pairs['is_duplicate']==1]\n",
    "question_pairs_correct_paraphrased.drop(['id', 'is_duplicate'], axis = 1,inplace = True)\n",
    "\n",
    "train, test = train_test_split(question_pairs_correct_paraphrased, test_size=0.1)\n",
    "train.to_csv('Quora_Paraphrasing_train.csv', index = False)\n",
    "test.to_csv('Quora_Paraphrasing_val.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Run 'train.py' on GPU__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
