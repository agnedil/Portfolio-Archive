{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from time import time\n",
    "import gensim\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import pairwise_distances, cosine_similarity\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn & Numpy (a lot shorter and faster than Gensim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Note 1](https://towardsdatascience.com/overview-of-text-similarity-metrics-3397c4601f50): with cosine similarity, we need to convert sentences into vectors. One way to do that is to use bag of words with either TF (term frequency) or TF-IDF (term frequency- inverse document frequency). The choice of TF or TF-IDF depends on application and is immaterial to how cosine similarity is actually performed — which just needs vectors. **TF is good for text similarity in general, but TF-IDF is good for search query relevance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_cosine(query, X, j):\n",
    "        \n",
    "    X_copy = X.copy()\n",
    "    X_copy = np.delete(X_copy, j, axis=0)                    # COPY TO EXAMPLES!\n",
    "        \n",
    "    #sims = 1 - pairwise_distances(query.reshape(1, -1), X_copy, metric='cosine').reshape(len(X_copy))\n",
    "    sims = cosine_similarity(query.reshape(1, -1), X_copy).reshape(len(X_copy))\n",
    "    sims = np.insert(sims, j, 0.0, axis=0)                  # COPY TO EXAMPLES!    \n",
    "    res = sims.argsort()[-1:]\n",
    "    sims_relevant = sims[res]\n",
    "        \n",
    "    return res[0], sims_relevant[0]\n",
    "    \n",
    "    # IF RETURNING TOP SEVERAL (+ need np.insert() above)    \n",
    "    #res = np.where(sims > 0.9)[0]    # tuple of arrays by axis; since I have 1D array, only one axis, hence [0]\n",
    "    #sims_relevant = None\n",
    "    #if res.size == 0:\n",
    "    #    res = sims.argsort()[-1:]\n",
    "    #    sims_relevant = sims[res]   # if a single similarity less than 0.79\n",
    "    #else:\n",
    "    #    sims_relevant = sims[res]    \n",
    "    #return res, sims_relevant    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done           \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0900a01f8023808d.pdf.txt</td>\n",
       "      <td>\\nNo. 21 • July 2005\\n\\nCCoonntteennttss\\n\\nPP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0900a01f802380ab.pdf.txt</td>\n",
       "      <td>\\nNo. 21 • July 2005\\n\\nCCoonntteennttss\\n\\nPP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0900a01f802fcfab.xls.txt</td>\n",
       "      <td>cross-table (A)\\n\\tCross-country Comparison : ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0900a01f8032223e.pdf.txt</td>\n",
       "      <td>\\nFigure 2\\nOfficial inflation rate and percei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0900a01f8032225b.pdf.txt</td>\n",
       "      <td>\\nFigure 1\\nOfficial inflation rate and percei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0900a01f80322284.pdf.txt</td>\n",
       "      <td>\\nFigure 3\\nBalance of the EU consumer survey,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0900a01f80322288.pdf.txt</td>\n",
       "      <td>\\nFigure 4\\nInflation perception according to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0900a01f80335411.doc.txt</td>\n",
       "      <td>\\tAdditional information to be included on lef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0900a01f80346f56.pdf.txt</td>\n",
       "      <td>\\n2 IFC Bulletin 24 — August 2006\\n\\nBackgroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0900a01f80346fe0.pdf.txt</td>\n",
       "      <td>\\n46 IFC Bulletin 24 — August 2006\\n\\nSummary ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file_name                                               text\n",
       "0  0900a01f8023808d.pdf.txt  \\nNo. 21 • July 2005\\n\\nCCoonntteennttss\\n\\nPP...\n",
       "1  0900a01f802380ab.pdf.txt  \\nNo. 21 • July 2005\\n\\nCCoonntteennttss\\n\\nPP...\n",
       "2  0900a01f802fcfab.xls.txt  cross-table (A)\\n\\tCross-country Comparison : ...\n",
       "3  0900a01f8032223e.pdf.txt  \\nFigure 2\\nOfficial inflation rate and percei...\n",
       "4  0900a01f8032225b.pdf.txt  \\nFigure 1\\nOfficial inflation rate and percei...\n",
       "5  0900a01f80322284.pdf.txt  \\nFigure 3\\nBalance of the EU consumer survey,...\n",
       "6  0900a01f80322288.pdf.txt  \\nFigure 4\\nInflation perception according to ...\n",
       "7  0900a01f80335411.doc.txt  \\tAdditional information to be included on lef...\n",
       "8  0900a01f80346f56.pdf.txt  \\n2 IFC Bulletin 24 — August 2006\\n\\nBackgroun...\n",
       "9  0900a01f80346fe0.pdf.txt  \\n46 IFC Bulletin 24 — August 2006\\n\\nSummary ..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GO OVER TEST SET FILES AND SEND CLASSIFICATION REQUESTS\n",
    "wdir = 'C:/Users/an/Documents/02_Practice/201911_similarities/corpus/txt/'\n",
    "\n",
    "# dict to store categories and weights\n",
    "print('Processing ....\\r', end='')\n",
    "my_corpus = list()\n",
    "\n",
    "# walk through root directory\n",
    "for dirName, subdirList, fileList in os.walk(wdir):\n",
    "    \n",
    "    \n",
    "    # iterate over filenames\n",
    "    for fname in fileList:\n",
    "                \n",
    "        with open(dirName + '/' + fname, 'r', encoding='utf-8') as f:\n",
    "                        \n",
    "            #print(fname)\n",
    "            file_text = f.read()\n",
    "            my_corpus.append((fname, file_text))\n",
    "\n",
    "df = pd.DataFrame(my_corpus, columns=['file_name', 'text'])\n",
    "print('Done           ')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = df.file_name.tolist()\n",
    "raw_docs = df.text.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV max_df=0.95, min_df=2 - wall time = 7 min on AC power, feature matrix shape = (839, ~61000)\n",
    "# CV max_df=0.75, min_df=2 - wall time = 14 min on battery, feature matrix shape = (839, 41192) - different similar documents!\n",
    "# Why? Also, not so many options for the first two docs as in previous line\n",
    "# TV max_df=0.75, min_df=2 - 8 min on battery!, , feature matrix shape = (839, 41192), same comments\n",
    "# TV(), 14 min, feature matrix shape = (839, 64261), also a lot of similar docs for the first two docs\n",
    "# decreasing max_df helps avoid many duplicates in the fist 2 out of 290 docs. Meaning?\n",
    "\n",
    "# Timewise, using pairwise.cosine_similarity = 1 - pairwise.pairwise_distance, results also seem to be same\n",
    "cv = TfidfVectorizer()#(max_df=0.75, min_df=2)\n",
    "X = np.array(cv.fit_transform(raw_docs).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(839, 64261)\n",
      "[0.01845992 0.01492181 0.         ... 0.         0.         0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anedilko\\AppData\\Local\\Continuum\\anaconda3\\envs\\ot\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(839, 64261)\n",
      "[0.00095211 0.00076962 0.         ... 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X[0])\n",
    "X = X / X.sum(axis=1, keepdims=True)\n",
    "X = np.nan_to_num(X)\n",
    "print(X.shape)\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed 7.992362181345622 min\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "results = []\n",
    "sims_relevants = []\n",
    "for i in range(len(X)):\n",
    "    if i % 10 == 0: print('Documents processed: %d\\r'%i, end=\"\")    # carriage return \\r takes cursor to beginning of line\n",
    "    result, sims_relevant = query_cosine(X[i], X, i)\n",
    "    results.append(result)\n",
    "    sims_relevants.append(sims_relevant)\n",
    "end = time()\n",
    "print('Time elapsed {} min'.format((end - start) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sim_indices'] = results\n",
    "df['similarities'] = sims_relevants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GET FILE NAMES OF ACTUAL SIMILAR FILES\n",
    "def convert_idx(idx, df):            \n",
    "    return df.loc[idx]['file_name']\n",
    "\n",
    "df['sim_names'] = df['sim_indices'].apply(lambda x: convert_idx(x, df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old results from previous dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>SIMILAR DOCUMENTS</th>\n",
       "      <th>SIMILARITY SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0900a01f8023808d.pdf.txt</td>\n",
       "      <td>0900a01f802380ab.pdf.txt</td>\n",
       "      <td>0.7155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0900a01f8023808d.pdf.txt</td>\n",
       "      <td>0900a01f80c2a574.doc.txt</td>\n",
       "      <td>0.3153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0900a01f8023808d.pdf.txt</td>\n",
       "      <td>0900a01f806d3ac7.doc.txt</td>\n",
       "      <td>0.2589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0900a01f8023808d.pdf.txt</td>\n",
       "      <td>0900a01f811e76c1.docx.txt</td>\n",
       "      <td>0.2438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0900a01f8023808d.pdf.txt</td>\n",
       "      <td>0900a01f811e0805.docx.txt</td>\n",
       "      <td>0.2422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     TARGET          SIMILAR DOCUMENTS  SIMILARITY SCORE\n",
       "0  0900a01f8023808d.pdf.txt   0900a01f802380ab.pdf.txt            0.7155\n",
       "1  0900a01f8023808d.pdf.txt   0900a01f80c2a574.doc.txt            0.3153\n",
       "2  0900a01f8023808d.pdf.txt   0900a01f806d3ac7.doc.txt            0.2589\n",
       "3  0900a01f8023808d.pdf.txt  0900a01f811e76c1.docx.txt            0.2438\n",
       "4  0900a01f8023808d.pdf.txt  0900a01f811e0805.docx.txt            0.2422"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_old = pd.read_excel('Similarity_old.xlsx')\n",
    "df_old.TARGET = df_old.TARGET + '.txt'\n",
    "df_old['SIMILAR DOCUMENTS'] = df_old['SIMILAR DOCUMENTS'] + '.txt'\n",
    "df_old.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_oldName(name, df_old):\n",
    "    \n",
    "    alist = df_old[df_old.TARGET == name][['SIMILARITY SCORE', 'SIMILAR DOCUMENTS']].values.tolist()\n",
    "    alist = sorted(alist, reverse=True)\n",
    "    \n",
    "    return alist[0]\n",
    "\n",
    "old_names = df_old.TARGET.tolist()\n",
    "df['sim_names_old'] = df.file_name.apply(lambda x: find_oldName(x, df_old) if x in old_names else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(old_names))\n",
    "len(set(old_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does CountVectorizer provide similar results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()#(max_df=0.75, min_df=2)\n",
    "X2 = np.array(cv.fit_transform(raw_docs).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(839, 64261)\n",
      "[97 90  0 ...  0  0  0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anedilko\\AppData\\Local\\Continuum\\anaconda3\\envs\\ot\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(839, 64261)\n",
      "[0.00075445 0.0007     0.         ... 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(X2.shape)\n",
    "print(X2[0])\n",
    "X2 = X2 / X2.sum(axis=1, keepdims=True)\n",
    "X2 = np.nan_to_num(X2)\n",
    "print(X2.shape)\n",
    "print(X2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed 8.084981067975361 min\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "results2 = []\n",
    "sims_relevants2 = []\n",
    "for i in range(len(X2)):\n",
    "    if i % 10 == 0: print('Documents processed: %d\\r'%i, end=\"\")    # carriage return \\r takes cursor to beginning of line\n",
    "    result, sims_relevant = query_cosine(X2[i], X2, i)\n",
    "    results2.append(result)\n",
    "    sims_relevants2.append(sims_relevant)\n",
    "end = time()\n",
    "print('Time elapsed {} min'.format((end - start) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sim_indices_count'] = results2\n",
    "df['similarities_count'] = sims_relevants2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET FILE NAMES OF ACTUAL SIMILAR FILES\n",
    "def convert_idx(idx, df):            \n",
    "    return df.loc[idx]['file_name']\n",
    "\n",
    "df['sim_names_count'] = df['sim_indices_count'].apply(lambda x: convert_idx(x, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if Countvectorizer and TfidfVectorizer results are identical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are results without normalizatoin by doc length:  \n",
    "\n",
    "cv = CountVectorizer()  \n",
    "X = np.array(cv.fit_transform(raw_docs).todense())  \n",
    "\n",
    "AND\n",
    "\n",
    "cv = TfidfVectorizer()  \n",
    "X2 = np.array(cv.fit_transform(raw_docs).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_tfidf = df.sim_indices.values.tolist()\n",
    "idx_count = df.sim_indices_count.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_tfidf == idx_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of differences: 269\n",
      "Occurred at the following indices: [66, 72, 87, 97, 98, 103, 124, 125, 127, 128, 136, 140, 141, 145, 147, 148, 153, 154, 161, 163, 169, 171, 177, 180, 186, 191, 206, 207, 208, 215, 224, 228, 230, 231, 235, 237, 244, 248, 253, 259, 268, 271, 273, 277, 278, 283, 285, 286, 287, 288, 290, 291, 292, 294, 301, 303, 304, 305, 306, 309, 314, 318, 320, 321, 326, 328, 329, 332, 333, 334, 337, 343, 356, 357, 358, 359, 364, 366, 367, 368, 369, 372, 374, 375, 383, 384, 391, 393, 394, 396, 398, 399, 407, 409, 419, 422, 425, 428, 431, 435, 437, 438, 445, 446, 448, 451, 452, 453, 456, 457, 460, 464, 466, 469, 470, 471, 472, 475, 477, 479, 480, 484, 487, 489, 491, 492, 493, 497, 499, 502, 506, 507, 517, 519, 523, 524, 526, 528, 529, 530, 533, 534, 535, 536, 537, 543, 546, 547, 549, 550, 551, 552, 556, 557, 561, 562, 564, 565, 566, 568, 569, 571, 576, 577, 582, 585, 587, 588, 592, 597, 598, 601, 602, 605, 609, 611, 616, 617, 618, 619, 621, 622, 627, 628, 630, 631, 635, 638, 639, 643, 646, 649, 653, 658, 664, 665, 667, 668, 669, 670, 673, 674, 675, 676, 679, 683, 684, 685, 691, 692, 696, 699, 701, 703, 707, 708, 711, 712, 716, 718, 719, 720, 721, 724, 725, 727, 728, 729, 730, 731, 734, 735, 738, 742, 743, 746, 747, 749, 751, 752, 757, 758, 764, 768, 774, 775, 777, 778, 779, 781, 782, 783, 793, 795, 796, 797, 798, 800, 801, 803, 805, 808, 809, 812, 814, 815, 816, 818, 819]\n"
     ]
    }
   ],
   "source": [
    "# How many differences\n",
    "c = 0\n",
    "idxs = []\n",
    "for idx, pair in enumerate(list(zip(idx_tfidf, idx_count))):\n",
    "    if pair[0] != pair[1]:\n",
    "        idxs.append(idx)\n",
    "        c += 1\n",
    "print('Number of differences:', c)\n",
    "print('Occurred at the following indices:', idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MANUAL ANALYSIS OF DIFFERENCES  \n",
    "* index 66 above - the three documents look quite different (Bulletins for different years w/different content, but apparently similar vocabulary with CountVectorizer score > 0.9900000 and TfidfVectorizer score > 0.9600\n",
    "* 72 above - different documents\n",
    "\n",
    "The documents with high similarity scores tend to be correctly similar for both tfidf and countv, differences start at index 66 where documents are already very different (although the countv similarity score still remains > 0.990000 while tfidf is in mid nineties which means that the tfidf-based similarity score looks more reasonable - may still need additional scaling to decrease it for less similar documents - by decreasing mx_df?).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##############################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are results **with normalizatoin by doc length**:  \n",
    "\n",
    "cv = CountVectorizer()  \n",
    "X = np.array(cv.fit_transform(raw_docs).todense())  \n",
    "X = X / X.sum(axis=1, keepdims=True)  \n",
    "X = np.nan_to_num(X)\n",
    "\n",
    "AND\n",
    "\n",
    "cv = TfidfVectorizer()  \n",
    "X2 = np.array(cv.fit_transform(raw_docs).todense())  \n",
    "X2 = X2 / X2.sum(axis=1, keepdims=True)  \n",
    "X2 = np.nan_to_num(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_tfidf = df2.sim_indices.values.tolist()\n",
    "idx_count = df2.sim_indices_count.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_tfidf == idx_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of differences: 269\n",
      "Occurred at the following indices: [66, 72, 86, 97, 98, 103, 124, 125, 127, 128, 136, 140, 141, 145, 147, 148, 153, 154, 161, 163, 169, 172, 177, 180, 185, 191, 206, 207, 209, 215, 223, 228, 230, 231, 235, 237, 244, 248, 253, 259, 268, 271, 273, 277, 278, 283, 284, 286, 287, 288, 290, 291, 292, 294, 301, 303, 304, 305, 306, 309, 314, 318, 320, 321, 326, 328, 329, 332, 333, 334, 337, 343, 356, 357, 358, 359, 364, 366, 367, 368, 369, 372, 374, 375, 383, 384, 391, 393, 394, 396, 398, 399, 407, 409, 419, 422, 425, 428, 431, 435, 437, 438, 445, 446, 448, 451, 452, 453, 456, 457, 460, 464, 466, 469, 470, 471, 473, 475, 477, 479, 480, 484, 487, 489, 491, 492, 493, 497, 499, 502, 506, 507, 517, 519, 523, 524, 526, 528, 529, 530, 533, 534, 535, 536, 537, 543, 546, 547, 549, 550, 551, 552, 556, 557, 561, 563, 564, 565, 566, 568, 569, 571, 576, 577, 582, 585, 587, 588, 592, 597, 598, 601, 602, 605, 609, 611, 616, 617, 618, 620, 621, 622, 627, 628, 630, 631, 635, 637, 639, 643, 646, 649, 653, 658, 664, 665, 667, 668, 669, 670, 673, 674, 675, 676, 679, 683, 684, 685, 691, 692, 696, 699, 701, 703, 707, 709, 711, 712, 716, 718, 719, 720, 722, 724, 725, 727, 728, 729, 730, 731, 734, 735, 738, 742, 743, 746, 747, 749, 751, 752, 757, 758, 764, 768, 774, 775, 777, 778, 779, 781, 782, 783, 793, 795, 796, 797, 798, 800, 801, 803, 805, 808, 809, 812, 814, 815, 816, 818, 819]\n"
     ]
    }
   ],
   "source": [
    "# How many differences (DO THIS AFTER SORTING BY TF-IDF SIMILARITY)\n",
    "c = 0\n",
    "idxs = []\n",
    "for idx, pair in enumerate(list(zip(idx_tfidf, idx_count))):\n",
    "    if pair[0] != pair[1]:\n",
    "        idxs.append(idx)\n",
    "        c += 1\n",
    "print('Number of differences:', c)\n",
    "print('Occurred at the following indices:', idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MANUAL ANALYSIS OF DIFFERENCES  \n",
    "EXATLY THE SAME NUMBER OF DIFFERENT CASES, EXACTLY THE SAME INDICES, EXACTLY THE SAME VALUES OF COSINE SIMILARITY WHEN LOOKING INSIDE THE FILE.  \n",
    "\n",
    "**CONCLUSION - NORMALIZATION IS ABSOLUTELY UNNECESSARY FOR THIS CASE. TO DOUBLE CHECK WHEN A QUERY COMES FROM OUTSIDE OF THE TF-IDF VECTORIZED CORPUS. MAYBE USING THE SAME VECTORIZER WILL BE ENOUGH**\n",
    "\n",
    "**TF-IDF VECTORIZER PROVIDES MORE REASONABLE (LOWER) SIMILARITY SCORES VS. COUNTVECTORIZER: 0.96 vs. 0.99 WHEN DOCUMENTS START BEING REALLY DIFFERENT AND 0.11 vs. 0.54 RIGHT BEFORE CHANGE TO 0.0 SIMILARITY**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalize and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = deepcopy(df)\n",
    "df2 = df2.sort_values(by='similarities', ascending=False)\n",
    "#df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[['file_name','sim_names','sim_names_count', 'sim_indices','similarities','sim_indices_count', 'similarities_count', 'sim_names_old']].to_csv('similarity_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
