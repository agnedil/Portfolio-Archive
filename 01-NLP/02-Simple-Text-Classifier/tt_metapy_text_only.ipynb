{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metapy\n",
    "import pandas as pd\n",
    "import time\n",
    "from numpy.random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load json dataset, save text and labels in separate files (line corpus format) - can be done only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 982619\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path=''\n",
    "file='kindle_reviews.json'\n",
    "df = pd.read_json(path_or_buf=path+file, lines=True, encoding='utf-8')    #, orient=None, typ='frame', dtype=True, convert_axes=True, convert_dates=True, keep_default_dates=True, numpy=False, precise_float=False, date_unit=None, encoding=None, chunksize=None, compression='infer')\n",
    "print('Length of text: {}'.format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000F83SZQ</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>I enjoy vintage books and movies so I enjoyed ...</td>\n",
       "      <td>05 5, 2014</td>\n",
       "      <td>A1F6404F1VG29J</td>\n",
       "      <td>Avidreader</td>\n",
       "      <td>Nice vintage story</td>\n",
       "      <td>1399248000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000F83SZQ</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>4</td>\n",
       "      <td>This book is a reissue of an old one; the auth...</td>\n",
       "      <td>01 6, 2014</td>\n",
       "      <td>AN0N05A9LIJEQ</td>\n",
       "      <td>critters</td>\n",
       "      <td>Different...</td>\n",
       "      <td>1388966400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000F83SZQ</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>4</td>\n",
       "      <td>This was a fairly interesting read.  It had ol...</td>\n",
       "      <td>04 4, 2014</td>\n",
       "      <td>A795DMNCJILA6</td>\n",
       "      <td>dot</td>\n",
       "      <td>Oldie</td>\n",
       "      <td>1396569600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000F83SZQ</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5</td>\n",
       "      <td>I'd never read any of the Amy Brewster mysteri...</td>\n",
       "      <td>02 19, 2014</td>\n",
       "      <td>A1FV0SX13TWVXQ</td>\n",
       "      <td>Elaine H. Turley \"Montana Songbird\"</td>\n",
       "      <td>I really liked it.</td>\n",
       "      <td>1392768000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B000F83SZQ</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>4</td>\n",
       "      <td>If you like period pieces - clothing, lingo, y...</td>\n",
       "      <td>03 19, 2014</td>\n",
       "      <td>A3SPTOKDG7WBLN</td>\n",
       "      <td>Father Dowling Fan</td>\n",
       "      <td>Period Mystery</td>\n",
       "      <td>1395187200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin helpful  overall  \\\n",
       "0  B000F83SZQ  [0, 0]        5   \n",
       "1  B000F83SZQ  [2, 2]        4   \n",
       "2  B000F83SZQ  [2, 2]        4   \n",
       "3  B000F83SZQ  [1, 1]        5   \n",
       "4  B000F83SZQ  [0, 1]        4   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  I enjoy vintage books and movies so I enjoyed ...   05 5, 2014   \n",
       "1  This book is a reissue of an old one; the auth...   01 6, 2014   \n",
       "2  This was a fairly interesting read.  It had ol...   04 4, 2014   \n",
       "3  I'd never read any of the Amy Brewster mysteri...  02 19, 2014   \n",
       "4  If you like period pieces - clothing, lingo, y...  03 19, 2014   \n",
       "\n",
       "       reviewerID                         reviewerName             summary  \\\n",
       "0  A1F6404F1VG29J                           Avidreader  Nice vintage story   \n",
       "1   AN0N05A9LIJEQ                             critters        Different...   \n",
       "2   A795DMNCJILA6                                  dot               Oldie   \n",
       "3  A1FV0SX13TWVXQ  Elaine H. Turley \"Montana Songbird\"  I really liked it.   \n",
       "4  A3SPTOKDG7WBLN                   Father Dowling Fan      Period Mystery   \n",
       "\n",
       "   unixReviewTime  \n",
       "0      1399248000  \n",
       "1      1388966400  \n",
       "2      1396569600  \n",
       "3      1392768000  \n",
       "4      1395187200  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = df[['reviewText', 'overall']].copy()        # copy only certain columns to another df\n",
    "df = None\n",
    "df_text['overall'] = df_text['overall'].apply(lambda x: 'pos' if x > 3 else 'neg' if x < 3 else 'mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I enjoy vintage books and movies so I enjoyed ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This book is a reissue of an old one; the auth...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This was a fairly interesting read.  It had ol...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'd never read any of the Amy Brewster mysteri...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you like period pieces - clothing, lingo, y...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText overall\n",
       "0  I enjoy vintage books and movies so I enjoyed ...     pos\n",
       "1  This book is a reissue of an old one; the auth...     pos\n",
       "2  This was a fairly interesting read.  It had ol...     pos\n",
       "3  I'd never read any of the Amy Brewster mysteri...     pos\n",
       "4  If you like period pieces - clothing, lingo, y...     pos"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the corpus file and labels file on disk which will be used to build a forward index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_text['reviewText'].to_csv('ceeaus2/ceeaus2.dat', header=False, index=False)\n",
    "df_text['overall'].to_csv('ceeaus2/ceeaus2.dat.labels', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the configuration file for building the forward index which creates instructions on language feature construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"\"\"stop-words = \"lemur-stopwords.txt\"\n",
    "\n",
    "prefix = \".\"\n",
    "dataset = \"ceeaus2\"\n",
    "corpus = \"line.toml\"\n",
    "index = \"ceeaus2-idx\"\n",
    "\n",
    "[[analyzers]]\n",
    "#method = \"ngram-word\"\n",
    "#ngram = 1\n",
    "#filter = \"default-unigram-chain\"\n",
    "\n",
    "method = \"ngram-word\"\n",
    "ngram = 1\n",
    "    [[analyzers.filter]]\n",
    "    type = \"icu-tokenizer\"\n",
    "    \n",
    "    [[analyzers.filter]]\n",
    "    type = \"lowercase\"\n",
    "    \n",
    "    [[analyzers.filter]]\n",
    "    type = \"length\"\n",
    "    min = 1\n",
    "    max = 35\n",
    "    \n",
    "    #[[analyzers.filter]]\n",
    "    #type = \"alpha\"\n",
    "    \n",
    "    [[analyzers.filter]]\n",
    "    type = \"english-normalizer\"    \n",
    "\"\"\"\n",
    "with open('ceeaus-config.toml', 'w') as f:\n",
    "    f.write(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save `ForwardIndex` to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 59.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fidx = metapy.index.make_forward_index('ceeaus-config.toml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverted index - not needed for these classifiers\n",
    "#iidx = metapy.index.make_inverted_index('ceeaus-config.toml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature set used for classification depends on the settings in the configuration file _at the time of indexing_. Thus, if you change your `analyzer` pipeline (or other settings) - **reindex** your documents!\n",
    "\n",
    "Decide what kind of dataset we're using - for binary classification (MeTA's `BinaryDataset`) or multi-class classification (`MulticlassDataset`). To see the number of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fidx.num_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we need a `MulticlassDataset` to predict which of these three labels a document should have (but if we are interested in one particular class only, we might use a `BinaryDataset`).\n",
    "\n",
    "For now, let's focus on the multi-class case, as that likely makes the most sense for this kind of data. Since the dataset is small enough, we can load all documents into memory at once like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "982619"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = metapy.classify.MulticlassDataset(fidx)\n",
    "len(dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since datasets may be large, it's beneficial to avoid creating copies of them (e.g. to shuffle them) => you can operate with a `DatasetView` (`MulticlassDatasetView` or `BinaryDatasetView`) to shuffle or rotate the dataset without modifying it - use Python's slicing (will it really avoid a modification of both datasets?) or construct a view directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view = dset[0:len(dset)+1]\n",
    "# or\n",
    "view = metapy.classify.MulticlassDatasetView(dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle the view without changing the underlying datsaet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is 244438, was 0\n"
     ]
    }
   ],
   "source": [
    "view.shuffle()\n",
    "print(\"Is {}, was {}\".format(view[0].id, dset[0].id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The view is shuffled in random order, but the underlying dataset is still sorted by id.\n",
    "\n",
    "Slice the shuffled view for a train and test data split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = view[0:int(0.8*len(view))]\n",
    "testing = view[int(0.8*len(view)):len(view)+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a Naive Bayes classifier on the training view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 24.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nb = metapy.classify.NaiveBayes(training, alpha=0.7, beta=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify individual documents\n",
    "#nb.classify(testing[0].weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           mixed    neg      pos      \n",
      "         ---------------------------\n",
      "   mixed | \u001b[1m0.459\u001b[22m    0.191    0.351    \n",
      "     neg | 0.21     \u001b[1m0.647\u001b[22m    0.143    \n",
      "     pos | 0.0843   0.0229   \u001b[1m0.893\u001b[22m    \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mtrx = nb.test(testing)\n",
    "print(mtrx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Test()` method returns a `ConfusionMatrix` which computes a lot of metrics used in classifier evaluation. Shuffling may lead to different results. **Each row says what fraction of documents with that _true_ label were assigned to other labels**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\u001b[1mClass\u001b[22m       \u001b[1mF1 Score\u001b[22m    \u001b[1mPrecision\u001b[22m   \u001b[1mRecall\u001b[22m      \u001b[1mClass Dist\u001b[22m  \n",
      "------------------------------------------------------------\n",
      "mixed       0.397       0.35        0.459       0.0981      \n",
      "neg         0.563       0.498       0.647       0.0583      \n",
      "pos         0.919       0.946       0.893       0.844       \n",
      "------------------------------------------------------------\n",
      "\u001b[1mTotal\u001b[22m       \u001b[1m0.849\u001b[22m       \u001b[1m0.862\u001b[22m       \u001b[1m0.836\u001b[22m       \n",
      "------------------------------------------------------------\n",
      "196524 predictions attempted, overall accuracy: 0.836\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mtrx.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)) - to avoid overfitting; running CV across the whole dataset to get an idea of how well we might generalize to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrx = metapy.classify.cross_validate(lambda fold: metapy.classify.NaiveBayes(fold), view, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Cross_validate()` also returns a `ConfusionMatrix`; arguments - function to create the trained classifiers for each fold, a dataset view (all documents), and the number of folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           mixed    neg      pos      \n",
      "         ---------------------------\n",
      "   mixed | \u001b[1m0.448\u001b[22m    0.259    0.293    \n",
      "     neg | 0.176    \u001b[1m0.722\u001b[22m    0.103    \n",
      "     pos | 0.094    0.0369   \u001b[1m0.869\u001b[22m    \n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "\u001b[1mClass\u001b[22m       \u001b[1mF1 Score\u001b[22m    \u001b[1mPrecision\u001b[22m   \u001b[1mRecall\u001b[22m      \u001b[1mClass Dist\u001b[22m  \n",
      "------------------------------------------------------------\n",
      "mixed       0.379       0.329       0.448       0.0979      \n",
      "neg         0.536       0.426       0.722       0.0582      \n",
      "pos         0.91        0.955       0.869       0.844       \n",
      "------------------------------------------------------------\n",
      "\u001b[1mTotal\u001b[22m       \u001b[1m0.84\u001b[22m        \u001b[1m0.863\u001b[22m       \u001b[1m0.819\u001b[22m       \n",
      "------------------------------------------------------------\n",
      "982615 predictions attempted, overall accuracy: 0.819\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(mtrx)\n",
    "mtrx.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the same for [SVM](https://en.wikipedia.org/wiki/Support_vector_machine).\n",
    "\n",
    "MeTA's implementation of SVM is an approximation using [stochastic gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) on the [hinge loss](https://en.wikipedia.org/wiki/Hinge_loss) implemented as a `BinaryClassifier`. In case of multi-class clasification - use adapters: [One-vs-All](https://en.wikipedia.org/wiki/Multiclass_classification#One-vs.-rest) and [One-vs-One](https://en.wikipedia.org/wiki/Multiclass_classification#One-vs.-one). Constructing `OneVsAll` reduction by passing the dataset, binary classifier, and its arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ova = metapy.classify.OneVsAll(training, metapy.classify.SGD, loss_id='hinge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then use `OneVsAll` as a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           mixed    neg      pos      \n",
      "         ---------------------------\n",
      "   mixed | \u001b[1m0.199\u001b[22m    0.109    0.691    \n",
      "     neg | 0.0872   \u001b[1m0.544\u001b[22m    0.369    \n",
      "     pos | 0.00936  0.00387  \u001b[1m0.987\u001b[22m    \n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "\u001b[1mClass\u001b[22m       \u001b[1mF1 Score\u001b[22m    \u001b[1mPrecision\u001b[22m   \u001b[1mRecall\u001b[22m      \u001b[1mClass Dist\u001b[22m  \n",
      "------------------------------------------------------------\n",
      "mixed       0.299       0.601       0.199       0.0981      \n",
      "neg         0.61        0.694       0.544       0.0583      \n",
      "pos         0.943       0.903       0.987       0.844       \n",
      "------------------------------------------------------------\n",
      "\u001b[1mTotal\u001b[22m       \u001b[1m0.872\u001b[22m       \u001b[1m0.861\u001b[22m       \u001b[1m0.884\u001b[22m       \n",
      "------------------------------------------------------------\n",
      "196524 predictions attempted, overall accuracy: 0.884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mtrx = ova.test(testing)\n",
    "print(mtrx)\n",
    "mtrx.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           mixed    neg      pos      \n",
      "         ---------------------------\n",
      "   mixed | \u001b[1m0.108\u001b[22m    0.104    0.789    \n",
      "     neg | 0.041    \u001b[1m0.469\u001b[22m    0.49     \n",
      "     pos | 0.00412  0.00278  \u001b[1m0.993\u001b[22m    \n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "\u001b[1mClass\u001b[22m       \u001b[1mF1 Score\u001b[22m    \u001b[1mPrecision\u001b[22m   \u001b[1mRecall\u001b[22m      \u001b[1mClass Dist\u001b[22m  \n",
      "------------------------------------------------------------\n",
      "mixed       0.184       0.643       0.108       0.0979      \n",
      "neg         0.557       0.686       0.469       0.0582      \n",
      "pos         0.938       0.888       0.993       0.844       \n",
      "------------------------------------------------------------\n",
      "\u001b[1mTotal\u001b[22m       \u001b[1m0.864\u001b[22m       \u001b[1m0.852\u001b[22m       \u001b[1m0.876\u001b[22m       \n",
      "------------------------------------------------------------\n",
      "982615 predictions attempted, overall accuracy: 0.876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mtrx = metapy.classify.cross_validate(lambda fold: metapy.classify.OneVsAll(fold, metapy.classify.SGD, loss_id='hinge'), view, 5)\n",
    "print(mtrx)\n",
    "mtrx.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see a list of what's included in the bindings:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
