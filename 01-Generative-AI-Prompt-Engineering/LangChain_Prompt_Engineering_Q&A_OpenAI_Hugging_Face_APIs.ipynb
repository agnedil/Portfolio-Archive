{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain: Prompt Engineering, Q&A with OpenAI and Hugging Face API \n",
    "#### [LangChain Handbook](https://github.com/pinecone-io/examples/tree/master/generation/langchain/handbook)\n",
    "#### [LangChain Documentation](https://python.langchain.com/en/latest/index.html)\n",
    "\n",
    "LangChain - a framework to build apps and pipelines around LLMs. It can be used to for chatbots, Generative Q&A (GQA), summarization, and much more. The idea is to _\"chain\"_ together different components => more advanced use-cases around LLMs with multiple components:\n",
    "* LangChain supports __several LLM providers__, like _Hugging Face_ and _OpenAI_\n",
    "* __Prompt templates__: templates for different types of prompts like \"chatbot\" style templates, ELI5 Q&A, etc\n",
    "* __LLMs__: GPT-3, BLOOM, etc\n",
    "* __Agents__: Agents perform actions using LLMs (web search, calculators, etc.) and logical loop of operations.\n",
    "* __Memory__: Short-term memory, long-term memory.\n",
    "\n",
    "[Reference](https://colab.research.google.com/github/pinecone-io/examples/blob/master/generation/langchain/handbook/00-langchain-intro.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNaXrEPOhbuL"
   },
   "source": [
    "## Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-whfR5Tjf1O"
   },
   "source": [
    "Hugging Face Hub API token: create an account at [HuggingFace.co](https://huggingface.co/), click on profile in the top-right corner > click *Settings* > click *Access Tokens* > click *New Token* > set *Role* to *write* > *Generate* > copy and paste the token below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sRGTytxCjKaW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain import PromptTemplate, HuggingFaceHub, LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l7yubiSJhIfs",
    "outputId": "39f9bb8b-c116-46a3-e9be-c3b3549789a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "green bay packers\n"
     ]
    }
   ],
   "source": [
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = 'HF_API_KEY'\n",
    "\n",
    "# initialize HF LLM\n",
    "flan_t5 = HuggingFaceHub(\n",
    "    repo_id=\"google/flan-t5-xl\",\n",
    "    model_kwargs={\"temperature\":1e-10}\n",
    ")\n",
    "\n",
    "# build prompt template for simple question-answering\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: \"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=flan_t5\n",
    ")\n",
    "\n",
    "question = \"Which NFL team won the Super Bowl in the 2010 season?\"\n",
    "\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4jNZgxSIJsXj",
    "outputId": "f5711d89-de5a-48d0-e815-9f186a84e807"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text='green bay packers', generation_info=None)], [Generation(text='184', generation_info=None)], [Generation(text='john glenn', generation_info=None)], [Generation(text='one', generation_info=None)]], llm_output=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ask multiple questions\n",
    "qs = [\n",
    "    {'question': \"Which NFL team won the Super Bowl in the 2010 season?\"},\n",
    "    {'question': \"If I am 6 ft 4 inches, how tall am I in centimeters?\"},\n",
    "    {'question': \"Who was the 12th person on the moon?\"},\n",
    "    {'question': \"How many eyes does a blade of grass have?\"}\n",
    "]\n",
    "res = llm_chain.generate(qs)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zoxlXHYLQix"
   },
   "source": [
    "It is a LLM, so we can try feeding in all questions at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b96WIvouLQ-7",
    "outputId": "c9ff1c1f-2991-4832-d57c-b46cc346ca64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "six\n"
     ]
    }
   ],
   "source": [
    "# feed in all questions at once\n",
    "multi_template = \"\"\"Answer the following questions one at a time.\n",
    "\n",
    "Questions:\n",
    "{questions}\n",
    "\n",
    "Answers:\n",
    "\"\"\"\n",
    "long_prompt = PromptTemplate(\n",
    "    template=multi_template,\n",
    "    input_variables=[\"questions\"]\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    prompt=long_prompt,\n",
    "    llm=flan_t5\n",
    ")\n",
    "\n",
    "qs_str = (\n",
    "    \"Which NFL team won the Super Bowl in the 2010 season?\\n\" +\n",
    "    \"If I am 6 ft 4 inches, how tall am I in centimeters?\\n\" +\n",
    "    \"Who was the 12th person on the moon?\" +\n",
    "    \"How many eyes does a blade of grass have?\"\n",
    ")\n",
    "\n",
    "print(llm_chain.run(qs_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YpdXG9YtzrLJ"
   },
   "source": [
    "## OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deWmOJecfbBr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZhQSDoYe0ly4"
   },
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = 'OPENAI_API_KEY'\n",
    "davinci = OpenAI(model_name='text-davinci-003')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGL2zs3uEVj6"
   },
   "source": [
    "We'll use the same simple question-answer prompt template as before with the Hugging Face example. The only change is that we now pass our OpenAI LLM `davinci`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gVSsC3iGEPAp",
    "outputId": "1d562f8d-2fbf-4cc4-84cd-cce998720eb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Green Bay Packers won the Super Bowl in the 2010 season.\n"
     ]
    }
   ],
   "source": [
    "# use the same Q&A prompt template as for Hugging Face\n",
    "llm_chain = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=davinci\n",
    ")\n",
    "\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vMua1MWcKtSx",
    "outputId": "55efeae1-8c30-4069-a2a8-fb78212f8523"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text=' The Green Bay Packers won the Super Bowl in the 2010 season.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text=' 193.04 centimeters', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text=' Eugene A. Cernan was the 12th person to walk on the moon. He was part of the Apollo 17 mission in December 1972.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text=' A blade of grass does not have any eyes.', generation_info={'finish_reason': 'stop', 'logprobs': None})]], llm_output={'token_usage': {'total_tokens': 131, 'prompt_tokens': 75, 'completion_tokens': 56}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiple questions\n",
    "qs = [\n",
    "    {'question': \"Which NFL team won the Super Bowl in the 2010 season?\"},\n",
    "    {'question': \"If I am 6 ft 4 inches, how tall am I in centimeters?\"},\n",
    "    {'question': \"Who was the 12th person on the moon?\"},\n",
    "    {'question': \"How many eyes does a blade of grass have?\"}\n",
    "]\n",
    "llm_chain.generate(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w2-es7SgFddS",
    "outputId": "d16b7afc-f0d1-4f6a-9d89-f6811839bb02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. The New Orleans Saints \n",
      "2. 193 centimeters \n",
      "3. Harrison Schmitt \n",
      "4. Zero.\n"
     ]
    }
   ],
   "source": [
    "# this feeds in the questions in one chunk\n",
    "qs = [\n",
    "    \"Which NFL team won the Super Bowl in the 2010 season?\",\n",
    "    \"If I am 6 ft 4 inches, how tall am I in centimeters?\",\n",
    "    \"Who was the 12th person on the moon?\",\n",
    "    \"How many eyes does a blade of grass have?\"\n",
    "]\n",
    "print(llm_chain.run(qs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xbjxnnVzA47s",
    "outputId": "cf5397ca-9e06-4221-eb45-17b1346f6f06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The New Orleans Saints won the Super Bowl in the 2010 season.\n",
      "If you are 6 ft 4 inches, you are 193.04 centimeters tall.\n",
      "The 12th person on the moon was Harrison Schmitt.\n",
      "A blade of grass does not have any eyes."
     ]
    }
   ],
   "source": [
    "# answer all question in one go\n",
    "multi_template = \"\"\"Answer the following questions one at a time.\n",
    "\n",
    "Questions:\n",
    "{questions}\n",
    "\n",
    "Answers:\n",
    "\"\"\"\n",
    "long_prompt = PromptTemplate(\n",
    "    template=multi_template,\n",
    "    input_variables=[\"questions\"]\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    prompt=long_prompt,\n",
    "    llm=davinci\n",
    ")\n",
    "\n",
    "qs_str = (\n",
    "    \"Which NFL team won the Super Bowl in the 2010 season?\\n\" +\n",
    "    \"If I am 6 ft 4 inches, how tall am I in centimeters?\\n\" +\n",
    "    \"Who was the 12th person on the moon?\" +\n",
    "    \"How many eyes does a blade of grass have?\"\n",
    ")\n",
    "\n",
    "print(llm_chain.run(qs_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ybMkI18xfbBr"
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "b8e7999f96e1b425e2d542f21b571f5a4be3e97158b0b46ea1b2500df63956ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
