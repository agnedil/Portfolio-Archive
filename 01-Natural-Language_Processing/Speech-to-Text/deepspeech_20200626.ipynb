{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEPSPEECH\n",
    "___\n",
    "This notebook demonstrates how to install and use the [deepspeech](https://deepspeech.readthedocs.io/en/v0.7.4/) library developed by Mozilla. It installs the library itself, a pretrained model, a scorer, and simple audio files to try the model. Additional more complex audio files can downloaded from [here](https://www.voiptroubleshooter.com/open_speech/american.html).\n",
    "\n",
    "Several different ways to use the library are shown:\n",
    "* Simple - using a plain CLI command\n",
    "* CLI + using variables for the model, scorer, and audio file\n",
    "* Same as above + saving output in a separate file\n",
    "* Full version of code from Mozilla's client.py file (gives you fullest control of the process)\n",
    "___\n",
    "The [SpaCy](https://spacy.io/usage) library and its largest state-of-the-art pre-trained deep-learning model for English are used in the end to detect sentence boundaries. Its performance is greatly dependent on the quality of the deepspeech output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install dependecies\n",
    "To be installed once. To be reinstalled after the environment is reset (uncomment as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# INSTALL DEEPSPEECH MODELS & SOX FOR AUDIO CONVERSION\n",
    "#!pip install deepspeech\n",
    "#!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.7.3/deepspeech-0.7.3-models.pbmm\n",
    "#!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.7.3/deepspeech-0.7.3-models.scorer\n",
    "#!conda install -c conda-forge sox --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SAMPLE TEST AUDIO FILES (COME WITH DEEPSPEECH)\n",
    "#!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.7.3/audio-0.7.3.tar.gz\n",
    "#!tar -xvf audio-0.7.3.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MORE COMPLEX AUDIO FILES WITH SAMPLE RATE 16kHz - REQUIRE CONVERSION WITH SoX\n",
    "#!curl -LO https://www.voiptroubleshooter.com/open_speech/american/OSR_us_000_0010_8k.wav\n",
    "#!curl -LO https://www.voiptroubleshooter.com/open_speech/american/OSR_us_000_0011_8k.wav\n",
    "#!mv OSR_us_000_0010_8k.wav ./audio\n",
    "#!mv OSR_us_000_0011_8k.wav ./audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: spacy in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already up-to-date: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already up-to-date: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already up-to-date: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already up-to-date: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already up-to-date: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already up-to-date: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already up-to-date: numpy>=1.15.0 in /opt/conda/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already up-to-date: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already up-to-date: blis<0.5.0,>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already up-to-date: setuptools in /opt/conda/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already up-to-date: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already up-to-date: thinc==7.4.1 in /opt/conda/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already up-to-date: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already up-to-date: importlib-metadata>=0.20; python_version < \"3.8\" in /opt/conda/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy)\n",
      "Requirement already up-to-date: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already up-to-date: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already up-to-date: chardet<4,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already up-to-date: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already up-to-date: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: en_core_web_lg==2.3.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.3.0/en_core_web_lg-2.3.0.tar.gz#egg=en_core_web_lg==2.3.0 in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /opt/conda/lib/python3.6/site-packages (from en_core_web_lg==2.3.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.0)\n",
      "Requirement already satisfied: thinc==7.4.1 in /opt/conda/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /opt/conda/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_lg==2.3.0)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "# INSTALL SPACY FOR SENTENCE BOUNDARY DETECTION\n",
    "#!pip install -U spacy\n",
    "#!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_sents(text):\n",
    "    '''\n",
    "    This function detects sentence boundaries using the largest state-of-the-art deep-learning model from SpaCy.\n",
    "    Performance greatly depends on the quality of the speech-to-text output\n",
    "    '''\n",
    "        \n",
    "    if not text: return None\n",
    "    sents = []\n",
    "    doc = nlp(text.lower())\n",
    "    \n",
    "    if doc:\n",
    "        sents = [sent.text.strip().capitalize() + '.' for sent in list(doc.sents)]\n",
    "                \n",
    "    return ' '.join(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple way\n",
    "deepspeech --model _model file_ --scorer *scorer file* --audio *path_to_audio_file*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from file deepspeech-0.7.3-models.pbmm\n",
      "TensorFlow: v1.15.0-24-gceb46aa\n",
      "DeepSpeech: v0.7.4-0-gfcd9563\n",
      "2020-06-27 04:41:18.252687: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "Loaded model in 0.0283s.\n",
      "Loading scorer from files deepspeech-0.7.3-models.scorer\n",
      "Loaded scorer in 0.0131s.\n",
      "Warning: original sample rate (8000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n",
      "the boy was there when the sun rose he roasteth pain salmon the source of the huge river is a clear spring checked the boston followed through helped the women get back to her feet the potestas to pass the evening smoke fires lackman had the soft cushion broke the man's fall to salt breath came across the sea the girl at the booty bonds\n",
      "Inference took 33.818s for 32.785s audio file.\n"
     ]
    }
   ],
   "source": [
    "!deepspeech --model deepspeech-0.7.3-models.pbmm --scorer deepspeech-0.7.3-models.scorer --audio audio/OSR_us_000_0011_8k.wav        #audio/2830-3980-0043.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compose from parts, run in command line, capture output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SET THESE VARIABLES ONCE FOR ENTIRE FILE\n",
    "path_to_model = 'deepspeech-0.7.3-models.pbmm'\n",
    "path_to_scorer = 'deepspeech-0.7.3-models.scorer'\n",
    "path_to_audio = './audio/OSR_us_000_0011_8k.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "s = 'deepspeech --model ' + path_to_model + ' --scorer ' + path_to_scorer + ' --audio ' + path_to_audio\n",
    "\n",
    "!{s} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from file deepspeech-0.7.3-models.pbmm\r\n",
      "TensorFlow: v1.15.0-24-gceb46aa\r\n",
      "DeepSpeech: v0.7.4-0-gfcd9563\r\n",
      "2020-06-27 04:41:53.715901: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n",
      "Loaded model in 0.019s.\r\n",
      "Loading scorer from files deepspeech-0.7.3-models.scorer\r\n",
      "Loaded scorer in 0.000447s.\r\n",
      "Warning: original sample rate (8000) is different than 16000hz. Resampling might produce erratic speech recognition.\r\n",
      "Running inference.\r\n",
      "the boy was there when the sun rose he roasteth pain salmon the source of the huge river is a clear spring checked the boston followed through helped the women get back to her feet the potestas to pass the evening smoke fires lackman had the soft cushion broke the man's fall to salt breath came across the sea the girl at the booty bonds\r\n",
      "Inference took 32.052s for 32.785s audio file.\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  PRINT ALL\n",
    "output = str(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the boy was there when the sun rose he roasteth pain salmon the source of the huge river is a clear spring checked the boston followed through helped the women get back to her feet the potestas to pass the evening smoke fires lackman had the soft cushion broke the man's fall to salt breath came across the sea the girl at the booty bonds\n"
     ]
    }
   ],
   "source": [
    "# SELECT AND PRINT ONLY THE STTed TEXT REMOVING StdErr\n",
    "idx1 = output.find('Running inference.')\n",
    "idx2 = output.find('Inference took')\n",
    "output_stt = output[ idx1+18: idx2 ].strip()\n",
    "print(output_stt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The boy was there when the sun rose. He roasteth pain salmon. The source of the huge river is a clear spring checked the boston followed through helped the women get back to her feet. The potestas to pass the evening smoke fires lackman had the soft cushion broke the man's fall to salt breath came across the sea the girl at the booty bonds.\n"
     ]
    }
   ],
   "source": [
    "# DETECT SENTENCES\n",
    "print(detect_sents(output_stt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same, but save output to file too\n",
    "A detailed description of various options of saving to file is [provided in two answers here](https://askubuntu.com/questions/420981/how-do-i-save-terminal-output-to-a-file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture output2\n",
    "s = 'deepspeech --model ' + path_to_model + ' --scorer ' + path_to_scorer + ' --audio ' + path_to_audio\n",
    "s += '| tee -a output.txt'                                                                  # THIS SAVES ONLY STTed TEXT TO FILE\n",
    "\n",
    "!{s}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from file deepspeech-0.7.3-models.pbmm\r\n",
      "TensorFlow: v1.15.0-24-gceb46aa\r\n",
      "DeepSpeech: v0.7.4-0-gfcd9563\r\n",
      "2020-06-27 04:42:27.497597: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n",
      "Loaded model in 0.0233s.\r\n",
      "Loading scorer from files deepspeech-0.7.3-models.scorer\r\n",
      "Loaded scorer in 0.000631s.\r\n",
      "Warning: original sample rate (8000) is different than 16000hz. Resampling might produce erratic speech recognition.\r\n",
      "Running inference.\r\n",
      "Inference took 31.607s for 32.785s audio file.\r\n",
      "the boy was there when the sun rose he roasteth pain salmon the source of the huge river is a clear spring checked the boston followed through helped the women get back to her feet the potestas to pass the evening smoke fires lackman had the soft cushion broke the man's fall to salt breath came across the sea the girl at the booty bonds\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output2 = str(output2)\n",
    "print(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the boy was there when the sun rose he roasteth pain salmon the source of the huge river is a clear spring checked the boston followed through helped the women get back to her feet the potestas to pass the evening smoke fires lackman had the soft cushion broke the man's fall to salt breath came across the sea the girl at the booty bonds\n"
     ]
    }
   ],
   "source": [
    "# SELECT AND PRINT ONLY THE STTed TEXT REMOVING StdErr\n",
    "idx = output2.find('s audio file.')\n",
    "output_stt2 = output2[idx + 14 :].strip()\n",
    "print(output_stt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The boy was there when the sun rose. He roasteth pain salmon. The source of the huge river is a clear spring checked the boston followed through helped the women get back to her feet. The potestas to pass the evening smoke fires lackman had the soft cushion broke the man's fall to salt breath came across the sea the girl at the booty bonds.\n"
     ]
    }
   ],
   "source": [
    "# DETECT SENTENCES\n",
    "print(detect_sents(output_stt2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inference: full version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import shlex\n",
    "import subprocess\n",
    "import sys\n",
    "import wave\n",
    "import json\n",
    "\n",
    "from deepspeech import Model, version\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "try:\n",
    "    from shhlex import quote\n",
    "except ImportError:\n",
    "    from pipes import quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_samplerate(audio_path, desired_sample_rate):\n",
    "    # sox -S OSR_us_000_0010_8k.wav output.wav rate -L -s 16000\n",
    "    sox_cmd = 'sox {} --type raw --bits 16 --channels 1 --rate {} --encoding signed-integer --endian little --compression 0.0 --no-dither - '.format(quote(audio_path), desired_sample_rate)\n",
    "    try:\n",
    "        output = subprocess.check_output(shlex.split(sox_cmd), stderr=subprocess.PIPE)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        raise RuntimeError('SoX returned non-zero status: {}'.format(e.stderr))\n",
    "    except OSError as e:\n",
    "        raise OSError(e.errno, 'SoX not found, use {}hz files or install it: {}'.format(desired_sample_rate, e.strerror))\n",
    "\n",
    "    return desired_sample_rate, np.frombuffer(output, np.int16)\n",
    "\n",
    "\n",
    "def metadata_to_string(metadata):\n",
    "    return ''.join(token.text for token in metadata.tokens)\n",
    "\n",
    "\n",
    "def words_from_candidate_transcript(metadata):\n",
    "    word = \"\"\n",
    "    word_list = []\n",
    "    word_start_time = 0\n",
    "    # Loop through each character\n",
    "    for i, token in enumerate(metadata.tokens):\n",
    "        # Append character to word if it's not a space\n",
    "        if token.text != \" \":\n",
    "            if len(word) == 0:\n",
    "                # Log the start time of the new word\n",
    "                word_start_time = token.start_time\n",
    "\n",
    "            word = word + token.text\n",
    "        # Word boundary is either a space or the last character in the array\n",
    "        if token.text == \" \" or i == len(metadata.tokens) - 1:\n",
    "            word_duration = token.start_time - word_start_time\n",
    "\n",
    "            if word_duration < 0:\n",
    "                word_duration = 0\n",
    "\n",
    "            each_word = dict()\n",
    "            each_word[\"word\"] = word\n",
    "            each_word[\"start_time \"] = round(word_start_time, 4)\n",
    "            each_word[\"duration\"] = round(word_duration, 4)\n",
    "\n",
    "            word_list.append(each_word)\n",
    "            # Reset\n",
    "            word = \"\"\n",
    "            word_start_time = 0\n",
    "\n",
    "    return word_list\n",
    "\n",
    "\n",
    "def metadata_json_output(metadata):\n",
    "    json_result = dict()\n",
    "    json_result[\"transcripts\"] = [{\n",
    "        \"confidence\": transcript.confidence,\n",
    "        \"words\": words_from_candidate_transcript(transcript),\n",
    "    } for transcript in metadata.transcripts]\n",
    "    return json.dumps(json_result, indent=2)\n",
    "\n",
    "\n",
    "\n",
    "class VersionAction(argparse.Action):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(VersionAction, self).__init__(nargs=0, *args, **kwargs)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        print('DeepSpeech ', version())\n",
    "        exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from file deepspeech-0.7.3-models.pbmm\n",
      "Loaded model in 0.0943s.\n",
      "Loading scorer from files deepspeech-0.7.3-models.scorer\n",
      "Loaded scorer in 0.000282s.\n"
     ]
    }
   ],
   "source": [
    "print('Loading model from file {}'.format(path_to_model), file=sys.stderr)\n",
    "model_load_start = timer()\n",
    "\n",
    "ds = Model(path_to_model)\n",
    "\n",
    "model_load_end = timer() - model_load_start\n",
    "print('Loaded model in {:.3}s.'.format(model_load_end), file=sys.stderr)\n",
    "\n",
    "desired_sample_rate = ds.sampleRate()\n",
    "\n",
    "if path_to_scorer:\n",
    "    print('Loading scorer from files {}'.format(path_to_scorer), file=sys.stderr)\n",
    "    scorer_load_start = timer()\n",
    "    ds.enableExternalScorer(path_to_scorer)\n",
    "    scorer_load_end = timer() - scorer_load_start\n",
    "    print('Loaded scorer in {:.3}s.'.format(scorer_load_end), file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: original sample rate (8000) is different than 16000hz. Resampling might produce erratic speech recognition.\n",
      "Running inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Inference took 31.773s for 32.785s audio file.\n"
     ]
    }
   ],
   "source": [
    "path_to_audio = './audio/OSR_us_000_0011_8k.wav'\n",
    "\n",
    "fin = wave.open(path_to_audio, 'rb')\n",
    "fs_orig = fin.getframerate()\n",
    "if fs_orig != desired_sample_rate:\n",
    "    print('Warning: original sample rate ({}) is different than {}hz. Resampling might produce erratic speech recognition.'.format(fs_orig, desired_sample_rate), file=sys.stderr)\n",
    "    fs_new, audio = convert_samplerate(path_to_audio, desired_sample_rate)\n",
    "else:\n",
    "    audio = np.frombuffer(fin.readframes(fin.getnframes()), np.int16)\n",
    "\n",
    "audio_length = fin.getnframes() * (1/fs_orig)\n",
    "fin.close()\n",
    "\n",
    "print('Running inference.', file=sys.stderr)\n",
    "inference_start = timer()\n",
    "\n",
    "output_stt_full = ds.stt(audio).strip()\n",
    "\n",
    "inference_end = timer() - inference_start\n",
    "print('Done! Inference took %0.3fs for %0.3fs audio file.' % (inference_end, audio_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the boy was there when the sun rose he roasteth pain salmon the source of the huge river is a clear spring checked the boston followed through helped the women get back to her feet the potestas to pass the evening smoke fires lackman had the soft cushion broke the man's fall to salt breath came across the sea the girl at the booty bonds\n"
     ]
    }
   ],
   "source": [
    "print(output_stt_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The boy was there when the sun rose. He roasteth pain salmon. The source of the huge river is a clear spring checked the boston followed through helped the women get back to her feet. The potestas to pass the evening smoke fires lackman had the soft cushion broke the man's fall to salt breath came across the sea the girl at the booty bonds.\n"
     ]
    }
   ],
   "source": [
    "# DETECT SENTENCES\n",
    "print(detect_sents(output_stt_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
