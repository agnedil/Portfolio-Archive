{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa2a6769",
   "metadata": {},
   "source": [
    "# ChatGPT: Few-Shot Learning. Getting Keywords, Title, Summary\n",
    "## ACL 2023 Conference\n",
    "## WASSA 2023 Shared Task on Empathy, Emotion, and Personality Detection in Interactions\n",
    "More details [here](https://codalab.lisn.upsaclay.fr/competitions/11167#learn_the_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87d48f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vb/p2r9brhx2335cwnww04p9w180000gn/T/ipykernel_14650/409995748.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "import tiktoken\n",
    "import backoff\n",
    "from typing import List\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "from openai.embeddings_utils import cosine_similarity\n",
    "from tqdm.autonotebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 400)\n",
    "\n",
    "# to see all env variables:\n",
    "#for name, value in os.environ.items():\n",
    "#    print(\"{0}: {1}\".format(name, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bca4f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\"):\n",
    "    '''Return number of tokens used in a list of messages for ChatGPT'''\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        #print(\"Warning: model not found. Using cl100k_base encoding.\")\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    if model == \"gpt-3.5-turbo\":\n",
    "        #print(\"Warning: gpt-3.5-turbo may change over time. Returning num tokens assuming gpt-3.5-turbo-0301.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\")\n",
    "    elif model == \"gpt-4\":\n",
    "        #print(\"Warning: gpt-4 may change over time. Returning num tokens assuming gpt-4-0314.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-4-0314\")\n",
    "    elif model == \"gpt-3.5-turbo-0301\":\n",
    "        tokens_per_message = 4  # every message follows <|start|>{role/name}\\n{content}<|end|>\\n\n",
    "        tokens_per_name = -1  # if there's a name, the role is omitted\n",
    "    elif model == \"gpt-4-0314\":\n",
    "        tokens_per_message = 3\n",
    "        tokens_per_name = 1\n",
    "    else:\n",
    "        raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not implemented for model {model}. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\")\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c66f0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is just one token\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo-0301\")\n",
    "len(encoding.encode('####'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9022a37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy_messages(df_, text_col):\n",
    "    '''Used to determine num tokens in a text column in a dataframe'''\n",
    "    return [ {'role': 'user', 'content': ' '.join(df_[text_col].tolist())} ]\n",
    "\n",
    "\n",
    "# number of samples to sample per category in one iteration (for one data point in dev set)\n",
    "# (determined experimentally based on ChatGPT context window size) - constant\n",
    "to_sample = {\n",
    "    'Sadness': 8, 'Neutral': 6, 'Anger': 4, 'Disgust': 4, 'Fear': 4, 'Hope': 4, 'Surprise': 3, 'Joy': 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf2b4450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Anger', 1: 'Disgust', 2: 'Fear', 3: 'Hope', 4: 'Joy', 5: 'Neutral', 6: 'Sadness', 7: 'Surprise'}\n"
     ]
    }
   ],
   "source": [
    "# target variables\n",
    "label2key = {   \n",
    "    'Anger':    0,\n",
    "    'Disgust':  1,\n",
    "    'Fear':     2,\n",
    "    'Hope':     3,    \n",
    "    'Joy':      4,\n",
    "    'Neutral':  5,\n",
    "    'Sadness':  6,\n",
    "    'Surprise': 7,\n",
    "}\n",
    "key2label = {v: k for k,v in label2key.items()}\n",
    "print(key2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53c985dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Fear', 'Joy', 'Neutral', 'Sadness', 'Disgust', 'Surprise', 'Anger', 'Hope'}\n"
     ]
    }
   ],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY2\")\n",
    "model          = 'gpt-3.5-turbo'\n",
    "labels_set     = set(label2key.keys())\n",
    "clean = re.compile(r'[^a-zA-Z ]+')\n",
    "multi_spaces = re.compile('\\s{2,}')\n",
    "print(labels_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2256419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(emotions: List[str])->List[int]:\n",
    "    '''\n",
    "        Convert list of strings with categories into list of 0s and 1s with length 8 because there are 8 categories;\n",
    "        1 in the i-th position means that this essay belongs to the i-th category as in key2label[i]\n",
    "    '''\n",
    "    res  = [0]*8\n",
    "    idxs = [label2key[e] for e in emotions]    \n",
    "    for idx in idxs:\n",
    "        res[idx] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02a05596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_label(label_):\n",
    "    '''\n",
    "       Verify if label_ contains any of the categories\n",
    "       from the predefined set of labels\n",
    "    '''\n",
    "    label_ = clean.sub(' ', label_)\n",
    "    label_ = multi_spaces.sub(' ', label_).split()\n",
    "    res    = [i for i in label_ if i in labels_set]\n",
    "    res    = sorted(list(set(res)))\n",
    "    return '/'.join(res) if res else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fe25e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_num_tokens(model, messages):\n",
    "    '''Check that there is enough tokens available for a ChatGPT repsonse'''\n",
    "    num_tokens_tiktoken = num_tokens_from_messages(messages, model)\n",
    "    if num_tokens_tiktoken > 3500:\n",
    "        print(f'Number of tokens is {num_tokens_tiktoken} which exceeds 4080')        \n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "@backoff.on_exception(backoff.expo, openai.error.RateLimitError, max_time=10)\n",
    "def get_response(model, messages, temperature=0, max_tokens=None):\n",
    "    '''Send request, return reponse'''\n",
    "    response  = openai.ChatCompletion.create(\n",
    "        model = model,\n",
    "        messages = messages,\n",
    "        temperature = temperature,        # range(0,2), the more the less deterministic / focused\n",
    "        top_p = 1,                        # top probability mass, e.g. 0.1 = only tokens from top 10% proba mass\n",
    "        n = 1,                            # number of chat completions\n",
    "        #max_tokens = max_tokens,          # tokens to return\n",
    "        stream = False,        \n",
    "        stop=None,                        # sequence to stop generation (new line, end of text, etc.)\n",
    "        )\n",
    "    content = response['choices'][0]['message']['content'].strip()\n",
    "    #num_tokens_api = response['usage']['prompt_tokens']\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e92f9572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 - Below you are given examples of essays with categories separated by four hashtags.\n",
      "2 - Each essay has one or two relevant categories from the following list: Sadness, Neutral, Anger, Disgust, Fear, Hope, Surprise, Joy.\n",
      "3 - Your task is to carefully learn from the examples of essays with categories in order to understand what features or words in the essays make them belong to a specific category and then use this knowledge to assign the correct relevant category from the above list to the very last essay.\n",
      "4 - You may add a second category from the above list ONLY AND ONLY IF it is also relevant to the very last essay.\n",
      "5 - Output just the category or categories for the last essay and nothing else. If there are two relevant categories: sort them alphabetically, concatenate with a forward slash, and output only them and nothing else.\n",
      "\n",
      "####\n",
      "\n",
      "Are you sure about that? If yes - repeat the same output, if no - change the category, but make sure it's from the list of predefined categories\n"
     ]
    }
   ],
   "source": [
    "prompt_one = \"\"\"\n",
    "1 - Below you are given examples of essays with categories separated by four hashtags.\n",
    "2 - Each essay has one or two relevant categories from the following list: \\\n",
    "Sadness, Neutral, Anger, Disgust, Fear, Hope, Surprise, Joy.\n",
    "3 - Your task is to carefully learn from the examples of essays with categories in order to understand \\\n",
    "what features or words in the essays make them belong to a specific category and then use \\\n",
    "this knowledge to assign the correct relevant category from the above list to the very last essay.\n",
    "4 - You may add a second category from the above list ONLY AND ONLY IF it is also relevant \\\n",
    "to the very last essay.\n",
    "5 - Output just the category or categories for the last essay and nothing else. If there are two relevant \\\n",
    "categories: sort them alphabetically, concatenate with a forward slash, and output only them and nothing else.\n",
    "\n",
    "####\n",
    "\"\"\"\n",
    "\n",
    "print(prompt_one)\n",
    "\n",
    "# Using followup questions improves the reponse. but ChatGPT can change its mind too easily sometimes\n",
    "followup = \"\"\"Are you sure about that? If yes - repeat the same output, if no - change the category, \\\n",
    "but make sure it's from the list of predefined categories\"\"\"\n",
    "print(followup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5becf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f36fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b16f9f92",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "642d59ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 14:57:22.615269: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(792, 33) (208, 32)\n"
     ]
    }
   ],
   "source": [
    "file1    = 'data/df_train.pkl'\n",
    "df_train = pd.read_pickle(file1)\n",
    "\n",
    "file2    = 'data/df_dev.pkl'\n",
    "df_dev   = pd.read_pickle(file2)\n",
    "\n",
    "print(df_train.shape, df_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e42e2783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_clean_spellchecked</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How sad is it that this kind of pain and suffering, and those kind of living conditions still exist today? what a gap we have in society between developed countries and those that aren't. It's crazy to drive around the US and see all the money people spend on pointless things, and then to think about how the people in Haiti are living.</td>\n",
       "      <td>[Sadness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The article is kind of tragic and hits close to home as I am the son of Haitian immigrants. Haiti has a lot of problems that only become exaggerated during natural disasters. I think what the Haitian people really need from the international community is help developing infrastructure so they can address these issues themselves. Foreign aid only acts as a band aid.</td>\n",
       "      <td>[Sadness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I think that these kinds of stories, are sad, yet inspirational and leave you with kind of a good feeling. Even though his story is sad, it's cool and inspiring/motivational to see that he rose up against his circumstances. That he worked hard to make something of himself and he succeeded in what he wanted to do.</td>\n",
       "      <td>[Sadness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's crazy that random accidents like this happen everyday. I am not a baseball fan but of course enjoy a baseball game every now and again. I lived and worked in Miami too so I am vaguely familiar with that baseball player who unfortunately passed away. The effort to save him was great but unfortunately bad things seem to happen every day. He was so young too so it makes it worse.</td>\n",
       "      <td>[Neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This story makes me so so sad.... As someone who also grew up in the system, I can strongly relate. It's sad that America has not figured out a better and more safe system to handle kid's without parents or with parents who are unfit. A lot of the times, the system is no better, or even worse than the situation kids were in before, and I think this story is a good example of that.</td>\n",
       "      <td>[Sadness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>After reading the article, my first reaction and feeling is that i feel really bad for the brothers. I feel like people their age should not have to be locked inside a jail cell. They should be out in the world improving themselves and being normal people. It's also really sad for the family members of these brothers as well because they are probably all suffering and worrying.</td>\n",
       "      <td>[Sadness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I didn't know coal mining had such adverse effects on the surrounding environment. It has basically ruined the lives of the people who live nearby these mines. And the animal populations too, imagine a heard of elephants not able to sustain themselves with the food available and needing to invade human territory...They must really be in a desperate situation.</td>\n",
       "      <td>[Neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This is very sad. I can't imagine having elephants come stampede my house in the middle of the night. What a terrible and sad situation, and these poor people can't even do anything about it. Someone needs to stop the deforestation and stop polluting the air these people breathe, it is not right that they are doing and all for the sake of turning a profit.</td>\n",
       "      <td>[Sadness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Guys, reading this article really hits home for me. If you or someone you know is having suicidal thoughts, please get help from the available sources. Suicide is no joke and it is a shame when someone does not get the help they need. I've struggled with this for a few years now but I got the help I needed. This woman was not as fortunate.</td>\n",
       "      <td>[Sadness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hey guys. So I just read this article about Iraqi Christians being persecuted by Muslims in Iraq. I don't understand why people of different religious backgrounds can't get along there. I'm sure it is a cultural thing but it is such unnecessary violence and conflict. It hurts both sides and I wish there was a way we could get them to set aside their differences. But not military action. We don't need another war.</td>\n",
       "      <td>[Neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>This was pretty troubling to read about the events going on overseas. The families are struggling so much and there's no hope in sight for them to get any relief. Looking over their backs all the time and trying to protect their children. Trying to maintain work available to support their family. I can't imagine what it would be like.</td>\n",
       "      <td>[Sadness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>This article made me think about something that I have never thought about before. Returning to a place where a war happen is not only the repairing of the physical, but the place may have memories that you may never want to return to. For some reason, I always thought that people would just be able to return when the fighting stopped.</td>\n",
       "      <td>[Neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I hate hearing stories like this... I feel so bad for veterans, not only for what they have to deal with if they were on the battlefield, but because of the lack of respect for them in this country. Even if you don't agree with the war we are fighting, that is not their fault, don't take it out on them, take it out on their leaders.</td>\n",
       "      <td>[Anger]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I just read an article about cancer and how it effects a person. I know how cancer feels; I've dealt with family members getting cancer in my childhood. It was rough. But it takes a lot fo strength to get through the treatments. And I just want to say that if you have cancer, you can do it. you can beat it and get through it. No matter how gloomy the day may be look forward to a brighter tomorrow.</td>\n",
       "      <td>[Hope, Neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>This kind of stuff makes me so sad... I hate cancer... It's crazy, with how far advanced we are that we don't have a better cure for it yet... And that the only \"treatment\" really is pumping poison into your body... I do think that big pharma has something to do with this, because there is so so so much money to be made off of cancer.</td>\n",
       "      <td>[Sadness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>It's so sad that our disregard for the environment since the Industrial Age is having such an effect on the entire planet. The ice melting too soon is going to have such an effect on polar bears and pretty much every animal. I'm not sure what we can possibly do to prevent polar bears from dying out because of a lack of food. They need that ice to hurt seals and without it, they are restricted to what they can hunt on land.</td>\n",
       "      <td>[Sadness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I feel sad that elephants can't even be protected how they should be. The fact that a bid to give them high level protection was defeated tells me that money rules overall and it has been that way and will always be that way and it is something I can not just grasp my head around and accept as a fact of life because it just is not fair.</td>\n",
       "      <td>[Sadness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Any type of animal poaching and killing just really hurts my heart. It is disgusting that this kind of thing is still happening and that not everyone can agree to fiercely protect these gentle giants. I get that these countries are poor and this kind of hunting and trading brings in big money for them but I think they need to look at the bigger picture and more countries should help build these countries up in others ways so they dont have to rely on this for there people and economy. I also agree with the conservationist that say all the paper laws in the world cant cut down on the killings if you dont control illegal trade that is were the focus needs to stay on.</td>\n",
       "      <td>[Disgust]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I wasn't bullied much as a child but I can really sympathize with people who there. You're a lot more narrow minded as a child and getting bullied can make it seem like your entire life is ruined. I think it's a bigger problem now because of technology. Before a child would only get bullied during school hours, hopefully outside of the sight of a teacher. Now children can be bullied 24/7 through technology since everyone has a cell phone and uses social media. It's a hard problem to solve.</td>\n",
       "      <td>[Sadness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>I just read an article about bullying in France. Apparently, the suicide of a 17 year old French girl has caused the country to reevaluate its approach toward bullying. I personally have never experienced intense bullying or ridicule first hand or even second hand. I guess I was a pretty likable kid after all. I think the key to solving problems like this is most definitely inclusion. The reason children feel this way is because they perceive themselves to be absolutely alone.</td>\n",
       "      <td>[Neutral]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Did you read this article? It's so heartbreaking I cannot take it. News stories don't affect me unless there is kids involved and the image of the little girls wandering around calling for her mum and the two children that lost their mother. It's horrific. It's also making me rethink rides like these because you know I love the kali river rapids at Disney which this sounds similar too. Maybe I should just stay away from rides all together. They just aren't safe.</td>\n",
       "      <td>[Fear, Sadness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>I wish there was more details...How did this happen? Did maybe the kid fall off the cliff and when his father tried to save him, he also fell off? Were they running and didn't realize they were able to fall off a cliff? This is just a strange and really sad story. I hope that somebody puts fencing alongside where they fell, so this doesn't happen to anyone else.</td>\n",
       "      <td>[Hope, Sadness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>So I just read an article about how a father and his son died from a fall while hiking because there was a problem with the rescue chopper and they couldn't get to them in time. I think that is completely unacceptable. Why wasn't there a second rescue chopper? Is there no such thing as a back up? The loss of life could have been prevented.</td>\n",
       "      <td>[Anger]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>I just read an article about suicides in children between 10 and 14. Even though I as not aware of the recent spike in these types of fatalities, I am aware that they happen. Years ago when I was visiting my relatives in OK there was buzz around the town about a boy of only 12 that hung himself after he was punished by his father for misbehaving. To think of someone that young taking their own life is absolutely heartbreaking.</td>\n",
       "      <td>[Sadness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>It's pretty heartbreaking to hear and read stories about suicide. I have always felt like there is more that can be done for mental health with young and older people these days. It's not only the youth that struggle with it but it seems so normalized at a younger age. I feel strongly that there is no excuse for someone to kill themselves. Anything can be prevented and anyone can be helped. It's a hard time and age though and usually those kids feel like there is nothing left for them to live for when in reality they have an entire wonderful life ahead of themselves, regardless of past experiences. But that's just my opinion.</td>\n",
       "      <td>[Sadness]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             essay_clean_spellchecked  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                   How sad is it that this kind of pain and suffering, and those kind of living conditions still exist today? what a gap we have in society between developed countries and those that aren't. It's crazy to drive around the US and see all the money people spend on pointless things, and then to think about how the people in Haiti are living.   \n",
       "1                                                                                                                                                                                                                                                                                                                     The article is kind of tragic and hits close to home as I am the son of Haitian immigrants. Haiti has a lot of problems that only become exaggerated during natural disasters. I think what the Haitian people really need from the international community is help developing infrastructure so they can address these issues themselves. Foreign aid only acts as a band aid.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                          I think that these kinds of stories, are sad, yet inspirational and leave you with kind of a good feeling. Even though his story is sad, it's cool and inspiring/motivational to see that he rose up against his circumstances. That he worked hard to make something of himself and he succeeded in what he wanted to do.   \n",
       "3                                                                                                                                                                                                                                                                                                    It's crazy that random accidents like this happen everyday. I am not a baseball fan but of course enjoy a baseball game every now and again. I lived and worked in Miami too so I am vaguely familiar with that baseball player who unfortunately passed away. The effort to save him was great but unfortunately bad things seem to happen every day. He was so young too so it makes it worse.   \n",
       "4                                                                                                                                                                                                                                                                                                     This story makes me so so sad.... As someone who also grew up in the system, I can strongly relate. It's sad that America has not figured out a better and more safe system to handle kid's without parents or with parents who are unfit. A lot of the times, the system is no better, or even worse than the situation kids were in before, and I think this story is a good example of that.   \n",
       "5                                                                                                                                                                                                                                                                                                        After reading the article, my first reaction and feeling is that i feel really bad for the brothers. I feel like people their age should not have to be locked inside a jail cell. They should be out in the world improving themselves and being normal people. It's also really sad for the family members of these brothers as well because they are probably all suffering and worrying.   \n",
       "6                                                                                                                                                                                                                                                                                                                           I didn't know coal mining had such adverse effects on the surrounding environment. It has basically ruined the lives of the people who live nearby these mines. And the animal populations too, imagine a heard of elephants not able to sustain themselves with the food available and needing to invade human territory...They must really be in a desperate situation.   \n",
       "7                                                                                                                                                                                                                                                                                                                              This is very sad. I can't imagine having elephants come stampede my house in the middle of the night. What a terrible and sad situation, and these poor people can't even do anything about it. Someone needs to stop the deforestation and stop polluting the air these people breathe, it is not right that they are doing and all for the sake of turning a profit.   \n",
       "8                                                                                                                                                                                                                                                                                                                                               Guys, reading this article really hits home for me. If you or someone you know is having suicidal thoughts, please get help from the available sources. Suicide is no joke and it is a shame when someone does not get the help they need. I've struggled with this for a few years now but I got the help I needed. This woman was not as fortunate.   \n",
       "9                                                                                                                                                                                                                                                                    Hey guys. So I just read this article about Iraqi Christians being persecuted by Muslims in Iraq. I don't understand why people of different religious backgrounds can't get along there. I'm sure it is a cultural thing but it is such unnecessary violence and conflict. It hurts both sides and I wish there was a way we could get them to set aside their differences. But not military action. We don't need another war.   \n",
       "10                                                                                                                                                                                                                                                                                                                                                   This was pretty troubling to read about the events going on overseas. The families are struggling so much and there's no hope in sight for them to get any relief. Looking over their backs all the time and trying to protect their children. Trying to maintain work available to support their family. I can't imagine what it would be like.   \n",
       "11                                                                                                                                                                                                                                                                                                                                                  This article made me think about something that I have never thought about before. Returning to a place where a war happen is not only the repairing of the physical, but the place may have memories that you may never want to return to. For some reason, I always thought that people would just be able to return when the fighting stopped.   \n",
       "12                                                                                                                                                                                                                                                                                                                                                     I hate hearing stories like this... I feel so bad for veterans, not only for what they have to deal with if they were on the battlefield, but because of the lack of respect for them in this country. Even if you don't agree with the war we are fighting, that is not their fault, don't take it out on them, take it out on their leaders.   \n",
       "13                                                                                                                                                                                                                                                                                   I just read an article about cancer and how it effects a person. I know how cancer feels; I've dealt with family members getting cancer in my childhood. It was rough. But it takes a lot fo strength to get through the treatments. And I just want to say that if you have cancer, you can do it. you can beat it and get through it. No matter how gloomy the day may be look forward to a brighter tomorrow.   \n",
       "14                                                                                                                                                                                                                                                                                                                                                   This kind of stuff makes me so sad... I hate cancer... It's crazy, with how far advanced we are that we don't have a better cure for it yet... And that the only \"treatment\" really is pumping poison into your body... I do think that big pharma has something to do with this, because there is so so so much money to be made off of cancer.   \n",
       "15                                                                                                                                                                                                                                                         It's so sad that our disregard for the environment since the Industrial Age is having such an effect on the entire planet. The ice melting too soon is going to have such an effect on polar bears and pretty much every animal. I'm not sure what we can possibly do to prevent polar bears from dying out because of a lack of food. They need that ice to hurt seals and without it, they are restricted to what they can hunt on land.   \n",
       "16                                                                                                                                                                                                                                                                                                                                                 I feel sad that elephants can't even be protected how they should be. The fact that a bid to give them high level protection was defeated tells me that money rules overall and it has been that way and will always be that way and it is something I can not just grasp my head around and accept as a fact of life because it just is not fair.   \n",
       "17  Any type of animal poaching and killing just really hurts my heart. It is disgusting that this kind of thing is still happening and that not everyone can agree to fiercely protect these gentle giants. I get that these countries are poor and this kind of hunting and trading brings in big money for them but I think they need to look at the bigger picture and more countries should help build these countries up in others ways so they dont have to rely on this for there people and economy. I also agree with the conservationist that say all the paper laws in the world cant cut down on the killings if you dont control illegal trade that is were the focus needs to stay on.   \n",
       "18                                                                                                                                                                                     I wasn't bullied much as a child but I can really sympathize with people who there. You're a lot more narrow minded as a child and getting bullied can make it seem like your entire life is ruined. I think it's a bigger problem now because of technology. Before a child would only get bullied during school hours, hopefully outside of the sight of a teacher. Now children can be bullied 24/7 through technology since everyone has a cell phone and uses social media. It's a hard problem to solve.   \n",
       "19                                                                                                                                                                                                  I just read an article about bullying in France. Apparently, the suicide of a 17 year old French girl has caused the country to reevaluate its approach toward bullying. I personally have never experienced intense bullying or ridicule first hand or even second hand. I guess I was a pretty likable kid after all. I think the key to solving problems like this is most definitely inclusion. The reason children feel this way is because they perceive themselves to be absolutely alone.   \n",
       "20                                                                                                                                                                                                                 Did you read this article? It's so heartbreaking I cannot take it. News stories don't affect me unless there is kids involved and the image of the little girls wandering around calling for her mum and the two children that lost their mother. It's horrific. It's also making me rethink rides like these because you know I love the kali river rapids at Disney which this sounds similar too. Maybe I should just stay away from rides all together. They just aren't safe.   \n",
       "21                                                                                                                                                                                                                                                                                                                       I wish there was more details...How did this happen? Did maybe the kid fall off the cliff and when his father tried to save him, he also fell off? Were they running and didn't realize they were able to fall off a cliff? This is just a strange and really sad story. I hope that somebody puts fencing alongside where they fell, so this doesn't happen to anyone else.   \n",
       "22                                                                                                                                                                                                                                                                                                                                              So I just read an article about how a father and his son died from a fall while hiking because there was a problem with the rescue chopper and they couldn't get to them in time. I think that is completely unacceptable. Why wasn't there a second rescue chopper? Is there no such thing as a back up? The loss of life could have been prevented.   \n",
       "23                                                                                                                                                                                                                                                     I just read an article about suicides in children between 10 and 14. Even though I as not aware of the recent spike in these types of fatalities, I am aware that they happen. Years ago when I was visiting my relatives in OK there was buzz around the town about a boy of only 12 that hung himself after he was punished by his father for misbehaving. To think of someone that young taking their own life is absolutely heartbreaking.   \n",
       "24                                          It's pretty heartbreaking to hear and read stories about suicide. I have always felt like there is more that can be done for mental health with young and older people these days. It's not only the youth that struggle with it but it seems so normalized at a younger age. I feel strongly that there is no excuse for someone to kill themselves. Anything can be prevented and anyone can be helped. It's a hard time and age though and usually those kids feel like there is nothing left for them to live for when in reality they have an entire wonderful life ahead of themselves, regardless of past experiences. But that's just my opinion.   \n",
       "\n",
       "            emotion  \n",
       "0         [Sadness]  \n",
       "1         [Sadness]  \n",
       "2         [Sadness]  \n",
       "3         [Neutral]  \n",
       "4         [Sadness]  \n",
       "5         [Sadness]  \n",
       "6         [Neutral]  \n",
       "7         [Sadness]  \n",
       "8         [Sadness]  \n",
       "9         [Neutral]  \n",
       "10        [Sadness]  \n",
       "11        [Neutral]  \n",
       "12          [Anger]  \n",
       "13  [Hope, Neutral]  \n",
       "14        [Sadness]  \n",
       "15        [Sadness]  \n",
       "16        [Sadness]  \n",
       "17        [Disgust]  \n",
       "18        [Sadness]  \n",
       "19        [Neutral]  \n",
       "20  [Fear, Sadness]  \n",
       "21  [Hope, Sadness]  \n",
       "22          [Anger]  \n",
       "23        [Sadness]  \n",
       "24        [Sadness]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = [ 'essay_clean_spellchecked', 'emotion', ]\n",
    "with pd.option_context('display.max_colwidth', None):\n",
    "    display(df_dev[cols].head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd2b0a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fd98217",
   "metadata": {},
   "source": [
    "# Few-Shot Approach 1: concatenate random examples into one long string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a40072c",
   "metadata": {},
   "source": [
    "## 1a. Divide training set into random 208 chunks\n",
    "This is done in a reproducible way - the same random_states are used (exact same results are confirmed in multiple runs)\n",
    "\n",
    "Options:\n",
    "1. Keep double categories when concatenating examples\n",
    "2. 1 essay w/1 category (using explode()) before concatenating examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5283ebc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY2\")\n",
    "model          = 'gpt-3.5-turbo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d87c080f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3157\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Disgust      4\n",
      "Fear         4\n",
      "Hope         4\n",
      "Anger        3\n",
      "Neutral      3\n",
      "Joy          2\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [32, 35, 38, 90, 107, 111, 171, 216, 225, 238, 246, 246, 295, 295, 336, 342, 371, 371, 373, 383, 400, 426, 430, 478, 494, 561, 574, 593, 593, 617, 617, 620, 687, 729]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3110\n",
      "Value counts:\n",
      "Sadness     7\n",
      "Disgust     6\n",
      "Anger       6\n",
      "Neutral     5\n",
      "Fear        4\n",
      "Joy         3\n",
      "Surprise    3\n",
      "Hope        2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [29, 54, 93, 157, 157, 202, 298, 347, 375, 415, 420, 424, 460, 466, 509, 522, 532, 567, 567, 575, 612, 626, 631, 650, 650, 662, 662, 664, 664, 681, 682, 703, 734, 739, 751, 751]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (37, 2)\n",
      "Number of tokens: 3194\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Anger        7\n",
      "Neutral      6\n",
      "Disgust      4\n",
      "Hope         3\n",
      "Fear         3\n",
      "Joy          2\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [0, 9, 9, 11, 19, 23, 42, 49, 64, 113, 118, 127, 150, 156, 164, 193, 294, 313, 313, 355, 402, 409, 436, 462, 479, 493, 519, 577, 700, 712, 731, 740, 746, 746, 749, 749, 769]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3092\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Neutral      5\n",
      "Anger        5\n",
      "Disgust      4\n",
      "Fear         4\n",
      "Hope         2\n",
      "Surprise     2\n",
      "Joy          1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [25, 36, 94, 121, 140, 152, 159, 181, 210, 241, 295, 295, 341, 399, 416, 419, 529, 538, 538, 599, 599, 601, 619, 619, 621, 621, 645, 666, 671, 705, 736, 744, 760, 761]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3057\n",
      "Value counts:\n",
      "Sadness     9\n",
      "Anger       5\n",
      "Hope        4\n",
      "Disgust     4\n",
      "Neutral     4\n",
      "Surprise    4\n",
      "Joy         3\n",
      "Fear        3\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [14, 20, 88, 95, 102, 102, 130, 135, 148, 157, 157, 200, 253, 295, 338, 339, 387, 421, 452, 453, 517, 517, 561, 561, 646, 648, 648, 667, 692, 694, 720, 725, 738, 773, 773, 774]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (37, 2)\n",
      "Number of tokens: 3139\n",
      "Value counts:\n",
      "Sadness     13\n",
      "Disgust      5\n",
      "Fear         4\n",
      "Neutral      4\n",
      "Anger        4\n",
      "Surprise     3\n",
      "Hope         3\n",
      "Joy          1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [109, 111, 124, 126, 187, 201, 207, 208, 278, 280, 308, 311, 321, 321, 321, 329, 355, 358, 388, 389, 527, 527, 530, 530, 536, 570, 599, 606, 642, 643, 643, 653, 681, 732, 763, 772, 790]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3145\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Neutral      6\n",
      "Anger        4\n",
      "Disgust      4\n",
      "Hope         4\n",
      "Fear         3\n",
      "Joy          2\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [1, 29, 45, 59, 103, 103, 117, 187, 209, 213, 213, 228, 251, 299, 319, 322, 343, 377, 379, 405, 405, 438, 485, 491, 528, 542, 561, 592, 618, 688, 708, 714, 714, 739, 743, 787]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3194\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Disgust      5\n",
      "Neutral      4\n",
      "Fear         4\n",
      "Anger        3\n",
      "Joy          3\n",
      "Hope         3\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [21, 32, 32, 102, 102, 107, 107, 111, 153, 187, 192, 192, 203, 207, 217, 222, 235, 343, 343, 355, 367, 376, 378, 451, 468, 512, 534, 561, 561, 595, 595, 705, 705, 743, 743]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3166\n",
      "Value counts:\n",
      "Sadness     13\n",
      "Anger        6\n",
      "Neutral      5\n",
      "Disgust      4\n",
      "Fear         4\n",
      "Surprise     2\n",
      "Joy          2\n",
      "Hope         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [0, 11, 11, 43, 62, 65, 161, 242, 245, 261, 296, 296, 301, 338, 338, 362, 370, 385, 385, 402, 436, 464, 464, 508, 514, 530, 530, 561, 561, 625, 713, 714, 714, 725, 739, 743, 743, 758]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3138\n",
      "Value counts:\n",
      "Anger       7\n",
      "Sadness     7\n",
      "Disgust     5\n",
      "Fear        5\n",
      "Neutral     3\n",
      "Joy         3\n",
      "Surprise    3\n",
      "Hope        3\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [74, 82, 99, 100, 104, 181, 207, 226, 253, 253, 284, 286, 292, 295, 295, 343, 343, 346, 353, 388, 416, 429, 436, 436, 438, 453, 453, 511, 538, 538, 541, 561, 580, 608, 673, 711]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3195\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Anger        8\n",
      "Neutral      4\n",
      "Fear         4\n",
      "Hope         4\n",
      "Disgust      3\n",
      "Surprise     2\n",
      "Joy          1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [22, 32, 32, 40, 68, 92, 107, 107, 117, 132, 150, 189, 189, 197, 197, 209, 276, 276, 294, 327, 346, 355, 432, 434, 440, 453, 458, 463, 481, 501, 546, 561, 565, 575, 615, 695, 773, 773]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3185\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Disgust      6\n",
      "Anger        4\n",
      "Hope         4\n",
      "Joy          3\n",
      "Neutral      3\n",
      "Fear         3\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [35, 84, 139, 139, 169, 177, 200, 200, 207, 253, 270, 278, 283, 315, 315, 338, 343, 346, 351, 354, 354, 384, 403, 436, 438, 472, 472, 479, 479, 522, 556, 561, 573, 588, 604, 668]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (37, 2)\n",
      "Number of tokens: 3126\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Disgust      5\n",
      "Fear         5\n",
      "Neutral      5\n",
      "Hope         3\n",
      "Surprise     3\n",
      "Joy          3\n",
      "Anger        2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [30, 137, 145, 149, 150, 190, 294, 297, 305, 324, 338, 338, 355, 355, 438, 441, 449, 449, 459, 461, 465, 522, 530, 530, 561, 561, 643, 643, 650, 650, 662, 662, 716, 726, 730, 742, 774]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3198\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Neutral      5\n",
      "Anger        5\n",
      "Hope         4\n",
      "Fear         3\n",
      "Joy          3\n",
      "Disgust      3\n",
      "Surprise     3\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [10, 10, 76, 114, 114, 131, 134, 138, 150, 157, 157, 200, 200, 212, 294, 335, 338, 355, 355, 369, 402, 456, 500, 568, 583, 592, 599, 599, 650, 650, 657, 662, 690, 693, 728, 731]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3180\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Anger        5\n",
      "Disgust      5\n",
      "Neutral      4\n",
      "Fear         3\n",
      "Surprise     3\n",
      "Joy          1\n",
      "Hope         1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [32, 89, 101, 101, 102, 102, 107, 107, 125, 157, 187, 204, 289, 293, 310, 331, 343, 343, 381, 398, 406, 469, 489, 589, 589, 605, 622, 622, 681, 714, 714, 731, 740, 748]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3193\n",
      "Value counts:\n",
      "Sadness     15\n",
      "Neutral      4\n",
      "Fear         3\n",
      "Hope         3\n",
      "Disgust      3\n",
      "Surprise     3\n",
      "Joy          2\n",
      "Anger        2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [35, 53, 97, 147, 167, 299, 316, 330, 346, 357, 402, 432, 446, 447, 447, 449, 449, 475, 480, 522, 539, 569, 569, 585, 590, 643, 643, 661, 662, 689, 703, 727, 740, 740, 769]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3149\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Neutral      6\n",
      "Disgust      4\n",
      "Hope         4\n",
      "Anger        4\n",
      "Fear         4\n",
      "Surprise     3\n",
      "Joy          1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [2, 17, 35, 69, 139, 139, 150, 231, 239, 240, 240, 247, 250, 266, 288, 294, 345, 346, 442, 547, 560, 592, 628, 638, 651, 662, 662, 665, 674, 678, 684, 703, 703, 717, 731, 739, 766, 769]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3143\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Anger        5\n",
      "Neutral      5\n",
      "Disgust      4\n",
      "Fear         3\n",
      "Joy          3\n",
      "Hope         2\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [0, 33, 35, 57, 187, 199, 225, 233, 252, 252, 255, 255, 273, 274, 277, 282, 312, 318, 333, 355, 355, 438, 498, 513, 538, 596, 607, 631, 641, 643, 643, 751, 751, 762, 790]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3135\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Neutral      5\n",
      "Disgust      5\n",
      "Fear         4\n",
      "Hope         3\n",
      "Anger        3\n",
      "Joy          3\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [0, 4, 15, 21, 56, 75, 78, 119, 120, 155, 186, 207, 248, 249, 256, 279, 279, 294, 300, 347, 382, 383, 388, 438, 455, 496, 535, 536, 536, 574, 584, 681, 696, 743, 743, 774]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3187\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Neutral      6\n",
      "Anger        5\n",
      "Hope         3\n",
      "Disgust      3\n",
      "Fear         3\n",
      "Surprise     2\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [5, 34, 64, 122, 139, 152, 177, 189, 223, 253, 253, 267, 290, 349, 360, 388, 408, 438, 453, 471, 492, 525, 578, 599, 617, 619, 619, 636, 649, 672, 681, 684, 763, 771, 784]\n",
      "\n",
      "===========================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3196\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Disgust      5\n",
      "Anger        4\n",
      "Fear         4\n",
      "Joy          3\n",
      "Surprise     3\n",
      "Neutral      3\n",
      "Hope         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [14, 29, 37, 38, 50, 94, 102, 102, 111, 151, 181, 181, 215, 269, 375, 375, 388, 416, 438, 467, 504, 553, 561, 561, 593, 593, 608, 619, 619, 627, 703, 740, 786, 791]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (37, 2)\n",
      "Number of tokens: 3170\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Anger        8\n",
      "Hope         4\n",
      "Neutral      4\n",
      "Disgust      3\n",
      "Joy          3\n",
      "Fear         3\n",
      "Surprise     1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [0, 11, 11, 29, 35, 63, 80, 102, 162, 172, 271, 296, 348, 374, 386, 391, 431, 438, 453, 453, 510, 531, 536, 536, 538, 538, 540, 574, 582, 593, 665, 684, 694, 694, 703, 703, 745]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3151\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Anger        6\n",
      "Hope         4\n",
      "Fear         4\n",
      "Neutral      3\n",
      "Surprise     3\n",
      "Joy          3\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [29, 35, 111, 180, 180, 216, 227, 230, 275, 344, 346, 380, 450, 453, 453, 484, 516, 538, 538, 575, 631, 631, 633, 647, 681, 697, 734, 734, 740, 740, 755, 769, 778, 778]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3140\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Anger        6\n",
      "Neutral      4\n",
      "Fear         4\n",
      "Hope         4\n",
      "Joy          3\n",
      "Disgust      3\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [16, 35, 64, 72, 108, 115, 187, 216, 216, 246, 246, 299, 328, 338, 338, 350, 355, 355, 368, 407, 449, 487, 530, 536, 561, 561, 575, 593, 595, 595, 659, 664, 668, 686, 721, 743, 743, 759]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (37, 2)\n",
      "Number of tokens: 3145\n",
      "Value counts:\n",
      "Sadness     13\n",
      "Anger        5\n",
      "Disgust      5\n",
      "Fear         4\n",
      "Neutral      4\n",
      "Hope         3\n",
      "Surprise     2\n",
      "Joy          1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [118, 200, 200, 216, 253, 253, 275, 275, 277, 295, 295, 300, 314, 388, 393, 410, 416, 470, 482, 490, 500, 521, 542, 542, 554, 561, 567, 575, 598, 619, 619, 624, 640, 687, 749, 749, 782]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3088\n",
      "Value counts:\n",
      "Sadness     9\n",
      "Anger       7\n",
      "Disgust     5\n",
      "Neutral     4\n",
      "Hope        3\n",
      "Joy         3\n",
      "Fear        2\n",
      "Surprise    1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [29, 128, 157, 163, 191, 225, 248, 259, 272, 279, 279, 286, 309, 337, 355, 355, 394, 453, 453, 480, 483, 537, 538, 567, 567, 581, 593, 675, 709, 719, 740, 751, 751, 773]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3161\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Disgust      5\n",
      "Neutral      4\n",
      "Hope         4\n",
      "Anger        3\n",
      "Surprise     3\n",
      "Joy          2\n",
      "Fear         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [13, 19, 31, 34, 58, 86, 98, 101, 101, 173, 192, 192, 207, 239, 239, 295, 343, 420, 420, 444, 522, 530, 561, 605, 619, 619, 674, 681, 707, 714, 714, 731, 737, 767]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3200\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Anger        7\n",
      "Disgust      4\n",
      "Fear         4\n",
      "Hope         3\n",
      "Surprise     3\n",
      "Joy          3\n",
      "Neutral      3\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [35, 64, 185, 211, 225, 278, 294, 295, 361, 370, 373, 373, 396, 425, 432, 447, 447, 453, 453, 464, 464, 479, 495, 542, 542, 544, 555, 579, 595, 595, 632, 681, 695, 706, 731, 748, 748, 768]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (39, 2)\n",
      "Number of tokens: 3171\n",
      "Value counts:\n",
      "Sadness     15\n",
      "Neutral      5\n",
      "Fear         4\n",
      "Hope         4\n",
      "Anger        4\n",
      "Surprise     3\n",
      "Disgust      2\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [3, 9, 9, 35, 83, 142, 146, 147, 195, 207, 216, 216, 236, 255, 255, 258, 278, 299, 331, 347, 371, 371, 404, 412, 435, 443, 479, 479, 480, 522, 527, 527, 551, 561, 561, 603, 613, 679, 774]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3148\n",
      "Value counts:\n",
      "Sadness     8\n",
      "Disgust     6\n",
      "Fear        6\n",
      "Anger       5\n",
      "Hope        4\n",
      "Neutral     3\n",
      "Surprise    2\n",
      "Joy         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [29, 52, 87, 101, 101, 120, 141, 144, 149, 149, 253, 253, 338, 338, 370, 388, 453, 453, 476, 526, 530, 556, 561, 561, 599, 599, 610, 617, 617, 621, 621, 631, 694, 694, 703, 718]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3187\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Anger        7\n",
      "Disgust      6\n",
      "Surprise     3\n",
      "Fear         3\n",
      "Neutral      3\n",
      "Joy          3\n",
      "Hope         1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [1, 10, 10, 21, 29, 35, 64, 209, 213, 213, 216, 216, 244, 296, 296, 464, 466, 466, 480, 529, 533, 538, 543, 562, 593, 593, 609, 611, 670, 680, 685, 716, 720, 725, 725, 746]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3121\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Disgust      6\n",
      "Neutral      5\n",
      "Fear         4\n",
      "Hope         3\n",
      "Joy          3\n",
      "Anger        3\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [7, 29, 51, 64, 65, 129, 150, 157, 157, 181, 181, 200, 200, 209, 220, 254, 275, 275, 286, 295, 295, 347, 356, 388, 454, 464, 464, 488, 505, 572, 586, 645, 650, 714, 714, 780]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (37, 2)\n",
      "Number of tokens: 3200\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Neutral      6\n",
      "Anger        5\n",
      "Disgust      5\n",
      "Hope         3\n",
      "Fear         3\n",
      "Surprise     2\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [11, 11, 29, 47, 91, 96, 115, 139, 139, 168, 182, 205, 221, 241, 253, 253, 272, 303, 321, 321, 372, 395, 436, 436, 449, 449, 550, 576, 619, 626, 681, 684, 753, 762, 774, 785, 788]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3139\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Disgust      6\n",
      "Neutral      5\n",
      "Fear         4\n",
      "Joy          3\n",
      "Anger        3\n",
      "Surprise     2\n",
      "Hope         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [69, 157, 157, 209, 319, 323, 355, 355, 359, 410, 464, 468, 477, 496, 536, 561, 561, 614, 617, 617, 639, 643, 647, 668, 671, 696, 714, 731, 735, 743, 743, 749, 751, 751, 759]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3135\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Anger        7\n",
      "Neutral      5\n",
      "Hope         4\n",
      "Disgust      3\n",
      "Fear         2\n",
      "Surprise     2\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [21, 24, 33, 64, 68, 102, 102, 116, 118, 147, 149, 149, 150, 162, 172, 218, 257, 343, 343, 356, 381, 416, 434, 538, 561, 594, 619, 629, 630, 660, 714, 714, 739, 763, 770]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3156\n",
      "Value counts:\n",
      "Sadness     13\n",
      "Disgust      7\n",
      "Anger        4\n",
      "Neutral      4\n",
      "Fear         4\n",
      "Hope         3\n",
      "Surprise     2\n",
      "Joy          1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [32, 35, 107, 107, 115, 157, 171, 187, 216, 216, 250, 262, 330, 371, 371, 390, 428, 477, 477, 499, 509, 527, 527, 534, 558, 564, 615, 618, 643, 704, 714, 714, 743, 743, 772, 773, 773, 779]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3136\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Anger        5\n",
      "Disgust      4\n",
      "Fear         4\n",
      "Joy          3\n",
      "Neutral      3\n",
      "Hope         3\n",
      "Surprise     3\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [38, 67, 157, 157, 183, 216, 216, 232, 234, 266, 278, 290, 354, 371, 371, 417, 432, 438, 445, 479, 479, 510, 514, 514, 542, 542, 637, 643, 643, 681, 691, 724, 739, 773, 773, 778]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (37, 2)\n",
      "Number of tokens: 3163\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Disgust      8\n",
      "Hope         4\n",
      "Fear         4\n",
      "Joy          3\n",
      "Neutral      3\n",
      "Anger        3\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [0, 11, 18, 21, 105, 117, 150, 178, 184, 187, 207, 209, 219, 260, 294, 295, 295, 304, 313, 343, 343, 462, 478, 478, 517, 517, 522, 651, 671, 671, 673, 681, 687, 747, 765, 766, 784]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (37, 2)\n",
      "Number of tokens: 3192\n",
      "Value counts:\n",
      "Sadness     13\n",
      "Disgust      5\n",
      "Anger        4\n",
      "Hope         4\n",
      "Neutral      4\n",
      "Surprise     3\n",
      "Fear         2\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [0, 11, 26, 139, 139, 161, 239, 239, 253, 253, 272, 277, 281, 290, 291, 330, 334, 366, 378, 406, 430, 433, 438, 449, 449, 462, 500, 513, 541, 559, 561, 561, 621, 621, 643, 643, 733]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (33, 2)\n",
      "Number of tokens: 3134\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Anger        5\n",
      "Disgust      4\n",
      "Surprise     3\n",
      "Fear         3\n",
      "Neutral      3\n",
      "Joy          2\n",
      "Hope         1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [14, 29, 32, 107, 107, 123, 171, 187, 237, 352, 360, 406, 438, 472, 472, 492, 501, 501, 503, 509, 520, 538, 538, 557, 571, 619, 619, 626, 674, 674, 699, 709, 720]\n",
      "\n",
      "===========================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3148\n",
      "Value counts:\n",
      "Sadness     13\n",
      "Disgust      5\n",
      "Neutral      4\n",
      "Anger        4\n",
      "Fear         4\n",
      "Joy          3\n",
      "Hope         2\n",
      "Surprise     1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [32, 37, 107, 107, 135, 146, 149, 157, 157, 253, 253, 263, 295, 295, 319, 325, 344, 377, 388, 491, 524, 527, 546, 561, 561, 593, 593, 643, 655, 657, 723, 734, 751, 751, 754, 783]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (37, 2)\n",
      "Number of tokens: 3143\n",
      "Value counts:\n",
      "Sadness     13\n",
      "Anger        6\n",
      "Neutral      5\n",
      "Fear         4\n",
      "Disgust      3\n",
      "Hope         3\n",
      "Joy          2\n",
      "Surprise     1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [47, 80, 80, 109, 180, 180, 216, 216, 225, 264, 285, 300, 331, 354, 355, 355, 371, 371, 373, 398, 402, 436, 436, 450, 525, 620, 643, 650, 650, 652, 662, 674, 689, 763, 783, 786, 790]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3158\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Hope         5\n",
      "Anger        5\n",
      "Disgust      5\n",
      "Neutral      4\n",
      "Surprise     3\n",
      "Joy          2\n",
      "Fear         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [29, 55, 64, 69, 101, 138, 148, 255, 255, 278, 290, 319, 378, 395, 406, 472, 472, 479, 494, 513, 527, 527, 536, 561, 561, 599, 599, 608, 639, 662, 662, 671, 671, 740, 747, 759, 778, 778]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (39, 2)\n",
      "Number of tokens: 3200\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Anger        7\n",
      "Fear         6\n",
      "Neutral      5\n",
      "Disgust      4\n",
      "Hope         3\n",
      "Surprise     2\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [38, 46, 99, 104, 149, 150, 155, 157, 157, 213, 214, 221, 239, 253, 284, 338, 338, 341, 388, 402, 436, 436, 514, 514, 542, 542, 544, 578, 595, 595, 662, 703, 703, 734, 734, 743, 743, 767, 774]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3151\n",
      "Value counts:\n",
      "Sadness     9\n",
      "Neutral     6\n",
      "Anger       6\n",
      "Disgust     5\n",
      "Hope        5\n",
      "Surprise    4\n",
      "Fear        2\n",
      "Joy         1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [32, 32, 51, 107, 108, 131, 187, 192, 225, 250, 341, 354, 354, 362, 373, 373, 406, 434, 477, 477, 511, 511, 536, 536, 564, 578, 632, 678, 681, 694, 694, 705, 705, 717, 725, 725, 739, 750]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (37, 2)\n",
      "Number of tokens: 3184\n",
      "Value counts:\n",
      "Sadness     7\n",
      "Anger       7\n",
      "Neutral     6\n",
      "Disgust     4\n",
      "Fear        4\n",
      "Joy         4\n",
      "Hope        3\n",
      "Surprise    2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [1, 9, 10, 10, 29, 35, 66, 112, 117, 157, 157, 167, 191, 192, 192, 209, 229, 279, 287, 295, 453, 453, 480, 497, 511, 532, 617, 617, 692, 694, 694, 714, 720, 727, 751, 759, 774]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3165\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Neutral      5\n",
      "Surprise     4\n",
      "Anger        4\n",
      "Joy          3\n",
      "Disgust      3\n",
      "Fear         3\n",
      "Hope         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [7, 14, 21, 29, 36, 84, 111, 120, 152, 155, 171, 216, 239, 239, 256, 286, 290, 408, 436, 436, 438, 457, 467, 522, 641, 650, 650, 674, 674, 711, 712, 714, 714, 774, 790]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (37, 2)\n",
      "Number of tokens: 3174\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Disgust      5\n",
      "Neutral      5\n",
      "Anger        4\n",
      "Fear         4\n",
      "Surprise     3\n",
      "Hope         2\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [1, 4, 7, 29, 34, 37, 55, 102, 102, 137, 152, 181, 216, 234, 243, 295, 295, 311, 371, 401, 555, 593, 593, 613, 614, 624, 643, 643, 664, 664, 687, 696, 746, 746, 773, 778, 778]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (30, 2)\n",
      "Number of tokens: 3154\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Neutral      4\n",
      "Anger        4\n",
      "Disgust      3\n",
      "Joy          3\n",
      "Hope         3\n",
      "Surprise     2\n",
      "Fear         1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [14, 35, 102, 110, 111, 151, 163, 207, 276, 315, 325, 343, 352, 354, 355, 355, 424, 438, 471, 554, 567, 593, 691, 694, 694, 725, 725, 740, 767, 769]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (40, 2)\n",
      "Number of tokens: 3149\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Neutral      6\n",
      "Disgust      5\n",
      "Anger        5\n",
      "Hope         4\n",
      "Surprise     4\n",
      "Fear         3\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [21, 32, 32, 39, 96, 107, 107, 133, 150, 157, 157, 162, 169, 173, 235, 252, 252, 278, 350, 379, 439, 441, 447, 449, 449, 522, 555, 569, 569, 615, 643, 643, 645, 673, 703, 725, 725, 746, 746, 774]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3161\n",
      "Value counts:\n",
      "Sadness     8\n",
      "Anger       7\n",
      "Fear        4\n",
      "Disgust     4\n",
      "Neutral     4\n",
      "Surprise    3\n",
      "Hope        3\n",
      "Joy         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [57, 121, 134, 149, 149, 157, 200, 207, 276, 276, 313, 338, 365, 402, 438, 454, 459, 500, 522, 527, 527, 538, 538, 542, 561, 568, 657, 664, 670, 707, 725, 746, 746, 748, 748]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3141\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Neutral      5\n",
      "Fear         4\n",
      "Anger        4\n",
      "Disgust      4\n",
      "Hope         3\n",
      "Surprise     3\n",
      "Joy          3\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [32, 32, 35, 44, 49, 107, 107, 111, 121, 157, 157, 194, 200, 200, 273, 285, 295, 361, 375, 379, 487, 527, 527, 535, 536, 536, 552, 592, 599, 606, 613, 614, 618, 650, 650, 671, 671, 725]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3157\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Neutral      6\n",
      "Anger        4\n",
      "Disgust      4\n",
      "Joy          3\n",
      "Hope         3\n",
      "Surprise     3\n",
      "Fear         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [29, 77, 101, 101, 108, 149, 149, 166, 187, 196, 200, 239, 239, 247, 278, 314, 319, 347, 350, 352, 358, 358, 447, 447, 449, 453, 453, 489, 527, 527, 561, 561, 654, 668, 681, 785]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (31, 2)\n",
      "Number of tokens: 3089\n",
      "Value counts:\n",
      "Sadness     9\n",
      "Hope        5\n",
      "Fear        5\n",
      "Anger       4\n",
      "Disgust     4\n",
      "Neutral     2\n",
      "Surprise    1\n",
      "Joy         1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [14, 29, 64, 102, 102, 106, 149, 149, 196, 200, 223, 239, 338, 338, 425, 449, 449, 556, 556, 604, 617, 631, 651, 672, 713, 726, 740, 740, 746, 746, 769]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (33, 2)\n",
      "Number of tokens: 3179\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Fear         4\n",
      "Hope         4\n",
      "Anger        4\n",
      "Surprise     3\n",
      "Neutral      3\n",
      "Disgust      3\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [54, 191, 239, 255, 255, 272, 295, 295, 298, 298, 346, 373, 373, 383, 402, 420, 517, 517, 527, 527, 541, 569, 569, 619, 694, 694, 726, 732, 739, 746, 746, 751, 751]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3153\n",
      "Value counts:\n",
      "Sadness     9\n",
      "Neutral     6\n",
      "Anger       5\n",
      "Disgust     4\n",
      "Fear        4\n",
      "Hope        3\n",
      "Joy         2\n",
      "Surprise    2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [21, 27, 32, 35, 94, 107, 107, 123, 181, 205, 225, 252, 252, 255, 255, 295, 340, 343, 343, 429, 432, 453, 468, 492, 504, 508, 522, 534, 636, 669, 722, 736, 739, 749, 771]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3163\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Disgust      6\n",
      "Anger        4\n",
      "Hope         4\n",
      "Neutral      4\n",
      "Joy          3\n",
      "Fear         3\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [3, 29, 34, 68, 68, 84, 150, 168, 226, 253, 253, 255, 255, 294, 295, 324, 382, 388, 394, 402, 406, 432, 444, 542, 550, 551, 561, 561, 589, 589, 619, 619, 635, 657, 676, 722]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3151\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Anger        6\n",
      "Neutral      4\n",
      "Fear         4\n",
      "Disgust      4\n",
      "Joy          3\n",
      "Hope         3\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [11, 11, 29, 34, 96, 121, 150, 157, 157, 171, 181, 181, 272, 276, 289, 305, 343, 343, 351, 371, 397, 436, 436, 466, 474, 478, 520, 561, 580, 615, 619, 619, 743, 743, 760, 784]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (37, 2)\n",
      "Number of tokens: 3171\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Neutral      5\n",
      "Fear         5\n",
      "Anger        4\n",
      "Hope         3\n",
      "Disgust      3\n",
      "Joy          3\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [15, 35, 101, 101, 119, 150, 163, 173, 207, 253, 255, 255, 275, 295, 295, 338, 343, 343, 360, 361, 386, 388, 402, 435, 449, 449, 511, 518, 530, 530, 572, 593, 599, 599, 619, 715, 768]\n",
      "\n",
      "===========================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3142\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Disgust      6\n",
      "Neutral      5\n",
      "Anger        4\n",
      "Fear         3\n",
      "Joy          2\n",
      "Surprise     2\n",
      "Hope         1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [7, 15, 35, 95, 140, 156, 187, 200, 233, 295, 313, 316, 392, 410, 500, 506, 556, 556, 591, 620, 621, 621, 655, 692, 710, 718, 721, 734, 734, 736, 743, 743, 746, 751, 751]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (33, 2)\n",
      "Number of tokens: 3188\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Neutral      5\n",
      "Disgust      4\n",
      "Anger        4\n",
      "Joy          3\n",
      "Fear         3\n",
      "Hope         2\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [15, 68, 68, 147, 155, 203, 210, 230, 244, 295, 310, 321, 321, 321, 355, 355, 385, 385, 438, 483, 561, 561, 574, 579, 592, 650, 725, 725, 739, 740, 763, 769, 790]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (39, 2)\n",
      "Number of tokens: 3181\n",
      "Value counts:\n",
      "Sadness     15\n",
      "Anger        7\n",
      "Neutral      4\n",
      "Disgust      4\n",
      "Joy          3\n",
      "Surprise     2\n",
      "Fear         2\n",
      "Hope         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [0, 10, 11, 11, 29, 52, 100, 103, 104, 182, 272, 295, 295, 342, 402, 408, 413, 436, 436, 445, 478, 478, 502, 509, 522, 525, 552, 643, 662, 671, 671, 697, 703, 703, 706, 712, 745, 746, 746]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3198\n",
      "Value counts:\n",
      "Sadness     8\n",
      "Anger       7\n",
      "Disgust     6\n",
      "Hope        5\n",
      "Neutral     5\n",
      "Surprise    3\n",
      "Fear        3\n",
      "Joy         1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [20, 80, 80, 150, 179, 187, 239, 239, 263, 294, 295, 402, 420, 420, 453, 453, 490, 529, 532, 553, 574, 592, 603, 617, 617, 624, 631, 631, 643, 643, 645, 646, 664, 664, 694, 694, 767, 789]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (33, 2)\n",
      "Number of tokens: 3189\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Neutral      5\n",
      "Anger        5\n",
      "Hope         4\n",
      "Disgust      4\n",
      "Fear         3\n",
      "Surprise     1\n",
      "Joy          1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [102, 188, 215, 240, 253, 253, 299, 347, 355, 377, 464, 464, 475, 506, 514, 546, 546, 556, 556, 557, 568, 575, 588, 615, 666, 681, 690, 740, 740, 746, 746, 778, 778]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3158\n",
      "Value counts:\n",
      "Sadness     13\n",
      "Disgust      4\n",
      "Hope         4\n",
      "Anger        4\n",
      "Neutral      3\n",
      "Surprise     3\n",
      "Fear         2\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [14, 21, 81, 96, 102, 181, 207, 260, 311, 355, 355, 434, 447, 447, 453, 453, 463, 498, 515, 523, 619, 624, 643, 643, 650, 650, 694, 722, 723, 730, 740, 740, 743, 743, 757]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (39, 2)\n",
      "Number of tokens: 3133\n",
      "Value counts:\n",
      "Sadness     13\n",
      "Disgust      6\n",
      "Anger        5\n",
      "Neutral      5\n",
      "Hope         3\n",
      "Fear         3\n",
      "Surprise     2\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [32, 57, 114, 114, 157, 157, 183, 204, 249, 295, 300, 321, 321, 321, 346, 347, 373, 432, 473, 480, 497, 517, 517, 542, 542, 549, 615, 619, 620, 664, 664, 665, 706, 734, 734, 748, 764, 769, 782]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3148\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Disgust      5\n",
      "Anger        5\n",
      "Hope         4\n",
      "Fear         4\n",
      "Surprise     3\n",
      "Joy          2\n",
      "Neutral      2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [1, 14, 14, 21, 42, 68, 101, 101, 102, 102, 111, 114, 114, 117, 200, 200, 207, 209, 217, 224, 246, 246, 338, 343, 415, 473, 485, 491, 508, 561, 669, 681, 725, 725, 735, 739]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3186\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Neutral      6\n",
      "Anger        4\n",
      "Disgust      4\n",
      "Joy          3\n",
      "Surprise     3\n",
      "Hope         2\n",
      "Fear         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [0, 11, 19, 21, 112, 130, 139, 139, 141, 181, 233, 295, 295, 306, 324, 326, 338, 347, 438, 443, 486, 535, 538, 538, 556, 633, 670, 705, 720, 725, 725, 748, 748, 773]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3101\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Disgust      7\n",
      "Anger        6\n",
      "Neutral      4\n",
      "Surprise     3\n",
      "Joy          3\n",
      "Fear         3\n",
      "Hope         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [6, 29, 51, 74, 111, 135, 157, 157, 177, 187, 252, 252, 259, 268, 296, 296, 367, 402, 449, 449, 485, 503, 565, 591, 612, 613, 643, 643, 714, 720, 740, 746, 746, 748, 748, 751, 767, 777]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3154\n",
      "Value counts:\n",
      "Sadness     8\n",
      "Disgust     6\n",
      "Neutral     5\n",
      "Anger       4\n",
      "Fear        4\n",
      "Surprise    3\n",
      "Hope        2\n",
      "Joy         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [35, 41, 102, 102, 126, 157, 157, 172, 181, 187, 195, 223, 253, 253, 275, 285, 346, 352, 377, 433, 511, 538, 538, 561, 619, 619, 621, 671, 671, 694, 703, 714, 738, 776]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3090\n",
      "Value counts:\n",
      "Sadness     8\n",
      "Neutral     6\n",
      "Fear        4\n",
      "Anger       4\n",
      "Hope        4\n",
      "Joy         3\n",
      "Surprise    3\n",
      "Disgust     3\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [24, 29, 34, 152, 186, 210, 219, 225, 239, 239, 253, 253, 261, 275, 279, 339, 355, 361, 372, 373, 391, 401, 435, 436, 436, 458, 478, 492, 561, 561, 593, 593, 617, 617, 731]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3064\n",
      "Value counts:\n",
      "Sadness     7\n",
      "Disgust     6\n",
      "Neutral     5\n",
      "Anger       5\n",
      "Fear        4\n",
      "Hope        3\n",
      "Surprise    2\n",
      "Joy         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [94, 145, 150, 181, 181, 185, 201, 216, 216, 295, 295, 343, 347, 354, 355, 355, 466, 546, 546, 549, 572, 592, 619, 619, 621, 669, 674, 674, 683, 737, 772, 778, 778, 786]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3182\n",
      "Value counts:\n",
      "Sadness     9\n",
      "Anger       5\n",
      "Neutral     4\n",
      "Disgust     4\n",
      "Fear        4\n",
      "Surprise    3\n",
      "Joy         3\n",
      "Hope        3\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [21, 29, 139, 139, 164, 225, 262, 295, 343, 346, 356, 361, 373, 373, 436, 436, 554, 619, 619, 622, 622, 638, 641, 645, 663, 664, 668, 673, 689, 705, 705, 729, 736, 751, 766]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3185\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Neutral      6\n",
      "Hope         4\n",
      "Disgust      3\n",
      "Surprise     3\n",
      "Fear         3\n",
      "Anger        2\n",
      "Joy          1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [2, 29, 147, 147, 180, 187, 234, 239, 295, 296, 296, 320, 328, 373, 373, 381, 387, 439, 472, 472, 518, 594, 599, 599, 604, 617, 617, 631, 631, 662, 686, 705, 731, 736]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3171\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Fear         5\n",
      "Neutral      5\n",
      "Anger        5\n",
      "Disgust      4\n",
      "Joy          3\n",
      "Hope         2\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [0, 11, 11, 21, 139, 139, 169, 194, 328, 338, 348, 355, 355, 370, 388, 408, 438, 453, 453, 474, 481, 492, 530, 530, 542, 542, 546, 546, 556, 584, 664, 664, 684, 739, 770, 791]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3092\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Disgust      7\n",
      "Neutral      6\n",
      "Anger        4\n",
      "Fear         4\n",
      "Hope         3\n",
      "Surprise     2\n",
      "Joy          1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [25, 34, 80, 80, 87, 117, 185, 209, 236, 276, 285, 287, 295, 298, 315, 347, 368, 378, 402, 482, 523, 530, 530, 542, 565, 619, 621, 621, 647, 699, 703, 703, 714, 725, 725, 746, 746, 757]\n",
      "\n",
      "===========================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of combined df: (32, 2)\n",
      "Number of tokens: 3155\n",
      "Value counts:\n",
      "Sadness     8\n",
      "Anger       6\n",
      "Disgust     4\n",
      "Surprise    3\n",
      "Neutral     3\n",
      "Hope        3\n",
      "Joy         3\n",
      "Fear        2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [147, 157, 157, 169, 207, 279, 295, 295, 300, 321, 321, 321, 348, 396, 402, 436, 522, 525, 538, 538, 609, 617, 617, 643, 705, 705, 706, 714, 714, 715, 766, 776]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (40, 2)\n",
      "Number of tokens: 3147\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Neutral      6\n",
      "Anger        6\n",
      "Hope         5\n",
      "Disgust      5\n",
      "Fear         3\n",
      "Joy          3\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [29, 32, 32, 35, 62, 74, 95, 107, 111, 115, 200, 200, 207, 258, 269, 274, 279, 279, 290, 320, 338, 338, 343, 343, 393, 397, 493, 574, 576, 592, 593, 593, 658, 681, 706, 715, 725, 754, 754, 765]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (32, 2)\n",
      "Number of tokens: 3099\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Neutral      5\n",
      "Anger        4\n",
      "Disgust      3\n",
      "Fear         3\n",
      "Joy          3\n",
      "Hope         2\n",
      "Surprise     1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [14, 14, 19, 35, 43, 87, 102, 102, 103, 157, 170, 187, 246, 295, 295, 310, 358, 358, 360, 377, 381, 434, 440, 458, 480, 487, 546, 615, 705, 734, 734, 769]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (37, 2)\n",
      "Number of tokens: 3170\n",
      "Value counts:\n",
      "Sadness     14\n",
      "Neutral      6\n",
      "Disgust      5\n",
      "Anger        3\n",
      "Joy          3\n",
      "Surprise     2\n",
      "Hope         2\n",
      "Fear         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [44, 132, 150, 161, 189, 189, 223, 315, 331, 355, 355, 368, 405, 405, 411, 430, 436, 493, 505, 515, 561, 561, 591, 599, 635, 643, 643, 681, 687, 705, 705, 714, 736, 743, 743, 748, 748]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (33, 2)\n",
      "Number of tokens: 3132\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Neutral      6\n",
      "Fear         5\n",
      "Anger        3\n",
      "Joy          3\n",
      "Disgust      3\n",
      "Hope         2\n",
      "Surprise     1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [14, 21, 102, 102, 158, 192, 192, 201, 249, 253, 272, 295, 295, 358, 373, 443, 447, 472, 472, 480, 483, 487, 536, 548, 565, 567, 599, 650, 681, 739, 749, 754, 771]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3140\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Fear         5\n",
      "Neutral      4\n",
      "Anger        4\n",
      "Hope         4\n",
      "Disgust      3\n",
      "Joy          3\n",
      "Surprise     3\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [35, 97, 100, 142, 150, 200, 200, 260, 285, 289, 294, 338, 338, 343, 343, 377, 436, 438, 453, 453, 480, 519, 521, 525, 555, 557, 561, 561, 593, 593, 651, 695, 705, 705, 751, 791]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (37, 2)\n",
      "Number of tokens: 3120\n",
      "Value counts:\n",
      "Sadness     8\n",
      "Neutral     5\n",
      "Disgust     5\n",
      "Anger       5\n",
      "Hope        5\n",
      "Fear        4\n",
      "Joy         3\n",
      "Surprise    2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [19, 21, 29, 133, 148, 200, 200, 224, 241, 253, 253, 286, 313, 313, 328, 366, 383, 402, 406, 475, 507, 511, 511, 536, 559, 593, 619, 619, 629, 629, 631, 631, 694, 720, 738, 743, 767]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (39, 2)\n",
      "Number of tokens: 3137\n",
      "Value counts:\n",
      "Sadness     15\n",
      "Neutral      6\n",
      "Anger        5\n",
      "Disgust      4\n",
      "Hope         4\n",
      "Joy          2\n",
      "Surprise     2\n",
      "Fear         1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [29, 32, 32, 80, 80, 84, 102, 128, 129, 137, 138, 139, 185, 186, 193, 228, 236, 371, 390, 522, 536, 536, 567, 567, 606, 619, 619, 662, 662, 674, 681, 686, 703, 703, 721, 749, 749, 755, 778]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (40, 2)\n",
      "Number of tokens: 3187\n",
      "Value counts:\n",
      "Anger       10\n",
      "Sadness      9\n",
      "Hope         5\n",
      "Neutral      5\n",
      "Disgust      3\n",
      "Joy          3\n",
      "Fear         3\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [10, 10, 54, 57, 117, 139, 157, 157, 180, 180, 207, 209, 253, 253, 282, 283, 304, 348, 368, 402, 416, 430, 436, 436, 445, 478, 488, 489, 516, 538, 538, 547, 642, 653, 664, 664, 681, 732, 739, 760]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3160\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Disgust      5\n",
      "Neutral      5\n",
      "Fear         4\n",
      "Anger        3\n",
      "Hope         2\n",
      "Surprise     2\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [10, 35, 46, 108, 119, 151, 165, 187, 235, 263, 299, 321, 321, 321, 330, 338, 338, 371, 371, 449, 479, 479, 497, 530, 530, 631, 681, 692, 692, 746, 759, 767, 773, 773]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3139\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Fear         6\n",
      "Neutral      5\n",
      "Disgust      4\n",
      "Surprise     4\n",
      "Hope         3\n",
      "Anger        2\n",
      "Joy          1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [5, 15, 138, 139, 238, 252, 253, 257, 296, 338, 338, 342, 344, 355, 355, 364, 373, 373, 480, 575, 593, 593, 595, 605, 629, 643, 643, 650, 650, 705, 705, 739, 763, 767, 774, 777]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3168\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Disgust      6\n",
      "Anger        4\n",
      "Neutral      4\n",
      "Hope         3\n",
      "Fear         3\n",
      "Joy          3\n",
      "Surprise     1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [35, 101, 101, 102, 102, 110, 111, 121, 177, 180, 180, 239, 239, 275, 275, 279, 279, 295, 315, 315, 339, 438, 454, 523, 527, 544, 570, 575, 592, 662, 684, 746, 747, 753]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3192\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Anger        5\n",
      "Fear         4\n",
      "Hope         4\n",
      "Neutral      4\n",
      "Disgust      3\n",
      "Surprise     2\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [7, 157, 200, 200, 253, 253, 315, 338, 355, 355, 400, 416, 433, 436, 442, 449, 449, 472, 490, 599, 599, 622, 622, 626, 667, 674, 681, 705, 705, 711, 745, 749, 750, 751, 751, 789]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3135\n",
      "Value counts:\n",
      "Sadness     13\n",
      "Disgust      5\n",
      "Neutral      4\n",
      "Anger        3\n",
      "Surprise     3\n",
      "Hope         3\n",
      "Fear         3\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [67, 68, 80, 80, 131, 135, 207, 216, 239, 239, 245, 255, 255, 343, 343, 346, 371, 379, 383, 397, 436, 438, 561, 561, 567, 583, 619, 619, 692, 692, 704, 740, 740, 744, 778, 778]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (39, 2)\n",
      "Number of tokens: 3142\n",
      "Value counts:\n",
      "Sadness     13\n",
      "Neutral      5\n",
      "Hope         4\n",
      "Surprise     4\n",
      "Anger        4\n",
      "Joy          3\n",
      "Disgust      3\n",
      "Fear         3\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [21, 29, 32, 32, 69, 107, 107, 212, 319, 354, 354, 356, 359, 369, 405, 436, 476, 484, 522, 527, 527, 558, 561, 561, 599, 599, 638, 655, 684, 694, 694, 703, 703, 731, 743, 754, 763, 781, 791]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3159\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Disgust      6\n",
      "Anger        5\n",
      "Fear         4\n",
      "Neutral      4\n",
      "Hope         4\n",
      "Surprise     3\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [0, 0, 21, 65, 138, 150, 178, 201, 235, 239, 293, 299, 315, 315, 318, 343, 343, 345, 346, 382, 410, 436, 436, 464, 464, 466, 466, 480, 561, 561, 643, 643, 694, 694, 720, 755, 769, 775]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (37, 2)\n",
      "Number of tokens: 3186\n",
      "Value counts:\n",
      "Sadness     7\n",
      "Disgust     6\n",
      "Anger       5\n",
      "Neutral     5\n",
      "Surprise    4\n",
      "Hope        4\n",
      "Joy         3\n",
      "Fear        3\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [9, 21, 44, 117, 161, 167, 184, 207, 294, 296, 299, 309, 355, 355, 393, 406, 436, 438, 500, 510, 517, 517, 527, 527, 538, 556, 556, 621, 621, 704, 725, 740, 740, 773, 773, 784, 790]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3104\n",
      "Value counts:\n",
      "Sadness     8\n",
      "Anger       7\n",
      "Neutral     6\n",
      "Fear        4\n",
      "Hope        4\n",
      "Disgust     3\n",
      "Joy         2\n",
      "Surprise    2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [10, 34, 119, 131, 152, 157, 157, 186, 225, 243, 285, 301, 338, 358, 358, 383, 385, 436, 436, 464, 464, 490, 561, 561, 594, 604, 639, 643, 643, 668, 740, 740, 756, 778, 778, 790]\n",
      "\n",
      "===========================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of combined df: (33, 2)\n",
      "Number of tokens: 3184\n",
      "Value counts:\n",
      "Sadness     9\n",
      "Disgust     5\n",
      "Anger       4\n",
      "Hope        4\n",
      "Neutral     4\n",
      "Joy         3\n",
      "Fear        3\n",
      "Surprise    1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [73, 82, 139, 181, 181, 189, 189, 225, 240, 240, 252, 252, 278, 295, 295, 382, 402, 438, 479, 479, 486, 573, 617, 617, 619, 619, 621, 621, 634, 653, 683, 694, 748]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3160\n",
      "Value counts:\n",
      "Sadness     13\n",
      "Neutral      6\n",
      "Anger        5\n",
      "Disgust      5\n",
      "Surprise     3\n",
      "Hope         2\n",
      "Joy          2\n",
      "Fear         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [10, 10, 29, 103, 103, 156, 295, 301, 379, 432, 436, 436, 437, 489, 536, 561, 565, 571, 633, 648, 648, 664, 664, 666, 679, 693, 699, 702, 703, 734, 734, 746, 751, 751, 755, 773, 774, 778]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (33, 2)\n",
      "Number of tokens: 3176\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Anger        5\n",
      "Neutral      5\n",
      "Fear         5\n",
      "Hope         3\n",
      "Surprise     2\n",
      "Disgust      2\n",
      "Joy          1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [0, 0, 37, 64, 146, 225, 252, 318, 343, 343, 346, 349, 413, 416, 429, 441, 448, 480, 530, 530, 555, 561, 566, 595, 595, 609, 617, 617, 626, 667, 683, 743, 743]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3144\n",
      "Value counts:\n",
      "Sadness     9\n",
      "Disgust     6\n",
      "Neutral     5\n",
      "Hope        4\n",
      "Anger       4\n",
      "Surprise    3\n",
      "Joy         2\n",
      "Fear        2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [29, 32, 35, 68, 107, 107, 111, 173, 184, 208, 225, 275, 275, 319, 361, 373, 399, 418, 452, 484, 496, 547, 556, 562, 593, 593, 626, 662, 662, 703, 734, 734, 770, 773, 773]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (39, 2)\n",
      "Number of tokens: 3115\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Neutral      6\n",
      "Anger        5\n",
      "Disgust      5\n",
      "Hope         4\n",
      "Fear         4\n",
      "Surprise     2\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [0, 0, 11, 11, 90, 100, 121, 121, 137, 163, 193, 229, 253, 253, 271, 278, 355, 355, 367, 388, 417, 420, 438, 466, 500, 604, 607, 623, 648, 648, 703, 725, 725, 730, 746, 746, 762, 778, 778]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3149\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Disgust      7\n",
      "Neutral      4\n",
      "Anger        4\n",
      "Surprise     2\n",
      "Joy          2\n",
      "Fear         2\n",
      "Hope         1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [9, 106, 110, 147, 158, 161, 191, 193, 219, 253, 262, 268, 295, 295, 302, 478, 478, 498, 538, 561, 561, 617, 621, 621, 631, 634, 643, 643, 650, 650, 651, 714, 725, 725]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3185\n",
      "Value counts:\n",
      "Sadness     14\n",
      "Disgust      6\n",
      "Neutral      4\n",
      "Fear         4\n",
      "Anger        3\n",
      "Hope         2\n",
      "Surprise     1\n",
      "Joy          1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [14, 101, 101, 102, 140, 191, 246, 253, 253, 261, 343, 349, 372, 373, 373, 408, 438, 440, 448, 477, 477, 562, 643, 648, 648, 672, 705, 705, 712, 731, 734, 736, 751, 751, 773]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3134\n",
      "Value counts:\n",
      "Sadness     9\n",
      "Anger       5\n",
      "Fear        5\n",
      "Neutral     5\n",
      "Disgust     5\n",
      "Joy         3\n",
      "Surprise    1\n",
      "Hope        1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [10, 21, 35, 116, 186, 210, 279, 294, 346, 361, 363, 371, 371, 385, 437, 501, 501, 508, 530, 530, 542, 561, 561, 564, 590, 666, 694, 694, 712, 725, 729, 751, 751, 776]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3194\n",
      "Value counts:\n",
      "Sadness     13\n",
      "Neutral      6\n",
      "Disgust      5\n",
      "Anger        4\n",
      "Fear         4\n",
      "Hope         3\n",
      "Joy          2\n",
      "Surprise     1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [53, 111, 117, 132, 209, 216, 216, 217, 239, 242, 244, 246, 251, 277, 285, 295, 295, 305, 369, 392, 518, 542, 542, 575, 585, 595, 595, 662, 678, 681, 715, 719, 757, 761, 762, 769, 772, 773]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3183\n",
      "Value counts:\n",
      "Sadness     8\n",
      "Anger       7\n",
      "Neutral     6\n",
      "Disgust     4\n",
      "Fear        4\n",
      "Hope        3\n",
      "Surprise    3\n",
      "Joy         3\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [21, 34, 35, 47, 102, 140, 141, 152, 193, 224, 235, 240, 240, 255, 278, 327, 346, 351, 364, 389, 479, 479, 500, 556, 556, 593, 593, 644, 657, 663, 681, 682, 721, 722, 746, 755, 763, 778]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (37, 2)\n",
      "Number of tokens: 3066\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Neutral      6\n",
      "Disgust      5\n",
      "Joy          3\n",
      "Surprise     3\n",
      "Fear         3\n",
      "Hope         3\n",
      "Anger        2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [35, 37, 56, 80, 80, 105, 195, 221, 226, 250, 280, 294, 326, 337, 348, 350, 371, 402, 416, 438, 439, 507, 548, 574, 631, 705, 705, 711, 720, 731, 745, 748, 751, 751, 773, 773, 774]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3189\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Neutral      6\n",
      "Disgust      6\n",
      "Anger        5\n",
      "Hope         3\n",
      "Joy          3\n",
      "Fear         3\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [35, 42, 150, 155, 157, 157, 166, 173, 187, 228, 242, 246, 246, 311, 330, 338, 338, 369, 387, 419, 438, 453, 455, 466, 520, 530, 530, 537, 619, 619, 642, 650, 650, 694, 695, 746, 761, 773]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (39, 2)\n",
      "Number of tokens: 3183\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Anger        6\n",
      "Hope         5\n",
      "Neutral      4\n",
      "Disgust      4\n",
      "Surprise     3\n",
      "Fear         3\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [10, 10, 21, 30, 40, 45, 68, 68, 82, 252, 252, 278, 284, 308, 319, 331, 347, 373, 373, 436, 436, 500, 527, 527, 535, 536, 536, 571, 630, 650, 660, 681, 734, 734, 736, 746, 746, 772, 781]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3126\n",
      "Value counts:\n",
      "Sadness     7\n",
      "Fear        5\n",
      "Neutral     5\n",
      "Disgust     4\n",
      "Hope        4\n",
      "Anger       4\n",
      "Surprise    3\n",
      "Joy         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [10, 32, 80, 80, 93, 150, 159, 203, 279, 279, 295, 295, 319, 346, 383, 438, 489, 508, 513, 575, 619, 619, 643, 643, 650, 650, 705, 705, 751, 751, 760, 778, 778, 780]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (32, 2)\n",
      "Number of tokens: 3091\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Anger        5\n",
      "Neutral      4\n",
      "Fear         3\n",
      "Disgust      3\n",
      "Hope         3\n",
      "Surprise     2\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [21, 64, 110, 114, 114, 117, 121, 121, 125, 132, 209, 216, 216, 217, 230, 253, 371, 377, 382, 402, 459, 514, 514, 538, 538, 554, 561, 700, 739, 740, 740, 754]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (39, 2)\n",
      "Number of tokens: 3180\n",
      "Value counts:\n",
      "Disgust     8\n",
      "Sadness     8\n",
      "Anger       6\n",
      "Hope        5\n",
      "Neutral     4\n",
      "Surprise    3\n",
      "Joy         3\n",
      "Fear        2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [2, 10, 10, 34, 35, 81, 108, 139, 151, 200, 200, 207, 255, 255, 294, 295, 340, 343, 343, 356, 500, 517, 517, 567, 569, 569, 595, 600, 608, 662, 662, 672, 681, 696, 703, 725, 725, 773, 773]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3195\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Disgust      6\n",
      "Neutral      5\n",
      "Anger        4\n",
      "Hope         2\n",
      "Joy          2\n",
      "Fear         2\n",
      "Surprise     1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [94, 147, 147, 179, 181, 181, 262, 268, 274, 338, 347, 357, 385, 397, 402, 501, 553, 554, 561, 561, 563, 601, 618, 648, 693, 705, 705, 725, 741, 746, 778, 783, 786, 787]\n",
      "\n",
      "===========================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3128\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Anger        5\n",
      "Disgust      5\n",
      "Hope         4\n",
      "Fear         3\n",
      "Joy          3\n",
      "Neutral      2\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [21, 34, 54, 127, 128, 152, 177, 189, 189, 198, 256, 278, 299, 346, 352, 355, 355, 375, 375, 386, 438, 458, 472, 504, 527, 593, 617, 617, 664, 664, 694, 694, 726, 731, 751]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (37, 2)\n",
      "Number of tokens: 3178\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Fear         5\n",
      "Anger        5\n",
      "Disgust      4\n",
      "Surprise     3\n",
      "Joy          3\n",
      "Neutral      3\n",
      "Hope         3\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [9, 9, 21, 40, 164, 187, 244, 245, 273, 298, 298, 338, 338, 373, 373, 388, 402, 436, 436, 438, 439, 466, 478, 479, 479, 503, 536, 556, 556, 631, 631, 678, 705, 725, 725, 736, 737]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (33, 2)\n",
      "Number of tokens: 3135\n",
      "Value counts:\n",
      "Sadness     8\n",
      "Neutral     6\n",
      "Fear        5\n",
      "Hope        4\n",
      "Joy         3\n",
      "Anger       3\n",
      "Disgust     3\n",
      "Surprise    1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [8, 50, 70, 106, 111, 126, 138, 157, 191, 197, 200, 200, 253, 253, 266, 272, 282, 292, 338, 338, 402, 487, 538, 538, 557, 613, 643, 681, 703, 736, 767, 772, 776]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3132\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Anger        6\n",
      "Disgust      5\n",
      "Neutral      4\n",
      "Hope         3\n",
      "Joy          2\n",
      "Surprise     2\n",
      "Fear         1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [9, 18, 32, 32, 107, 111, 141, 171, 323, 355, 355, 431, 439, 453, 479, 556, 556, 561, 565, 567, 567, 569, 569, 617, 617, 619, 671, 694, 696, 714, 714, 725, 725, 752]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (39, 2)\n",
      "Number of tokens: 3186\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Anger        7\n",
      "Fear         4\n",
      "Hope         4\n",
      "Disgust      4\n",
      "Neutral      3\n",
      "Surprise     3\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [127, 138, 216, 216, 235, 246, 246, 267, 291, 295, 295, 329, 338, 338, 341, 355, 399, 432, 445, 453, 453, 538, 538, 591, 620, 637, 643, 651, 703, 703, 706, 739, 746, 749, 749, 754, 755, 763, 769]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3192\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Disgust      5\n",
      "Hope         5\n",
      "Neutral      5\n",
      "Anger        4\n",
      "Surprise     3\n",
      "Joy          2\n",
      "Fear         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [0, 7, 21, 32, 32, 87, 127, 138, 139, 139, 150, 165, 217, 217, 222, 253, 295, 295, 313, 347, 393, 405, 405, 432, 476, 478, 478, 479, 479, 522, 551, 571, 661, 671, 699, 703, 703, 731]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (33, 2)\n",
      "Number of tokens: 3156\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Anger        5\n",
      "Fear         5\n",
      "Surprise     3\n",
      "Disgust      3\n",
      "Neutral      3\n",
      "Joy          2\n",
      "Hope         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [12, 34, 35, 94, 134, 253, 295, 304, 316, 324, 328, 347, 388, 405, 450, 522, 530, 543, 556, 556, 561, 567, 592, 610, 615, 623, 669, 698, 705, 716, 751, 751, 774]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3162\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Anger        6\n",
      "Neutral      5\n",
      "Hope         5\n",
      "Fear         4\n",
      "Disgust      4\n",
      "Surprise     2\n",
      "Joy          1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [59, 68, 134, 139, 145, 150, 198, 204, 242, 253, 253, 266, 279, 306, 319, 343, 343, 436, 453, 453, 455, 518, 527, 527, 552, 555, 558, 561, 561, 593, 593, 641, 651, 734, 734, 763, 771, 790]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (33, 2)\n",
      "Number of tokens: 3093\n",
      "Value counts:\n",
      "Sadness     13\n",
      "Anger        5\n",
      "Neutral      4\n",
      "Disgust      4\n",
      "Hope         2\n",
      "Surprise     2\n",
      "Joy          2\n",
      "Fear         1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [75, 87, 91, 102, 102, 126, 157, 213, 253, 276, 309, 346, 349, 355, 355, 362, 381, 389, 402, 406, 423, 433, 472, 472, 479, 564, 617, 619, 666, 714, 734, 734, 787]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3118\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Anger        6\n",
      "Disgust      6\n",
      "Hope         5\n",
      "Neutral      3\n",
      "Fear         3\n",
      "Joy          2\n",
      "Surprise     1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [34, 74, 101, 135, 152, 157, 234, 252, 252, 254, 313, 355, 415, 431, 436, 448, 475, 493, 517, 517, 664, 664, 694, 694, 699, 714, 736, 740, 740, 746, 746, 751, 773, 773, 788, 790]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3166\n",
      "Value counts:\n",
      "Sadness     13\n",
      "Disgust      5\n",
      "Anger        5\n",
      "Neutral      4\n",
      "Hope         3\n",
      "Surprise     2\n",
      "Fear         2\n",
      "Joy          1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [171, 184, 226, 241, 299, 313, 313, 358, 358, 379, 397, 406, 438, 491, 527, 530, 561, 564, 589, 593, 619, 631, 631, 632, 637, 639, 662, 662, 668, 703, 703, 714, 751, 782, 787]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3096\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Disgust      6\n",
      "Neutral      5\n",
      "Fear         4\n",
      "Anger        3\n",
      "Surprise     2\n",
      "Joy          2\n",
      "Hope         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [65, 85, 146, 195, 201, 247, 253, 253, 267, 282, 296, 296, 313, 328, 373, 388, 419, 501, 501, 523, 536, 561, 561, 617, 624, 631, 641, 643, 643, 671, 671, 681, 703, 754, 774]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3119\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Disgust      5\n",
      "Anger        4\n",
      "Fear         4\n",
      "Joy          3\n",
      "Hope         3\n",
      "Neutral      3\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [21, 40, 55, 101, 101, 150, 155, 186, 252, 295, 295, 326, 338, 338, 347, 430, 438, 471, 479, 479, 521, 528, 566, 608, 626, 668, 705, 720, 751, 751, 754, 754, 763, 774]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3112\n",
      "Value counts:\n",
      "Sadness     9\n",
      "Anger       6\n",
      "Neutral     5\n",
      "Disgust     3\n",
      "Hope        3\n",
      "Fear        3\n",
      "Joy         3\n",
      "Surprise    2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [34, 37, 152, 157, 157, 164, 182, 192, 192, 194, 226, 241, 254, 296, 296, 297, 400, 402, 405, 416, 422, 500, 524, 538, 538, 561, 561, 579, 708, 731, 746, 746, 751, 751]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3185\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Neutral      6\n",
      "Anger        5\n",
      "Joy          4\n",
      "Disgust      4\n",
      "Hope         4\n",
      "Surprise     3\n",
      "Fear         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [21, 23, 29, 54, 56, 80, 147, 147, 200, 210, 281, 299, 309, 338, 347, 348, 379, 405, 416, 427, 455, 462, 478, 480, 486, 500, 542, 561, 561, 567, 593, 593, 604, 681, 703, 734, 734, 784]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (32, 2)\n",
      "Number of tokens: 3118\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Neutral      5\n",
      "Anger        4\n",
      "Joy          3\n",
      "Hope         3\n",
      "Surprise     3\n",
      "Disgust      2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [1, 31, 45, 150, 156, 189, 200, 200, 239, 289, 355, 355, 376, 406, 438, 442, 469, 479, 546, 547, 586, 615, 619, 619, 643, 650, 662, 663, 681, 682, 693, 776]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3134\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Disgust      6\n",
      "Neutral      5\n",
      "Fear         4\n",
      "Anger        4\n",
      "Hope         3\n",
      "Surprise     2\n",
      "Joy          1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [11, 48, 81, 113, 120, 168, 181, 200, 216, 216, 218, 224, 230, 233, 290, 315, 315, 321, 321, 321, 338, 338, 371, 402, 436, 542, 561, 574, 592, 646, 680, 683, 687, 725, 725, 765]\n",
      "\n",
      "===========================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3083\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Disgust      7\n",
      "Anger        5\n",
      "Hope         4\n",
      "Neutral      4\n",
      "Surprise     3\n",
      "Fear         2\n",
      "Joy          1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [80, 94, 100, 121, 121, 155, 181, 181, 189, 200, 200, 286, 288, 294, 295, 323, 338, 346, 456, 500, 525, 561, 561, 567, 567, 578, 590, 604, 649, 653, 725, 725, 746, 753, 755, 770]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3159\n",
      "Value counts:\n",
      "Sadness     9\n",
      "Anger       8\n",
      "Disgust     5\n",
      "Fear        3\n",
      "Joy         3\n",
      "Neutral     3\n",
      "Surprise    2\n",
      "Hope        1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [34, 103, 107, 116, 118, 142, 157, 157, 162, 163, 187, 211, 249, 295, 295, 355, 355, 476, 478, 478, 480, 514, 514, 556, 556, 567, 569, 569, 595, 595, 599, 746, 751, 751]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (37, 2)\n",
      "Number of tokens: 3153\n",
      "Value counts:\n",
      "Sadness     13\n",
      "Neutral      5\n",
      "Fear         5\n",
      "Anger        4\n",
      "Surprise     4\n",
      "Disgust      2\n",
      "Joy          2\n",
      "Hope         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [8, 47, 85, 138, 152, 163, 192, 192, 205, 218, 264, 282, 295, 295, 302, 343, 343, 346, 347, 383, 402, 429, 450, 467, 542, 542, 571, 631, 631, 666, 714, 725, 725, 731, 734, 734, 769]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3148\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Neutral      5\n",
      "Disgust      4\n",
      "Hope         4\n",
      "Anger        4\n",
      "Joy          3\n",
      "Surprise     3\n",
      "Fear         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [21, 34, 152, 161, 181, 252, 253, 295, 342, 355, 355, 363, 364, 366, 403, 433, 436, 453, 511, 511, 528, 529, 536, 536, 569, 569, 584, 666, 694, 714, 725, 725, 781, 786, 790]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (37, 2)\n",
      "Number of tokens: 3185\n",
      "Value counts:\n",
      "Anger       8\n",
      "Sadness     8\n",
      "Neutral     5\n",
      "Disgust     4\n",
      "Fear        3\n",
      "Joy         3\n",
      "Hope        3\n",
      "Surprise    3\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [0, 21, 38, 44, 46, 90, 113, 150, 157, 157, 264, 294, 307, 334, 416, 447, 447, 522, 538, 538, 541, 557, 561, 567, 595, 595, 604, 615, 641, 643, 643, 662, 678, 749, 749, 774, 790]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3080\n",
      "Value counts:\n",
      "Sadness     9\n",
      "Anger       6\n",
      "Neutral     5\n",
      "Disgust     3\n",
      "Hope        3\n",
      "Fear        3\n",
      "Joy         3\n",
      "Surprise    2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [35, 100, 149, 157, 157, 166, 198, 207, 238, 264, 338, 346, 385, 385, 392, 416, 438, 479, 479, 508, 509, 528, 551, 585, 599, 617, 617, 618, 736, 739, 740, 754, 754, 765]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3176\n",
      "Value counts:\n",
      "Sadness     7\n",
      "Disgust     6\n",
      "Fear        4\n",
      "Anger       4\n",
      "Hope        4\n",
      "Neutral     4\n",
      "Surprise    3\n",
      "Joy         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [45, 57, 82, 94, 111, 122, 160, 181, 181, 197, 225, 230, 235, 253, 288, 321, 321, 321, 343, 343, 355, 374, 378, 538, 603, 611, 651, 681, 720, 725, 735, 739, 740, 778]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3148\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Anger        5\n",
      "Fear         4\n",
      "Hope         4\n",
      "Disgust      4\n",
      "Neutral      4\n",
      "Joy          1\n",
      "Surprise     1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [6, 32, 32, 107, 107, 138, 187, 195, 207, 213, 233, 241, 252, 279, 280, 315, 343, 343, 410, 457, 469, 503, 553, 637, 668, 681, 683, 705, 705, 720, 734, 734, 751, 751]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3184\n",
      "Value counts:\n",
      "Sadness     9\n",
      "Neutral     6\n",
      "Disgust     5\n",
      "Hope        4\n",
      "Fear        4\n",
      "Surprise    3\n",
      "Joy         3\n",
      "Anger       2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [21, 34, 82, 152, 177, 206, 271, 279, 295, 345, 346, 416, 438, 442, 478, 478, 506, 538, 538, 543, 554, 561, 609, 643, 643, 653, 654, 674, 714, 714, 736, 739, 740, 740, 751, 764]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (32, 2)\n",
      "Number of tokens: 3044\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Hope         5\n",
      "Fear         4\n",
      "Disgust      3\n",
      "Neutral      3\n",
      "Anger        3\n",
      "Joy          2\n",
      "Surprise     1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [14, 19, 32, 92, 107, 107, 187, 212, 220, 223, 295, 295, 338, 338, 345, 380, 521, 530, 530, 621, 631, 631, 650, 681, 693, 696, 705, 705, 736, 749, 749, 777]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (32, 2)\n",
      "Number of tokens: 3080\n",
      "Value counts:\n",
      "Sadness     7\n",
      "Fear        6\n",
      "Disgust     4\n",
      "Neutral     4\n",
      "Hope        4\n",
      "Anger       4\n",
      "Surprise    2\n",
      "Joy         1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [66, 118, 157, 226, 253, 253, 275, 295, 314, 338, 343, 368, 371, 371, 427, 436, 436, 447, 478, 530, 530, 538, 538, 567, 567, 592, 728, 731, 734, 740, 740, 767]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (37, 2)\n",
      "Number of tokens: 3075\n",
      "Value counts:\n",
      "Sadness     15\n",
      "Anger        5\n",
      "Disgust      4\n",
      "Neutral      4\n",
      "Fear         3\n",
      "Surprise     3\n",
      "Joy          2\n",
      "Hope         1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [35, 82, 147, 216, 227, 292, 315, 315, 317, 336, 345, 360, 371, 374, 402, 436, 436, 449, 449, 466, 466, 504, 531, 561, 648, 648, 668, 711, 725, 725, 734, 746, 751, 751, 773, 778, 778]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (37, 2)\n",
      "Number of tokens: 3187\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Anger        6\n",
      "Fear         5\n",
      "Disgust      5\n",
      "Neutral      4\n",
      "Hope         3\n",
      "Surprise     2\n",
      "Joy          1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [8, 67, 103, 103, 138, 157, 157, 216, 216, 334, 338, 338, 340, 359, 371, 371, 373, 373, 375, 375, 434, 457, 556, 593, 593, 614, 650, 650, 725, 740, 743, 743, 772, 773, 773, 775, 788]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3184\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Disgust      5\n",
      "Neutral      5\n",
      "Anger        4\n",
      "Fear         4\n",
      "Joy          3\n",
      "Hope         3\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [10, 25, 120, 124, 207, 210, 248, 273, 338, 340, 347, 355, 355, 392, 408, 411, 438, 450, 465, 506, 530, 530, 536, 536, 538, 542, 542, 595, 595, 613, 631, 631, 660, 673, 681, 683, 731, 779]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (39, 2)\n",
      "Number of tokens: 3149\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Disgust      6\n",
      "Anger        5\n",
      "Neutral      5\n",
      "Hope         4\n",
      "Fear         3\n",
      "Joy          3\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [13, 18, 49, 86, 130, 207, 216, 239, 286, 290, 307, 343, 343, 354, 354, 371, 371, 402, 417, 438, 489, 512, 517, 561, 561, 564, 592, 595, 595, 662, 662, 673, 703, 725, 731, 748, 748, 763, 774]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3185\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Disgust      5\n",
      "Hope         4\n",
      "Fear         4\n",
      "Surprise     4\n",
      "Neutral      4\n",
      "Joy          3\n",
      "Anger        2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [21, 69, 78, 79, 88, 103, 103, 149, 200, 203, 219, 295, 295, 316, 338, 338, 339, 342, 347, 401, 416, 420, 438, 500, 536, 542, 542, 563, 590, 592, 599, 602, 730, 736, 746, 746, 773, 773]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (31, 2)\n",
      "Number of tokens: 3140\n",
      "Value counts:\n",
      "Sadness     8\n",
      "Hope        6\n",
      "Disgust     4\n",
      "Anger       4\n",
      "Joy         3\n",
      "Neutral     3\n",
      "Fear        2\n",
      "Surprise    1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [0, 0, 11, 21, 29, 108, 207, 223, 225, 239, 239, 252, 252, 270, 279, 338, 355, 355, 548, 567, 589, 589, 617, 617, 679, 694, 694, 696, 731, 751, 751]\n",
      "\n",
      "===========================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3181\n",
      "Value counts:\n",
      "Sadness     9\n",
      "Neutral     6\n",
      "Anger       5\n",
      "Disgust     4\n",
      "Fear        3\n",
      "Surprise    3\n",
      "Joy         2\n",
      "Hope        2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [21, 53, 169, 225, 233, 239, 260, 266, 285, 295, 309, 315, 315, 321, 321, 346, 361, 362, 403, 415, 436, 461, 522, 538, 538, 608, 621, 634, 654, 751, 751, 755, 778, 778]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3181\n",
      "Value counts:\n",
      "Sadness     9\n",
      "Anger       7\n",
      "Disgust     4\n",
      "Neutral     4\n",
      "Joy         3\n",
      "Fear        3\n",
      "Surprise    3\n",
      "Hope        3\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [110, 117, 144, 157, 157, 163, 209, 226, 270, 276, 284, 315, 315, 355, 355, 416, 421, 441, 477, 477, 479, 479, 549, 598, 619, 619, 662, 662, 681, 690, 703, 703, 716, 717, 739, 774]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (33, 2)\n",
      "Number of tokens: 3176\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Hope         4\n",
      "Fear         4\n",
      "Neutral      4\n",
      "Disgust      3\n",
      "Joy          2\n",
      "Anger        2\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [9, 9, 21, 32, 34, 50, 103, 107, 107, 110, 140, 146, 152, 218, 239, 239, 252, 295, 295, 329, 465, 575, 620, 631, 658, 662, 662, 691, 714, 731, 753, 774, 790]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3075\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Fear         5\n",
      "Disgust      4\n",
      "Hope         4\n",
      "Anger        3\n",
      "Surprise     3\n",
      "Neutral      3\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [9, 21, 108, 200, 200, 204, 216, 253, 253, 260, 268, 295, 315, 321, 321, 321, 338, 338, 353, 355, 363, 371, 371, 373, 389, 399, 479, 479, 500, 621, 730, 733, 739, 740, 773, 780]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3179\n",
      "Value counts:\n",
      "Sadness     13\n",
      "Disgust      5\n",
      "Neutral      4\n",
      "Anger        3\n",
      "Hope         3\n",
      "Surprise     2\n",
      "Joy          2\n",
      "Fear         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [13, 21, 64, 139, 150, 210, 239, 239, 294, 322, 328, 333, 371, 371, 438, 464, 464, 472, 472, 514, 522, 532, 534, 554, 561, 564, 571, 619, 626, 673, 703, 705, 705, 746]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3148\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Anger        7\n",
      "Neutral      4\n",
      "Disgust      4\n",
      "Hope         3\n",
      "Joy          2\n",
      "Fear         2\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [0, 0, 11, 11, 29, 157, 165, 187, 198, 225, 261, 279, 279, 289, 306, 312, 409, 425, 436, 436, 447, 447, 466, 466, 501, 561, 561, 585, 631, 631, 652, 672, 684, 690, 751, 755]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3141\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Anger        5\n",
      "Neutral      4\n",
      "Joy          4\n",
      "Fear         4\n",
      "Disgust      4\n",
      "Surprise     2\n",
      "Hope         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [11, 11, 14, 14, 29, 34, 44, 75, 102, 102, 125, 152, 157, 157, 180, 180, 189, 208, 211, 315, 315, 320, 346, 402, 438, 449, 449, 479, 488, 500, 515, 554, 688, 693, 760, 766]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3186\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Anger        7\n",
      "Fear         4\n",
      "Hope         4\n",
      "Surprise     3\n",
      "Disgust      3\n",
      "Neutral      2\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [29, 50, 117, 209, 227, 240, 240, 255, 255, 272, 300, 338, 338, 346, 385, 391, 409, 449, 449, 517, 538, 561, 561, 593, 593, 641, 679, 695, 725, 725, 740, 740, 742, 769, 777]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3141\n",
      "Value counts:\n",
      "Sadness     9\n",
      "Anger       7\n",
      "Fear        4\n",
      "Disgust     4\n",
      "Hope        4\n",
      "Neutral     3\n",
      "Surprise    3\n",
      "Joy         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [95, 107, 108, 127, 136, 149, 149, 151, 157, 181, 181, 207, 272, 279, 279, 295, 347, 413, 415, 417, 447, 447, 484, 599, 599, 662, 664, 664, 681, 701, 703, 703, 714, 714, 720, 731]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3113\n",
      "Value counts:\n",
      "Sadness     9\n",
      "Disgust     5\n",
      "Fear        5\n",
      "Anger       5\n",
      "Hope        5\n",
      "Neutral     5\n",
      "Joy         2\n",
      "Surprise    2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [21, 29, 71, 92, 200, 229, 243, 315, 315, 332, 338, 338, 383, 385, 385, 394, 430, 497, 525, 527, 527, 532, 566, 593, 593, 619, 624, 632, 643, 662, 714, 720, 725, 725, 734, 734, 736, 772]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (39, 2)\n",
      "Number of tokens: 3174\n",
      "Value counts:\n",
      "Sadness     9\n",
      "Disgust     6\n",
      "Neutral     6\n",
      "Anger       5\n",
      "Fear        4\n",
      "Hope        4\n",
      "Joy         3\n",
      "Surprise    2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [10, 10, 35, 54, 80, 80, 197, 216, 249, 269, 272, 338, 338, 348, 351, 364, 402, 493, 513, 527, 536, 536, 546, 546, 561, 561, 625, 635, 645, 650, 651, 731, 756, 773, 773, 778, 778, 783, 789]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3121\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Disgust      5\n",
      "Hope         4\n",
      "Neutral      4\n",
      "Anger        4\n",
      "Surprise     3\n",
      "Fear         2\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [0, 9, 9, 47, 63, 150, 253, 253, 295, 295, 310, 370, 423, 436, 485, 500, 508, 536, 536, 542, 561, 561, 587, 589, 592, 595, 595, 622, 622, 696, 705, 725, 725, 743, 772]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3168\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Anger        5\n",
      "Disgust      4\n",
      "Surprise     4\n",
      "Neutral      4\n",
      "Joy          3\n",
      "Hope         3\n",
      "Fear         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [5, 21, 134, 150, 160, 181, 210, 259, 325, 402, 403, 453, 453, 469, 485, 490, 524, 569, 576, 593, 599, 599, 621, 621, 631, 631, 681, 703, 703, 711, 725, 734, 734, 773, 773, 775]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3192\n",
      "Value counts:\n",
      "Sadness     9\n",
      "Anger       7\n",
      "Disgust     4\n",
      "Hope        3\n",
      "Fear        3\n",
      "Surprise    3\n",
      "Joy         3\n",
      "Neutral     3\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [7, 32, 32, 55, 64, 107, 107, 149, 149, 184, 250, 325, 346, 360, 402, 409, 438, 478, 479, 588, 589, 589, 593, 593, 648, 681, 690, 694, 694, 700, 720, 746, 746, 764, 771]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (40, 2)\n",
      "Number of tokens: 3199\n",
      "Value counts:\n",
      "Sadness     9\n",
      "Disgust     7\n",
      "Anger       5\n",
      "Neutral     4\n",
      "Hope        4\n",
      "Fear        4\n",
      "Surprise    4\n",
      "Joy         3\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [27, 29, 36, 113, 117, 139, 203, 209, 216, 234, 238, 242, 248, 279, 279, 286, 371, 371, 378, 402, 464, 464, 596, 616, 643, 643, 681, 710, 714, 714, 725, 725, 734, 734, 736, 739, 743, 743, 773, 773]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3137\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Anger        8\n",
      "Fear         4\n",
      "Hope         4\n",
      "Neutral      3\n",
      "Joy          3\n",
      "Surprise     2\n",
      "Disgust      2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [0, 1, 11, 11, 35, 103, 180, 180, 221, 242, 343, 355, 355, 370, 432, 438, 440, 447, 501, 512, 522, 542, 563, 593, 593, 594, 606, 663, 714, 714, 717, 743, 743, 746, 751, 751]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3141\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Neutral      6\n",
      "Anger        5\n",
      "Surprise     4\n",
      "Fear         3\n",
      "Hope         3\n",
      "Disgust      2\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [47, 90, 117, 149, 180, 180, 214, 239, 239, 278, 290, 292, 388, 402, 406, 418, 422, 475, 478, 478, 500, 522, 557, 561, 561, 614, 625, 627, 650, 650, 694, 712, 725, 725, 736, 787]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3099\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Neutral      5\n",
      "Disgust      5\n",
      "Fear         4\n",
      "Hope         3\n",
      "Anger        3\n",
      "Surprise     2\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [1, 10, 10, 58, 112, 133, 144, 199, 207, 217, 217, 275, 295, 295, 296, 296, 359, 372, 402, 419, 432, 458, 460, 479, 479, 522, 575, 590, 617, 650, 650, 731, 746, 746, 758, 784]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3183\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Disgust      6\n",
      "Anger        5\n",
      "Fear         4\n",
      "Hope         4\n",
      "Surprise     3\n",
      "Neutral      2\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [21, 95, 139, 139, 200, 200, 217, 217, 240, 240, 266, 269, 296, 296, 319, 343, 343, 355, 358, 358, 477, 477, 511, 511, 520, 530, 530, 599, 599, 667, 672, 703, 722, 734, 734, 773, 774, 790]\n",
      "\n",
      "===========================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of combined df: (37, 2)\n",
      "Number of tokens: 3154\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Disgust      6\n",
      "Surprise     4\n",
      "Anger        4\n",
      "Hope         4\n",
      "Neutral      4\n",
      "Joy          2\n",
      "Fear         1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [14, 31, 65, 94, 102, 167, 181, 188, 206, 216, 216, 279, 279, 290, 295, 321, 321, 347, 350, 355, 371, 406, 436, 453, 453, 461, 494, 505, 536, 536, 542, 542, 618, 671, 702, 712, 722]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3145\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Disgust      6\n",
      "Anger        6\n",
      "Joy          3\n",
      "Hope         3\n",
      "Neutral      3\n",
      "Fear         2\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [27, 47, 82, 147, 157, 157, 254, 315, 315, 321, 321, 321, 343, 355, 355, 382, 402, 411, 416, 453, 514, 514, 532, 619, 662, 662, 679, 688, 714, 714, 721, 725, 725, 751, 751, 769]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3142\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Neutral      5\n",
      "Anger        5\n",
      "Fear         5\n",
      "Hope         5\n",
      "Disgust      4\n",
      "Surprise     2\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [2, 25, 35, 48, 70, 152, 157, 157, 253, 253, 338, 338, 346, 369, 376, 446, 453, 453, 472, 478, 495, 536, 536, 575, 585, 590, 592, 610, 633, 643, 662, 662, 694, 722, 726, 746, 752, 776]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3191\n",
      "Value counts:\n",
      "Sadness     13\n",
      "Disgust      5\n",
      "Neutral      4\n",
      "Fear         4\n",
      "Anger        4\n",
      "Joy          3\n",
      "Surprise     3\n",
      "Hope         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [10, 26, 35, 83, 98, 107, 107, 129, 143, 201, 240, 240, 262, 278, 295, 295, 297, 395, 517, 517, 592, 599, 599, 617, 617, 628, 631, 631, 638, 681, 694, 700, 720, 725, 725, 754, 754, 774]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3141\n",
      "Value counts:\n",
      "Sadness     9\n",
      "Anger       7\n",
      "Fear        4\n",
      "Disgust     4\n",
      "Hope        3\n",
      "Surprise    3\n",
      "Neutral     3\n",
      "Joy         1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [25, 32, 32, 33, 71, 107, 107, 157, 185, 192, 200, 216, 216, 275, 286, 338, 346, 371, 371, 457, 479, 515, 538, 538, 554, 564, 579, 593, 593, 604, 626, 645, 690, 725]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3187\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Neutral      5\n",
      "Anger        5\n",
      "Joy          4\n",
      "Fear         4\n",
      "Disgust      4\n",
      "Hope         4\n",
      "Surprise     1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [21, 32, 32, 126, 128, 139, 139, 157, 157, 163, 167, 193, 248, 253, 253, 272, 275, 275, 282, 388, 402, 482, 500, 542, 542, 561, 561, 572, 600, 605, 619, 622, 622, 666, 673, 728, 736, 764]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (33, 2)\n",
      "Number of tokens: 3195\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Anger        7\n",
      "Neutral      4\n",
      "Disgust      4\n",
      "Hope         3\n",
      "Fear         2\n",
      "Surprise     2\n",
      "Joy          1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [111, 157, 206, 212, 217, 240, 240, 248, 303, 321, 358, 358, 402, 416, 420, 439, 457, 534, 538, 538, 557, 617, 617, 631, 631, 643, 643, 671, 686, 709, 714, 743, 763]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3143\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Anger        5\n",
      "Disgust      4\n",
      "Surprise     4\n",
      "Neutral      3\n",
      "Fear         3\n",
      "Hope         3\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [0, 1, 11, 63, 82, 135, 157, 157, 261, 295, 347, 381, 409, 416, 436, 453, 453, 466, 466, 479, 546, 546, 568, 617, 617, 619, 619, 645, 681, 712, 714, 714, 734, 734, 775, 778]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3132\n",
      "Value counts:\n",
      "Anger       9\n",
      "Sadness     8\n",
      "Hope        4\n",
      "Disgust     4\n",
      "Joy         3\n",
      "Neutral     3\n",
      "Fear        3\n",
      "Surprise    2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [21, 26, 29, 34, 64, 114, 114, 117, 149, 152, 157, 157, 181, 200, 209, 255, 255, 276, 276, 288, 297, 319, 338, 338, 447, 447, 496, 510, 521, 523, 527, 593, 593, 671, 671, 708]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (37, 2)\n",
      "Number of tokens: 3163\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Anger        6\n",
      "Disgust      6\n",
      "Neutral      5\n",
      "Fear         3\n",
      "Surprise     3\n",
      "Hope         2\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [10, 11, 11, 16, 43, 45, 100, 105, 139, 139, 174, 213, 213, 252, 252, 295, 295, 343, 343, 441, 453, 453, 463, 480, 504, 561, 561, 573, 599, 599, 608, 662, 690, 696, 711, 715, 739]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3158\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Anger        8\n",
      "Joy          3\n",
      "Disgust      3\n",
      "Neutral      3\n",
      "Fear         3\n",
      "Hope         3\n",
      "Surprise     1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [29, 32, 32, 107, 126, 148, 150, 157, 157, 239, 239, 240, 240, 258, 369, 376, 398, 449, 449, 478, 522, 538, 538, 549, 580, 629, 681, 690, 732, 733, 734, 754, 764, 791]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3077\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Anger        7\n",
      "Fear         5\n",
      "Neutral      4\n",
      "Hope         3\n",
      "Disgust      2\n",
      "Joy          2\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [20, 35, 167, 168, 185, 216, 216, 272, 289, 338, 338, 347, 353, 354, 358, 367, 371, 371, 383, 405, 436, 436, 438, 486, 503, 561, 593, 664, 664, 700, 711, 720, 734, 751, 751]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3110\n",
      "Value counts:\n",
      "Sadness     13\n",
      "Neutral      6\n",
      "Fear         4\n",
      "Anger        4\n",
      "Hope         3\n",
      "Disgust      2\n",
      "Joy          2\n",
      "Surprise     1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [32, 32, 35, 58, 102, 107, 107, 111, 164, 214, 216, 216, 239, 239, 310, 343, 343, 360, 371, 371, 383, 436, 476, 561, 561, 582, 597, 610, 612, 629, 629, 656, 663, 715, 787]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3144\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Disgust      6\n",
      "Anger        5\n",
      "Fear         5\n",
      "Hope         4\n",
      "Surprise     3\n",
      "Neutral      3\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [10, 10, 13, 32, 32, 34, 35, 55, 64, 107, 107, 117, 143, 152, 155, 209, 210, 216, 216, 240, 240, 252, 252, 302, 339, 371, 446, 449, 449, 567, 567, 643, 643, 681, 695, 723, 731, 762]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (37, 2)\n",
      "Number of tokens: 3198\n",
      "Value counts:\n",
      "Sadness     8\n",
      "Anger       6\n",
      "Disgust     5\n",
      "Neutral     4\n",
      "Fear        4\n",
      "Joy         4\n",
      "Hope        4\n",
      "Surprise    2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [10, 10, 21, 22, 35, 86, 94, 107, 107, 114, 114, 123, 143, 239, 253, 253, 279, 279, 295, 299, 355, 388, 430, 432, 436, 436, 525, 542, 542, 559, 654, 692, 692, 732, 739, 748, 773]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3192\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Disgust      7\n",
      "Neutral      6\n",
      "Anger        4\n",
      "Fear         3\n",
      "Hope         2\n",
      "Surprise     2\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [0, 14, 14, 21, 45, 111, 145, 153, 189, 189, 209, 250, 274, 294, 313, 313, 338, 358, 358, 527, 556, 556, 561, 561, 615, 654, 692, 692, 701, 725, 725, 732, 746, 746, 748, 766]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3184\n",
      "Value counts:\n",
      "Sadness     8\n",
      "Anger       7\n",
      "Disgust     5\n",
      "Neutral     5\n",
      "Hope        4\n",
      "Fear        3\n",
      "Surprise    3\n",
      "Joy         1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [14, 14, 27, 35, 69, 73, 95, 102, 103, 118, 207, 343, 343, 427, 432, 453, 453, 468, 484, 500, 529, 530, 546, 546, 556, 556, 575, 590, 593, 598, 604, 654, 662, 685, 774, 783]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3179\n",
      "Value counts:\n",
      "Sadness     14\n",
      "Disgust      5\n",
      "Fear         5\n",
      "Hope         5\n",
      "Neutral      5\n",
      "Anger        2\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [19, 76, 126, 188, 200, 200, 205, 216, 216, 221, 224, 229, 238, 300, 338, 338, 355, 377, 416, 443, 451, 500, 521, 527, 527, 561, 562, 575, 590, 631, 631, 643, 643, 650, 650, 703, 703, 737]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3168\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Anger        6\n",
      "Disgust      4\n",
      "Neutral      4\n",
      "Fear         3\n",
      "Hope         3\n",
      "Surprise     3\n",
      "Joy          1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [3, 21, 64, 157, 163, 213, 213, 216, 216, 225, 280, 295, 342, 347, 371, 371, 373, 373, 416, 453, 480, 511, 551, 584, 610, 627, 636, 645, 665, 671, 671, 689, 721, 723, 731]\n",
      "\n",
      "===========================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3184\n",
      "Value counts:\n",
      "Sadness     8\n",
      "Anger       6\n",
      "Disgust     5\n",
      "Fear        4\n",
      "Neutral     4\n",
      "Hope        3\n",
      "Joy         2\n",
      "Surprise    2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [6, 11, 11, 21, 157, 157, 181, 181, 185, 189, 207, 244, 276, 276, 296, 391, 426, 449, 511, 574, 593, 593, 599, 605, 631, 631, 633, 690, 727, 748, 748, 756, 773, 790]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3185\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Neutral      6\n",
      "Disgust      5\n",
      "Anger        4\n",
      "Fear         3\n",
      "Joy          3\n",
      "Hope         3\n",
      "Surprise     1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [0, 0, 32, 32, 35, 107, 154, 189, 324, 344, 351, 382, 402, 449, 449, 464, 469, 479, 497, 514, 514, 525, 527, 527, 599, 602, 628, 629, 638, 665, 681, 692, 731, 750, 763, 765]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (31, 2)\n",
      "Number of tokens: 3091\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Neutral      6\n",
      "Joy          3\n",
      "Hope         3\n",
      "Surprise     2\n",
      "Anger        2\n",
      "Disgust      2\n",
      "Fear         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [35, 103, 160, 212, 239, 239, 277, 289, 295, 296, 319, 383, 492, 527, 535, 562, 569, 599, 604, 619, 629, 643, 643, 650, 662, 662, 681, 718, 726, 733, 777]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (31, 2)\n",
      "Number of tokens: 3146\n",
      "Value counts:\n",
      "Sadness     8\n",
      "Neutral     5\n",
      "Disgust     4\n",
      "Joy         3\n",
      "Anger       3\n",
      "Surprise    3\n",
      "Hope        3\n",
      "Fear        2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [79, 131, 139, 187, 208, 239, 239, 251, 295, 295, 305, 321, 338, 351, 354, 420, 438, 479, 479, 487, 547, 561, 565, 575, 619, 619, 661, 695, 740, 758, 774]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (33, 2)\n",
      "Number of tokens: 3133\n",
      "Value counts:\n",
      "Sadness     9\n",
      "Neutral     6\n",
      "Fear        5\n",
      "Anger       4\n",
      "Disgust     3\n",
      "Hope        3\n",
      "Joy         2\n",
      "Surprise    1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [13, 14, 14, 102, 107, 107, 135, 218, 253, 255, 255, 259, 272, 295, 388, 401, 438, 449, 449, 453, 459, 501, 501, 528, 541, 636, 702, 732, 734, 752, 774, 784, 787]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (39, 2)\n",
      "Number of tokens: 3182\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Hope         6\n",
      "Anger        5\n",
      "Neutral      5\n",
      "Fear         4\n",
      "Disgust      3\n",
      "Surprise     2\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [82, 139, 139, 157, 157, 222, 239, 239, 253, 253, 331, 345, 355, 383, 406, 461, 472, 472, 483, 536, 536, 537, 559, 561, 583, 621, 621, 631, 631, 633, 654, 714, 731, 736, 746, 754, 755, 778, 778]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (37, 2)\n",
      "Number of tokens: 3122\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Anger        6\n",
      "Neutral      5\n",
      "Disgust      5\n",
      "Fear         4\n",
      "Hope         3\n",
      "Joy          3\n",
      "Surprise     1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [19, 29, 56, 68, 68, 123, 166, 176, 213, 250, 279, 279, 316, 361, 368, 373, 373, 388, 454, 462, 510, 521, 527, 527, 561, 561, 565, 574, 631, 681, 694, 694, 746, 746, 773, 788, 790]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3108\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Neutral      5\n",
      "Fear         4\n",
      "Anger        3\n",
      "Joy          3\n",
      "Hope         3\n",
      "Surprise     3\n",
      "Disgust      3\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [7, 22, 29, 35, 78, 187, 212, 224, 229, 246, 253, 253, 280, 299, 313, 313, 360, 371, 371, 384, 476, 511, 511, 527, 532, 553, 575, 591, 592, 643, 681, 734, 738, 739]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3166\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Fear         5\n",
      "Neutral      5\n",
      "Hope         4\n",
      "Disgust      4\n",
      "Joy          3\n",
      "Anger        3\n",
      "Surprise     3\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [21, 35, 87, 106, 129, 137, 188, 216, 216, 253, 253, 286, 326, 356, 367, 371, 371, 392, 409, 428, 438, 477, 536, 536, 593, 593, 703, 705, 705, 725, 725, 731, 748, 750, 769, 778, 778, 785]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3176\n",
      "Value counts:\n",
      "Sadness     9\n",
      "Anger       5\n",
      "Neutral     5\n",
      "Disgust     4\n",
      "Fear        4\n",
      "Hope        4\n",
      "Surprise    3\n",
      "Joy         1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [26, 62, 75, 94, 98, 121, 121, 158, 181, 181, 207, 239, 253, 271, 295, 295, 306, 313, 340, 346, 355, 383, 405, 405, 445, 480, 520, 547, 561, 575, 608, 632, 652, 739, 774]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3149\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Anger        6\n",
      "Hope         5\n",
      "Neutral      5\n",
      "Fear         3\n",
      "Joy          2\n",
      "Disgust      2\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [24, 34, 36, 40, 61, 85, 150, 157, 157, 202, 211, 253, 253, 259, 378, 406, 438, 451, 453, 453, 468, 536, 536, 538, 538, 577, 603, 617, 628, 738, 740, 740, 758, 778, 778]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (32, 2)\n",
      "Number of tokens: 3155\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Neutral      5\n",
      "Disgust      4\n",
      "Fear         4\n",
      "Hope         3\n",
      "Anger        3\n",
      "Joy          2\n",
      "Surprise     1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [53, 102, 120, 126, 146, 150, 171, 200, 235, 278, 294, 319, 333, 360, 385, 413, 418, 476, 479, 479, 522, 553, 561, 561, 599, 650, 650, 681, 725, 751, 751, 770]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3142\n",
      "Value counts:\n",
      "Sadness     13\n",
      "Anger        6\n",
      "Neutral      4\n",
      "Fear         4\n",
      "Disgust      4\n",
      "Joy          3\n",
      "Surprise     2\n",
      "Hope         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [19, 21, 32, 51, 107, 107, 116, 117, 161, 209, 212, 229, 248, 295, 295, 315, 315, 332, 438, 453, 464, 464, 466, 468, 542, 542, 571, 592, 609, 631, 631, 648, 648, 696, 711, 725, 740, 777]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (33, 2)\n",
      "Number of tokens: 3132\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Anger        7\n",
      "Fear         5\n",
      "Disgust      3\n",
      "Hope         3\n",
      "Surprise     2\n",
      "Neutral      2\n",
      "Joy          1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [7, 14, 14, 31, 99, 176, 253, 253, 277, 295, 336, 340, 355, 355, 388, 436, 436, 536, 536, 538, 538, 592, 648, 648, 664, 664, 692, 692, 697, 748, 751, 770, 773]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3185\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Anger        5\n",
      "Neutral      5\n",
      "Disgust      4\n",
      "Surprise     3\n",
      "Fear         3\n",
      "Hope         3\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [9, 9, 111, 124, 162, 170, 172, 177, 187, 220, 240, 240, 252, 252, 294, 299, 317, 336, 403, 413, 431, 438, 443, 477, 477, 480, 500, 542, 561, 568, 597, 631, 740, 740, 744, 790]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3171\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Fear         4\n",
      "Anger        4\n",
      "Hope         4\n",
      "Disgust      4\n",
      "Neutral      4\n",
      "Surprise     3\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [29, 34, 64, 121, 121, 152, 157, 196, 252, 252, 305, 313, 327, 347, 366, 372, 432, 455, 472, 472, 498, 526, 542, 542, 599, 599, 631, 672, 677, 690, 740, 751, 751, 766, 778, 778]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3149\n",
      "Value counts:\n",
      "Sadness     11\n",
      "Hope         5\n",
      "Disgust      5\n",
      "Fear         5\n",
      "Neutral      4\n",
      "Joy          3\n",
      "Anger        3\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [29, 53, 109, 111, 130, 145, 207, 235, 268, 343, 348, 354, 371, 432, 443, 446, 492, 493, 522, 542, 561, 561, 681, 692, 692, 694, 694, 704, 734, 736, 743, 743, 746, 746, 748, 748, 773, 777]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (32, 2)\n",
      "Number of tokens: 3180\n",
      "Value counts:\n",
      "Sadness     9\n",
      "Anger       5\n",
      "Disgust     4\n",
      "Neutral     4\n",
      "Hope        3\n",
      "Surprise    3\n",
      "Joy         2\n",
      "Fear        2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [38, 103, 141, 157, 157, 248, 270, 276, 276, 296, 296, 355, 355, 388, 432, 445, 464, 497, 500, 530, 561, 564, 566, 574, 619, 691, 725, 725, 734, 740, 751, 751]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3129\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Disgust      7\n",
      "Anger        4\n",
      "Fear         4\n",
      "Surprise     3\n",
      "Hope         3\n",
      "Neutral      2\n",
      "Joy          1\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [35, 139, 149, 149, 153, 196, 199, 217, 217, 253, 253, 383, 464, 464, 490, 500, 501, 501, 561, 563, 584, 589, 616, 650, 655, 705, 714, 716, 720, 725, 725, 731, 743, 743]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (37, 2)\n",
      "Number of tokens: 3198\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Neutral      6\n",
      "Anger        4\n",
      "Hope         4\n",
      "Disgust      3\n",
      "Fear         3\n",
      "Joy          3\n",
      "Surprise     2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [32, 35, 52, 72, 101, 101, 107, 187, 209, 211, 214, 216, 216, 296, 334, 355, 355, 364, 373, 388, 407, 528, 546, 546, 589, 593, 632, 649, 650, 673, 681, 717, 737, 740, 746, 746, 786]\n",
      "\n",
      "===========================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of combined df: (34, 2)\n",
      "Number of tokens: 3166\n",
      "Value counts:\n",
      "Sadness     13\n",
      "Neutral      6\n",
      "Disgust      5\n",
      "Surprise     3\n",
      "Anger        3\n",
      "Hope         2\n",
      "Fear         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [32, 32, 78, 112, 156, 157, 226, 240, 295, 313, 313, 314, 340, 373, 373, 384, 395, 405, 465, 483, 494, 561, 582, 599, 599, 631, 631, 710, 731, 751, 751, 765, 773, 773]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (35, 2)\n",
      "Number of tokens: 3163\n",
      "Value counts:\n",
      "Sadness     12\n",
      "Anger        5\n",
      "Neutral      5\n",
      "Disgust      4\n",
      "Surprise     3\n",
      "Joy          2\n",
      "Fear         2\n",
      "Hope         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [9, 9, 12, 21, 64, 189, 189, 216, 292, 302, 342, 346, 377, 409, 449, 484, 496, 553, 556, 560, 565, 589, 589, 599, 599, 602, 662, 662, 681, 706, 714, 769, 778, 778, 788]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (37, 2)\n",
      "Number of tokens: 3186\n",
      "Value counts:\n",
      "Sadness     9\n",
      "Fear        5\n",
      "Hope        5\n",
      "Anger       4\n",
      "Neutral     4\n",
      "Disgust     4\n",
      "Surprise    3\n",
      "Joy         3\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [26, 29, 38, 47, 104, 139, 139, 157, 157, 181, 181, 207, 222, 225, 239, 239, 242, 271, 343, 343, 364, 383, 398, 453, 478, 479, 479, 493, 536, 580, 591, 592, 605, 626, 681, 731, 774]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (36, 2)\n",
      "Number of tokens: 3144\n",
      "Value counts:\n",
      "Sadness     10\n",
      "Disgust      6\n",
      "Anger        4\n",
      "Hope         4\n",
      "Neutral      4\n",
      "Fear         3\n",
      "Surprise     3\n",
      "Joy          2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [23, 49, 121, 121, 138, 277, 278, 279, 279, 299, 321, 321, 330, 353, 367, 402, 438, 453, 462, 479, 480, 503, 523, 631, 631, 640, 650, 650, 705, 705, 719, 736, 739, 768, 773, 773]\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Size of combined df: (38, 2)\n",
      "Number of tokens: 3146\n",
      "Value counts:\n",
      "Sadness     9\n",
      "Anger       6\n",
      "Disgust     5\n",
      "Fear        4\n",
      "Surprise    4\n",
      "Neutral     4\n",
      "Hope        4\n",
      "Joy         2\n",
      "Name: emotion_no_2nd_neut, dtype: int64\n",
      "Index: [75, 150, 244, 250, 255, 255, 270, 294, 305, 320, 347, 377, 405, 405, 420, 420, 432, 438, 500, 542, 542, 561, 561, 617, 617, 625, 643, 643, 648, 648, 655, 717, 734, 734, 739, 751, 763, 790]\n",
      "\n",
      "===========================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_iter       = df_dev.shape[0]\n",
    "max_tokens     = 3200\n",
    "text_col       = 'essay_clean_spellchecked'\n",
    "emotion_col    = 'emotion_no_2nd_neut'\n",
    "essays_sampled = []\n",
    "example_dfs    = []\n",
    "\n",
    "for i in range(num_iter):\n",
    "    res = []\n",
    "    for idx, (emo, num) in enumerate(to_sample.items()):\n",
    "        temp = df_train.copy().explode(emotion_col)\n",
    "        temp = temp[ ~temp[text_col].isin(essays_sampled) ]\n",
    "        temp = temp[ temp[emotion_col] == emo ]\n",
    "        \n",
    "        # if not enough data to sample, sample from the entire dataframe\n",
    "        if temp.shape[0] < num:\n",
    "            temp = df_train.copy().explode(emotion_col)\n",
    "            temp = temp[ temp[emotion_col] == emo ]\n",
    "\n",
    "        essays     = temp.sample(n=num, random_state=i)[text_col].tolist()\n",
    "        df_sampled = df_train[ df_train[text_col].isin(essays) ][[text_col, emotion_col]]\n",
    "        res.append( df_sampled )\n",
    "        essays_sampled.extend( essays )\n",
    "\n",
    "    df_sampled_combined = pd.concat(res).sample(frac=1, random_state=random_state)\n",
    "    # explode() helps avoide double categories in examples\n",
    "    df_sampled_combined = df_sampled_combined.explode( emotion_col ).sample(frac=1, random_state=random_state)\n",
    "    df_sampled_combined = df_sampled_combined.drop_duplicates()\n",
    "        \n",
    "    # reduce size to fit into the context window by removing overrepresented categories\n",
    "    while num_tokens_from_messages( get_dummy_messages(df_sampled_combined, text_col),\n",
    "                                    model=\"gpt-3.5-turbo-0301\",\n",
    "                                  ) > max_tokens:\n",
    "        df_sampled_combined = df_sampled_combined.sample(frac=1, random_state=i)\n",
    "        size = df_sampled_combined.shape[0]\n",
    "        df_sampled_combined = df_sampled_combined.head(size-1)\n",
    "        \n",
    "        '''\n",
    "        # old way, works worse after explode()\n",
    "        overrepresented = ['Sadness', 'Neutral']\n",
    "        count = 0\n",
    "        while df_sampled_combined.tail(1)[emotion_col].values[0] not in overrepresented:\n",
    "            df_sampled_combined = df_sampled_combined.sample(frac=1, random_state=i)\n",
    "            count += 1\n",
    "            if count >= 100:\n",
    "                break\n",
    "        size = df_sampled_combined.shape[0]\n",
    "        df_sampled_combined = df_sampled_combined.head(size-1)\n",
    "        '''\n",
    "    example_dfs.append( df_sampled_combined )\n",
    "\n",
    "    print('Size of combined df:', df_sampled_combined.shape )\n",
    "    num_tokens = num_tokens_from_messages( get_dummy_messages(df_sampled_combined, text_col),\n",
    "                                           model=\"gpt-3.5-turbo-0301\",\n",
    "                                         )\n",
    "    print('Number of tokens:', num_tokens)\n",
    "    print('Value counts:\\n', df_sampled_combined.explode(emotion_col)[emotion_col].value_counts(),sep='')\n",
    "    print('Index:', sorted(df_sampled_combined.index.tolist()))\n",
    "    print('\\n', '='*75, '\\n', sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a32a9eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean length: 35.78846153846154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(36, 44),\n",
       " (38, 33),\n",
       " (34, 32),\n",
       " (35, 28),\n",
       " (37, 27),\n",
       " (33, 14),\n",
       " (39, 13),\n",
       " (32, 8),\n",
       " (40, 4),\n",
       " (31, 4),\n",
       " (30, 1)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# smallest number of examples?\n",
    "from collections import Counter\n",
    "lengths = [df_.shape[0] for df_ in example_dfs]\n",
    "print('Mean length:', np.mean(lengths))\n",
    "c = Counter(lengths)\n",
    "c.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae63645",
   "metadata": {},
   "source": [
    "This means that having 34-35 essays per one set of examples will ensure that the total number of tokens for this set of examples will not exceed the context window size of 4096 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "60c20543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3630, 3603, 3692, 3565, 3547, 3638, 3631, 3677, 3675, 3625, 3702, 3676, 3621, 3686, 3658, 3672, 3653, 3626, 3626, 3665, 3669, 3668, 3617, 3645, 3647, 3563, 3636, 3705, 3687, 3639, 3680, 3613, 3697, 3624, 3614, 3669, 3625, 3664, 3696, 3598, 3643, 3641, 3667, 3716, 3660, 3681, 3645, 3672, 3588, 3674, 3641, 3649, 3647, 3535, 3645, 3631, 3655, 3641, 3665, 3626, 3652, 3700, 3709, 3653, 3638, 3655, 3637, 3657, 3613, 3628, 3569, 3535, 3660, 3652, 3658, 3602, 3611, 3670, 3552, 3671, 3590, 3624, 3616, 3656, 3714, 3633, 3622, 3644, 3678, 3628, 3656, 3669, 3686, 3595, 3647, 3671, 3635, 3628, 3629, 3632, 3668, 3607, 3701, 3689, 3562, 3697, 3701, 3595, 3545, 3701, 3675, 3609, 3680, 3593, 3612, 3702, 3700, 3619, 3669, 3559, 3612, 3649, 3580, 3590, 3585, 3690, 3570, 3627, 3577, 3635, 3650, 3628, 3683, 3550, 3648, 3621, 3669, 3496, 3531, 3575, 3688, 3693, 3669, 3690, 3586, 3652, 3669, 3640, 3562, 3654, 3643, 3632, 3666, 3628, 3616, 3694, 3608, 3656, 3672, 3722, 3621, 3629, 3591, 3690, 3656, 3639, 3649, 3701, 3616, 3699, 3661, 3633, 3622, 3665, 3634, 3555, 3593, 3656, 3695, 3686, 3673, 3684, 3651, 3656, 3677, 3533, 3591, 3590, 3702, 3621, 3573, 3668, 3656, 3628, 3609, 3650, 3596, 3675, 3660, 3657, 3635, 3605, 3693, 3641, 3645, 3684, 3633, 3654]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# 3.7k to 3.9k tokens per example\n",
    "examples  = []\n",
    "for df_ in example_dfs:\n",
    "    example = prompt_one.strip() + '\\n'\n",
    "    for text, emo in df_[[text_col, emotion_col]].values:\n",
    "        #example += f\"\\nText: {text}\\n\\nCategory: {'/'.join(emo)}.\\n\\n####\\n\"    #w/out explode()\n",
    "        example += f\"\\nEssay: {text}\\n\\nCategory: {emo}.\\n\\n####\\n\"     #w/explode()\n",
    "    examples.append(example)\n",
    "        \n",
    "lengths = [ num_tokens_from_messages([{'role':'user', 'content': example} ]) for example in examples ]\n",
    "print(lengths)\n",
    "print([l for l in lengths if l <3400])\n",
    "print([l for l in lengths if l > 3800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cdf672d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Below you are given examples of essays with categories separated by four hashtags.\n",
      "2 - Each essay has one or two relevant categories from the following list: Sadness, Neutral, Anger, Disgust, Fear, Hope, Surprise, Joy.\n",
      "3 - Your task is to carefully learn from the examples of essays with categories in order to understand what features or words in the essays make them belong to a specific category and then use this knowledge to assign the correct relevant category from the above list to the very last essay.\n",
      "4 - You may add a second category from the above list ONLY AND ONLY IF it is also relevant to the very last essay.\n",
      "5 - Output just the category or categories for the last essay and nothing else. If there are two relevant categories: sort them alphabetically, concatenate with a forward slash, and output only them and nothing else.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: I feel like overall it is quite sad that this happened and it should have been prevented by the proper authorities. I feel like as a people we should do what we can to prevent these things. I feel like the fact that the city reacted well is a good sign. I think they did the right thing in not letting muslims security personnel enter as you have to take all precautions necessary.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: I feel so sorry for the passengers and victims onboard. This would be my worst fear being on a train or plain having no control or way out of such a big accident. They must have been so afraid once the train started rocking back and forth. I wonder what actually caused this horrible accident in the first place. They said that a similar one happened earlier so it must be connected. A full investigation should be done to find the cause and fix it. The train should be shut down to avoid loss of life while it is investigated and corrected. It seems to be a totally avoidable way to lose a life and needs to have more security measures put into place.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: That was a sad story wow that was terrible what happened to that poor dog but then again I hate dogs so I'm glad its one less dog left on this planet if it were up to me I would shoot all the stupid ugly dogs that are out there I can not believe people keep them as pets they should eat them like they do in china\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: Troops killed in Afghanistan always angers because we should no longer be there in the first place. The fact that we are still there says a lot about us as a country. We need to realize that we have no business there anymore and get out. I don't know why we try to be the world police when it clearly does us no good in the long run.\n",
      "\n",
      "Category: Anger.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: When tragedies like the one in Paris happen we must dig down deep and look for proper solutions. I think we need to research what goes through people's heads when they commit crimes like this.It was a little racist for one of them to say muslim security collaborated with the criminals. That was a bad thing to say.\n",
      "\n",
      "Category: Neutral.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: I am writing as regards my thoughts for Polar bears, the poster-child for climate change, are among the animals most affected by the seasonal and year-to-year changes in Arctic sea ice, because they rely on this surface for essential activities such as hunting, traveling and breeding. The researchers recommend that the National Climate Assessment incorporate the timing of spring ice retreat and fall ice advance as measures of climate change in future reports. The study's results currently are used by the International Union for Conservation of Nature's polar bear specialist group, which completes assessments of polar bears and issues the species' conservation status. I am really pleased with this information.\n",
      "\n",
      "Category: Joy.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: When people split up it not only affects them but it affects the kids as well. The kids have to deal with the burden of having to live separate lives between time spent with the mom, and all the time they have to spend with the dad. I feel like this causes a toll on their childhood and they are not the same when they grow up because of it.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: Ehh I never really know what to think about claims like this. On the one hand, her roommates claim that they remember hearing her talk about it at the time. On the other hand, why wait twenty years to bring up an incident that happened that was that disturbing? I think some women are making allegations and accusations just to get attention or for political motivations. Who knows why. People do crazy things for crazy reasons. I'm just really skeptical of a lot of these things I hear and I think the #metoo movement has gotten way out of hand. Sorry, just my two cents.\n",
      "\n",
      "Category: Anger.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: it's crazy how islamic terrorism is still a thing. I mean they are just kidnapping people and using them as shields. I cannot believe this is still going on. There needs to be more done to stop this. This war seems like it will never end. What can be done about it? Who knows at this point. This makes no sense at all.\n",
      "\n",
      "Category: Anger.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: The depravity that goes on in this world is alarming at best. At Busch Gardens, Joseph Anthony Corrao, picked up a flamingo named Pinky and threw her to the ground. Her injuries were so bad that she was euthanized. Pinky was famous for a dance she just did on her own and welcomed visitors sometimes.\n",
      "\n",
      "Category: Neutral.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: It's quite sad what happened to the family. I can't even imagine what everyone is going through especially family members. Losing someone to an accident is something you never expect and something that will hurt for a long time. I felt really sad while reading the article because the children were so young and had so much ahead of them.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: Hey man, this is crazy. I had no idea air pollution causes this much damage to us. Did you know in India it kills almost half a million people per year? That is absolutely insane. Something has to be done about this pollution. I wonder what it is in America? It's probably even worse here than it is there. Some places have real bad air quality.\n",
      "\n",
      "Category: Surprise.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: After reading the article, i felt really bad for the wolf and animals that get hunted in general. I think that there should definitely be some sort of punishment for people who decide to kill animals, especially endangered species of animals just for fun. I think it is so inhumane and twisted that someone can kill a beautiful animal like that with no type of remorse whatsoever.\n",
      "\n",
      "Category: Disgust.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: Jose Fernandez, a pitcher for the Miami Marlins baseball team, was killed in a tragic boating accident. He was only 24 years old when he and two others were found dead near the entrance of Miami Harbor. Coast Guard employees found his boat upside down and found the three victims lifeless nearby following this accident.\n",
      "\n",
      "Category: Neutral.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: it's crazy how islamic terrorism is still a thing. I mean they are just kidnapping people and using them as shields. I cannot believe this is still going on. There needs to be more done to stop this. This war seems like it will never end. What can be done about it? Who knows at this point. This makes no sense at all.\n",
      "\n",
      "Category: Surprise.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: Hey did you hear about that murder suicide that happened the other day? He shares the name as the school principals at the twins school, I really hope there is no correlation. Its really scarey to think you really never know someone. I wonder somedays if my husband will snap on me. I can be a pain in the butt but he works alot and you never know what the future holds\n",
      "\n",
      "Category: Fear.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: I feel for both sides on this one. The police and people are trying to protect the sacred wild life and beings but also the village is probably needing the meat of the animal or the money from selling it as they are a very poor country. I can see being so desperate in a third world country that this would seem like the police are cutting off or taking your only source of livelihood. These poor guys however they are just trying to protect and do what is right they do not deserve to be so violently attacked im suprised they were able to live through such a brutal beating. I hope more is done to help the police but also the village\n",
      "\n",
      "Category: Hope.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: Dear friend, I have just read a story about another police officer shooting. These seem to be happening all the time now and it is very upsetting. I hope that one day something can be done about all of this. It is sad to think about .\n",
      "\n",
      "Category: Hope.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: Articles like this really hit home for me. I think older people should really be protected and watched carefully as this happens alot. Alot suffer from dementia and have no idea what is going on and can get lost very easily. It makes me think if this was my parent or grandparent I would be heartbroken. She was wondering with no coat probaly cold and very scared. I am very thankful that these officers found her before something bad happened to her. I hope she is able to be reunited with her family quickly and they put safeguards in place so it never happends again. May it is to much for the family now and she requires more assistance like a group home.\n",
      "\n",
      "Category: Hope.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: Reading about the attack on Paris that happened years ago brought up a lot of bad feelings and thoughts. I had completely forgotten about it because of how often things like that happen. It makes me upset to think that we are becoming numb to terror attacks in a way. i can only hope that the people affected have found peace and eventually we all will find peace\n",
      "\n",
      "Category: Hope.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: I feel so sorry for the passengers and victims onboard. This would be my worst fear being on a train or plain having no control or way out of such a big accident. They must have been so afraid once the train started rocking back and forth. I wonder what actually caused this horrible accident in the first place. They said that a similar one happened earlier so it must be connected. A full investigation should be done to find the cause and fix it. The train should be shut down to avoid loss of life while it is investigated and corrected. It seems to be a totally avoidable way to lose a life and needs to have more security measures put into place.\n",
      "\n",
      "Category: Fear.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: It's very difficult to fathom living somewhere where airstrikes can take you out at any given moment, regardless of where you are. It really makes me grateful to live in this beautiful nation where we live, America, and to have the freedoms that we have. In this story, the man's eight children lost their father and his wife lost her partner. That is very tragic, and all for a bunch of senseless killing. The US was supporting these airstrikes which is sort of sad. I find the whole situation over there so senseless. IT's like they are all just killing each other nonstop for no valid reason.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: It's very difficult to fathom living somewhere where airstrikes can take you out at any given moment, regardless of where you are. It really makes me grateful to live in this beautiful nation where we live, America, and to have the freedoms that we have. In this story, the man's eight children lost their father and his wife lost her partner. That is very tragic, and all for a bunch of senseless killing. The US was supporting these airstrikes which is sort of sad. I find the whole situation over there so senseless. IT's like they are all just killing each other nonstop for no valid reason.\n",
      "\n",
      "Category: Joy.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: Fires always manage to touch my heart. I have personal experience with this and the fear is still with me to this day. A fire can ravage everything that you have any really leave a person traumatized. A lot of times a person or family will get woken up to loud alarms and smoke out of nowhere and have to pick their most important possessions to save. This is a scary situation!\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: After reading the article, my initial reaction was that i felt really bad for the polar bears. They did not deserve what is happening to them. It is mainly due to climate change and i believe that is caused mostly by human activities. Because of human greed and consumption, we have to make other living things suffer. Because of this, many animals are facing extinction today.\n",
      "\n",
      "Category: Disgust.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: An article like this just make you so glad to live in the united states. Where everything is regulated and we have laws. I can not imagine living in a place where the government and law can do anything they please without consequences. Soldiers raping women burning down houses all with out real cause. Any aid workers and doctors are treated very poorly so theres not enough to go around how does this civilization survive. Crazy how far behind and uncivilized some places still are in 2019. I think more light needs to be shown on this as real people are hurting. Everyone deserves to feel safe in there country.\n",
      "\n",
      "Category: Disgust.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: After reading the article, i felt really bad for the wolf and animals that get hunted in general. I think that there should definitely be some sort of punishment for people who decide to kill animals, especially endangered species of animals just for fun. I think it is so inhumane and twisted that someone can kill a beautiful animal like that with no type of remorse whatsoever.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: I always worried about traveling in an airplane, but the recent news and this article makes me think twice about traveling by train. I feel very sorry of the four people who lost their life and the fifty injuries in the train wreck. I hope they find out what caused the wreck for it does not happen again.\n",
      "\n",
      "Category: Fear.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: This sounds like one of those situations where not much can really be done. It's sad for the animals who are dying and suffering and I feel bad for them. I think this is out of anyone's control and really just an act of nature. Sometimes things like this just happen and it's sad and a tragedy but no one can do anything to fix it. The animals are the ones that suffer. They are in essence having a drought and starving due to it which is really sad.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: This article was just heartbreaking. I just pictured my father working his whole life for us just for a warm and horrible people to come in and tear it down. It is pure hell for everyone living in this war torn area I cant imagine. No older people who worked there life so there familys can be better should be worried about war and losing the family. The doctors have even fled as there is no resources to help people anymore. Only once dialysis center left which will probably close soon for fear of people and lack of resources. Anyone with a chronic disease is just out of luck as medicine is few and aid cant even be reached to most of these people anymore. It is just so sad.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: Dear friend, I am writing to let you know about an article that I just finished reading. Some anti-poaching rangers were captured by a poacher and attacked by the locals of the village. I feel bad for them, they were just trying to protect the animals.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: Reading about the violence in Yemen is just emotionally draining. It seems the majority of the casualties are civilians. All of this violence is being spurred on by US backed Saudi violence. I am a firm believer that the US should keep its tendrils out of international conflict. Even when tenuous peace is declared the governments that are installed by US interests are almost destined to fail.\n",
      "\n",
      "Category: Disgust.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: I feel really bad for the rangers, who were just doing their job and were treated unmercifully by the villagers. And unfortunately they didn't get any help from the police officers, who ran away. What a horribly frightening experience that must have been. On the other hand, the article is also confusing for me. Why were the villagers so upset? Do they earn their livings from poaching? Were they confused about what was going on? Also, who called for the helicopter? And how did the rangers survive if they were really confronted by all those villagers with weapons. If the story is real then it's frightening and disturbing. But there seems to be a lot of missing information.\n",
      "\n",
      "Category: Fear.\n",
      "\n",
      "####\n",
      "\n",
      "Essay: I feel really bad for the rangers, who were just doing their job and were treated unmercifully by the villagers. And unfortunately they didn't get any help from the police officers, who ran away. What a horribly frightening experience that must have been. On the other hand, the article is also confusing for me. Why were the villagers so upset? Do they earn their livings from poaching? Were they confused about what was going on? Also, who called for the helicopter? And how did the rangers survive if they were really confronted by all those villagers with weapons. If the story is real then it's frightening and disturbing. But there seems to be a lot of missing information.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b12edd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text_few_shot(prompt_):\n",
    "    '''Classify text_ using prompt_ and ChatGPT API'''\n",
    "        \n",
    "    # compose messages and check num_tokens\n",
    "    messages = [\n",
    "            #{ \"role\": \"system\", \"content\": \"You are a helpful emotion classifier.\", },\n",
    "            { \"role\": \"user\", \"content\": prompt_, },\n",
    "            ]\n",
    "    #if not verify_num_tokens(model, messages): return None\n",
    "    label_    = get_response(model, messages)\n",
    "    old_label = label_\n",
    "    label_    = verify_label(label_)        # get just the category if response is too long\n",
    "    print('First iteration:', old_label, label_)\n",
    "        \n",
    "    # if label not found in response text - second, extended chat\n",
    "    if label_ is None:\n",
    "        messages += [\n",
    "            { \"role\": \"assistant\", \"content\": old_label, },\n",
    "            { \"role\": \"user\", \"content\": followup, }\n",
    "            ]        \n",
    "        label_    = get_response(model, messages)        \n",
    "        old_label = label_\n",
    "        label_    = verify_label(label_)        # get just the category if response is too long\n",
    "        print('\\tSecond iteration:', old_label, label_)\n",
    "            \n",
    "    return label_ if label_ is not None else old_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "acd75abf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First iteration: Sadness. Sadness\n",
      "First iteration: Hope. Hope\n",
      "First iteration: Hope. Hope\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Disgust/Sadness. Disgust/Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Hope. Hope\n",
      "First iteration: Anger. Anger\n",
      "Processing text 10; example 9\n",
      "First iteration: Fear. Fear\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Anger. Anger\n",
      "First iteration: Hope. Hope\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Disgust. Disgust\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Hope. Hope\n",
      "Processing text 20; example 19\n",
      "First iteration: Fear/Sadness. Fear/Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Anger. Anger\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Disgust. Disgust\n",
      "First iteration: Disgust. Disgust\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Anger. Anger\n",
      "First iteration: Hope. Hope\n",
      "Processing text 30; example 29\n",
      "First iteration: Sadness/Fear. Fear/Sadness\n",
      "First iteration: Neutral. Neutral\n",
      "First iteration: Neutral. Neutral\n",
      "First iteration: Hope/Sadness. Hope/Sadness\n",
      "First iteration: Hope. Hope\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Disgust. Disgust\n",
      "First iteration: Disgust. Disgust\n",
      "First iteration: Fear/Sadness. Fear/Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Hope. Hope\n",
      "First iteration: Disgust/Hope. Disgust/Hope\n",
      "First iteration: Neutral. Neutral\n",
      "First iteration: Sadness. Sadness\n",
      "Processing text 50; example 49\n",
      "First iteration: Fear. Fear\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Disgust. Disgust\n",
      "First iteration: Fear/Hope. Fear/Hope\n",
      "First iteration: Anger. Anger\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Fear. Fear\n",
      "Processing text 60; example 59\n",
      "First iteration: Anger/Sadness. Anger/Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Hope. Hope\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Neutral. Neutral\n",
      "First iteration: Neutral. Neutral\n",
      "First iteration: Hope. Hope\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "Processing text 70; example 69\n",
      "First iteration: Anger. Anger\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Neutral. Neutral\n",
      "First iteration: Disgust/Fear. Disgust/Fear\n",
      "First iteration: Anger. Anger\n",
      "First iteration: Fear. Fear\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Disgust. Disgust\n",
      "First iteration: Sadness. Sadness\n",
      "Processing text 80; example 79\n",
      "First iteration: Neutral. Neutral\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Disgust. Disgust\n",
      "First iteration: Disgust. Disgust\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Anger. Anger\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Disgust. Disgust\n",
      "Processing text 90; example 89\n",
      "First iteration: Disgust. Disgust\n",
      "First iteration: Disgust. Disgust\n",
      "First iteration: Fear. Fear\n",
      "First iteration: Fear. Fear\n",
      "First iteration: Disgust. Disgust\n",
      "First iteration: Disgust/Sadness. Disgust/Sadness\n",
      "First iteration: Anger/Sadness. Anger/Sadness\n",
      "First iteration: Anger. Anger\n",
      "First iteration: Fear. Fear\n",
      "First iteration: Sadness. Sadness\n",
      "Processing text 100; example 99\n",
      "First iteration: Disgust. Disgust\n",
      "First iteration: Anger. Anger\n",
      "First iteration: Anger. Anger\n",
      "First iteration: Fear. Fear\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Anger. Anger\n",
      "First iteration: Sadness. Sadness\n",
      "Processing text 110; example 109\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Fear. Fear\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Anger. Anger\n",
      "First iteration: Anger. Anger\n",
      "First iteration: Hope. Hope\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Fear. Fear\n",
      "Processing text 120; example 119\n",
      "First iteration: Surprise. Surprise\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Hope/Sadness. Hope/Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Hope. Hope\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Disgust/Sadness. Disgust/Sadness\n",
      "Processing text 130; example 129\n",
      "First iteration: Anger. Anger\n",
      "First iteration: Hope. Hope\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Hope. Hope\n",
      "First iteration: Hope. Hope\n",
      "First iteration: Sadness. Sadness\n",
      "Processing text 140; example 139\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Neutral. Neutral\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Fear. Fear\n",
      "First iteration: Fear. Fear\n",
      "First iteration: Fear. Fear\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Fear, Disgust. Disgust/Fear\n",
      "Processing text 150; example 149\n",
      "First iteration: Neutral. Neutral\n",
      "First iteration: Disgust. Disgust\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Anger. Anger\n",
      "First iteration: Hope. Hope\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Disgust. Disgust\n",
      "First iteration: Fear. Fear\n",
      "Processing text 160; example 159\n",
      "First iteration: Neutral. Neutral\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Fear/Sadness. Fear/Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Hope. Hope\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Fear. Fear\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "Processing text 170; example 169\n",
      "First iteration: Hope. Hope\n",
      "First iteration: Hope. Hope\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Hope. Hope\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Neutral. Neutral\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Anger. Anger\n",
      "First iteration: Neutral. Neutral\n",
      "First iteration: Neutral. Neutral\n",
      "Processing text 180; example 179\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Neutral. Neutral\n",
      "First iteration: Disgust. Disgust\n",
      "First iteration: Fear/Sadness. Fear/Sadness\n",
      "First iteration: Fear. Fear\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Disgust. Disgust\n",
      "First iteration: Anger/Sadness. Anger/Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "Processing text 190; example 189\n",
      "First iteration: Hope. Hope\n",
      "First iteration: Neutral. Neutral\n",
      "First iteration: Disgust. Disgust\n",
      "First iteration: Disgust. Disgust\n",
      "First iteration: Anger. Anger\n",
      "First iteration: Anger. Anger\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Disgust. Disgust\n",
      "First iteration: Anger. Anger\n",
      "Processing text 200; example 199\n",
      "First iteration: Anger. Anger\n",
      "First iteration: Anger. Anger\n",
      "First iteration: Fear. Fear\n",
      "First iteration: Sadness. Sadness\n",
      "First iteration: Disgust. Disgust\n",
      "First iteration: Neutral. Neutral\n",
      "First iteration: Fear. Fear\n",
      "First iteration: Sadness. Sadness\n",
      "\n",
      "Time elapsed 8.5103 min\n"
     ]
    }
   ],
   "source": [
    "start  = time.time()\n",
    "res    = dict()\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "for t in df_dev[text_col].tolist():\n",
    "    if t in res:\n",
    "        continue\n",
    "    if count2 >= len(examples):\n",
    "        count2 = 0\n",
    "    prompt = examples[ count2 ].strip() + f'\\nEssay: {t}\\n\\nCategory:'\n",
    "    count2 += 1\n",
    "    try:\n",
    "        res[ t ] = classify_text_few_shot(prompt)\n",
    "    except openai.error.RateLimitError:\n",
    "        print(f'\\nText: {t}.\\nRate limit error\\n')\n",
    "    except Exception as e:\n",
    "        print(f'\\nText: {t}\\nError: {e}\\n')\n",
    "                \n",
    "    count1 += 1    \n",
    "    if count1 % 10 == 0:\n",
    "        print(f'Processing text {count1}; example {count2-1}')\n",
    "        with open('data/res.pkl', 'wb') as f:\n",
    "            pickle.dump(res, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                        \n",
    "        \n",
    "elapsed = (time.time() - start)/60\n",
    "print(f'\\nTime elapsed {round(elapsed, 4)} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d192c250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 208)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(examples), len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b93b56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9136b4b0",
   "metadata": {},
   "source": [
    "### If a followup question was not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "846e6526",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article_id                    0\n",
      "conversation_id               0\n",
      "speaker_number                0\n",
      "essay_id                      0\n",
      "speaker_id                    0\n",
      "essay                         0\n",
      "essay_clean                   0\n",
      "split                         0\n",
      "gender                        0\n",
      "education                     0\n",
      "race                          0\n",
      "age                           0\n",
      "income                        0\n",
      "emotion                       0\n",
      "emotion_count                 0\n",
      "char_length                   0\n",
      "word_length                   0\n",
      "target_encoded                0\n",
      "article                       0\n",
      "article_clean                 0\n",
      "essay_clean_docs              0\n",
      "essay_clean_spellchecked      0\n",
      "article_clean_docs            0\n",
      "article_clean_spellchecked    0\n",
      "compare1                      0\n",
      "compare2                      0\n",
      "gpt_embedding                 0\n",
      "closest_texts                 0\n",
      "emotion_no_2nd_neut           0\n",
      "pred_all                      0\n",
      "pred_encoded                  0\n",
      "dtype: int64\n",
      "Sadness            91\n",
      "Anger              22\n",
      "Disgust            22\n",
      "Hope               21\n",
      "Fear               18\n",
      "Neutral            16\n",
      "Fear/Sadness        5\n",
      "Disgust/Sadness     3\n",
      "Anger/Sadness       3\n",
      "Hope/Sadness        2\n",
      "Disgust/Fear        2\n",
      "Disgust/Hope        1\n",
      "Fear/Hope           1\n",
      "Surprise            1\n",
      "Name: pred_all, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# if one label is the output\n",
    "df_dev['pred_all'] = df_dev[text_col].map( res )\n",
    "print(df_dev.isna().sum())\n",
    "print(df_dev['pred_all'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7ede4d2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     article_id  conversation_id  speaker_number  essay_id  speaker_id  \\\n",
      "158          31              204               2       703          93   \n",
      "\n",
      "                                                 essay  \\\n",
      "158  Hey man, Apparently, Indonesia is going throug...   \n",
      "\n",
      "                                           essay_clean split  gender  \\\n",
      "158  Hey man, Apparently, Indonesia is going throug...   dev       1   \n",
      "\n",
      "     education  race  age  income    emotion  emotion_count  char_length  \\\n",
      "158          7     5   41   64000  [Neutral]              1          467   \n",
      "\n",
      "     word_length            target_encoded  \\\n",
      "158           75  [0, 0, 0, 0, 0, 1, 0, 0]   \n",
      "\n",
      "                                               article  \\\n",
      "158  A Palm Oil Company Threatens The Third Largest...   \n",
      "\n",
      "                                         article_clean  \\\n",
      "158  A Palm Oil Company Threatens The Third Largest...   \n",
      "\n",
      "                                      essay_clean_docs  \\\n",
      "158  (Hey, man, ,, Apparently, ,, Indonesia, is, go...   \n",
      "\n",
      "                              essay_clean_spellchecked  \\\n",
      "158  Hey man, Apparently, Indonesia is going throug...   \n",
      "\n",
      "                                    article_clean_docs  \\\n",
      "158  (A, Palm, Oil, Company, Threatens, The, Third,...   \n",
      "\n",
      "                            article_clean_spellchecked  compare1  compare2  \\\n",
      "158  A Palm Oil Company Threatens The Third Largest...      True     False   \n",
      "\n",
      "                                         gpt_embedding  \\\n",
      "158  [0.008176305331289768, -0.035911086946725845, ...   \n",
      "\n",
      "                                         closest_texts emotion_no_2nd_neut  \\\n",
      "158  [I think this is sad for the orangutangs. It s...           [Neutral]   \n",
      "\n",
      "                                     pred_all              pred_encoded  \n",
      "158  Yes, I am sure. The category is Concern.  [0, 1, 0, 0, 0, 0, 0, 0]  \n"
     ]
    }
   ],
   "source": [
    "print(df_dev[ df_dev['pred_all']==\"Yes, I am sure. The category is Concern.\" ])\n",
    "df_dev.at[ 127, 'pred_all' ] = 'Fear'\n",
    "df_dev.at[ 76, 'pred_all' ] = 'Fear'\n",
    "df_dev.at[ 18, 'pred_all' ] = 'Sadness'\n",
    "df_dev.at[ 48, 'pred_all' ] = 'Neutral'\n",
    "df_dev.at[ 80, 'pred_all' ] = 'Neutral'\n",
    "df_dev.at[ 115, 'pred_all' ] = 'Anger'\n",
    "df_dev.at[ 74, 'pred_all' ] = 'Neutral'\n",
    "df_dev.at[ 158, 'pred_all' ] = 'Neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "473c1177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sadness            91\n",
       "Anger              22\n",
       "Disgust            22\n",
       "Hope               21\n",
       "Fear               18\n",
       "Neutral            16\n",
       "Fear/Sadness        5\n",
       "Disgust/Sadness     3\n",
       "Anger/Sadness       3\n",
       "Hope/Sadness        2\n",
       "Disgust/Fear        2\n",
       "Disgust/Hope        1\n",
       "Fear/Hope           1\n",
       "Surprise            1\n",
       "Name: pred_all, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev['pred_all'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "453f2971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize predictions\n",
    "df_dev['pred_encoded'] = df_dev['pred_all'].apply( lambda x: get_target(x.split('/')) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e0708c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anger     0.5600    0.3684    0.4444        38\n",
      "     Disgust     0.5000    0.5833    0.5385        24\n",
      "        Fear     0.2692    0.8750    0.4118         8\n",
      "        Hope     0.2400    0.3750    0.2927        16\n",
      "         Joy     0.0000    0.0000    0.0000         2\n",
      "     Neutral     0.6875    0.2037    0.3143        54\n",
      "     Sadness     0.7788    0.8020    0.7902       101\n",
      "    Surprise     0.0000    0.0000    0.0000         3\n",
      "\n",
      "   micro avg     0.5911    0.5407    0.5648       246\n",
      "   macro avg     0.3794    0.4009    0.3490       246\n",
      "weighted avg     0.6303    0.5407    0.5471       246\n",
      " samples avg     0.6058    0.5601    0.5681       246\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/opt/anaconda3/envs/top/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_dev_encoded      = np.array( df_dev['target_encoded'].values.tolist() )\n",
    "y_dev_pred_encoded = np.array( df_dev['pred_encoded'].values.tolist() )\n",
    "labels = list(label2key.keys())\n",
    "print( classification_report( y_dev_encoded, y_dev_pred_encoded, target_names=labels, digits=4 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2aeb61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68ea5b70",
   "metadata": {},
   "source": [
    "### If a followup question was used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ee6c254",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values:\n",
      "article_id                    0\n",
      "conversation_id               0\n",
      "speaker_number                0\n",
      "essay_id                      0\n",
      "speaker_id                    0\n",
      "essay                         0\n",
      "essay_clean                   0\n",
      "split                         0\n",
      "gender                        0\n",
      "education                     0\n",
      "race                          0\n",
      "age                           0\n",
      "income                        0\n",
      "emotion                       0\n",
      "emotion_count                 0\n",
      "char_length                   0\n",
      "word_length                   0\n",
      "target_encoded                0\n",
      "article                       0\n",
      "article_clean                 0\n",
      "essay_clean_docs              0\n",
      "essay_clean_spellchecked      0\n",
      "article_clean_docs            0\n",
      "article_clean_spellchecked    0\n",
      "compare1                      0\n",
      "compare2                      0\n",
      "pred_all                      0\n",
      "pred_encoded                  0\n",
      "pred                          3\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sadness             54\n",
       "Fear/Sadness        31\n",
       "Hope/Sadness        24\n",
       "Anger/Sadness       23\n",
       "Disgust/Sadness     19\n",
       "Anger/Disgust        9\n",
       "Hope                 8\n",
       "Fear                 6\n",
       "Disgust              5\n",
       "Neutral/Sadness      4\n",
       "Anger/Fear           4\n",
       "Hope/Neutral         4\n",
       "Disgust/Fear         3\n",
       "Anger                2\n",
       "Anger/Neutral        2\n",
       "Neutral              2\n",
       "Fear/Neutral         1\n",
       "Disgust/Neutral      1\n",
       "Sadness/Surprise     1\n",
       "Joy                  1\n",
       "Fear/Surprise        1\n",
       "Name: pred, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if a followup question was used - clean reponse\n",
    "df_dev['pred'] = df_dev['pred_all'].apply( lambda x: x[3] )\n",
    "print('Null values:\\n', df_dev.isna().sum(), sep='')\n",
    "df_dev['pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9205abdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([150, 167, 173], dtype='int64')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('Neutral',\n",
       "   'Neutral',\n",
       "   'I think the text is more related to Disappointment.',\n",
       "   None),\n",
       "  None],\n",
       " [('Sadness',\n",
       "   'Sadness',\n",
       "   \"Yes, I am sure. The text expresses concern about children not being able to eat and the country's failure to provide basic necessities to its people, which is a sad situation.\",\n",
       "   None),\n",
       "  None],\n",
       " [('Hope/Sadness',\n",
       "   'Hope/Sadness',\n",
       "   \"Yes, I'm sure. The text expresses sympathy for the situation but also a sense of helplessness, and ends with a hopeful attitude towards the future.\",\n",
       "   None),\n",
       "  None]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if a followup question was used - review why some predictions were NaNs\n",
    "temp = df_dev[ df_dev['pred'].isna() ]\n",
    "print(temp.index)\n",
    "temp[['pred_all', 'pred']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91e86456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if a followup question was used - manually assign missing predictions\n",
    "df_dev.at[150, 'pred'] = 'Neutral'\n",
    "df_dev.at[167, 'pred'] = 'Sadness'\n",
    "df_dev.at[173, 'pred'] = 'Hope/Sadness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fa47d5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize predictions\n",
    "df_dev['pred_encoded'] = df_dev['pred'].apply( lambda x: get_target(x.split('/')) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0d1845",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev_encoded      = np.array( df_dev['target_encoded'].values.tolist() )\n",
    "y_dev_pred_encoded = np.array( df_dev['pred_encoded'].values.tolist() )\n",
    "labels = list(label2key.keys())\n",
    "print( classification_report( y_dev_encoded, y_dev_pred_encoded, target_names=labels, digits=4 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737edf7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40649d88",
   "metadata": {},
   "source": [
    "# Few-Shot Approach 2: concatenate closest 30 examples into one long string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1e202e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY2\")\n",
    "model          = 'gpt-3.5-turbo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11c898e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text 10. Time elapsed: 0.0373 min\n",
      "Processing text 20. Time elapsed: 0.074 min\n",
      "Processing text 30. Time elapsed: 0.1105 min\n",
      "Processing text 40. Time elapsed: 0.1474 min\n",
      "Processing text 50. Time elapsed: 0.1841 min\n",
      "Processing text 60. Time elapsed: 0.2211 min\n",
      "Processing text 70. Time elapsed: 0.2579 min\n",
      "Processing text 80. Time elapsed: 0.2952 min\n",
      "Processing text 90. Time elapsed: 0.3326 min\n",
      "Processing text 100. Time elapsed: 0.3696 min\n",
      "Processing text 110. Time elapsed: 0.4074 min\n",
      "Processing text 120. Time elapsed: 0.445 min\n",
      "Processing text 130. Time elapsed: 0.4825 min\n",
      "Processing text 140. Time elapsed: 0.5202 min\n",
      "Processing text 150. Time elapsed: 0.5575 min\n",
      "Processing text 160. Time elapsed: 0.595 min\n",
      "Processing text 170. Time elapsed: 0.6326 min\n",
      "Processing text 180. Time elapsed: 0.671 min\n",
      "Processing text 190. Time elapsed: 0.709 min\n",
      "Processing text 200. Time elapsed: 0.747 min\n",
      "\n",
      "Time elapsed 0.7774 min\n"
     ]
    }
   ],
   "source": [
    "# find top_n closest df_train embeddings for each df_dev embedding\n",
    "def batch_cosine(embedding_, df, top_n=100):\n",
    "    df['similarity'] = df['gpt_embedding'].apply(lambda x: cosine_similarity(x, embedding_))\n",
    "    return df.sort_values(by='similarity', ascending=False).head(top_n)['essay_clean'].tolist()\n",
    "\n",
    "df_train_copy = df_train.copy()\n",
    "start = time.time()\n",
    "res   = dict()\n",
    "count = 0\n",
    "for t, e in df_dev[['essay_clean', 'gpt_embedding']].values:\n",
    "    if t in res:\n",
    "        continue\n",
    "    res[ t ] = batch_cosine( e, df_train_copy, top_n=30, )\n",
    "    count += 1\n",
    "    if count % 10 == 0:\n",
    "        print(f'Processing text {count}. Time elapsed: {round((time.time()-start)/60, 4)} min')\n",
    "        with open('data/res.pkl', 'wb') as f:\n",
    "            pickle.dump(res, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                        \n",
    "elapsed = (time.time() - start)/60\n",
    "print(f'\\nTime elapsed {round(elapsed, 4)} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6344201",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article_id                    0\n",
      "conversation_id               0\n",
      "speaker_number                0\n",
      "essay_id                      0\n",
      "speaker_id                    0\n",
      "essay                         0\n",
      "essay_clean                   0\n",
      "split                         0\n",
      "gender                        0\n",
      "education                     0\n",
      "race                          0\n",
      "age                           0\n",
      "income                        0\n",
      "emotion                       0\n",
      "emotion_count                 0\n",
      "char_length                   0\n",
      "word_length                   0\n",
      "target_encoded                0\n",
      "article                       0\n",
      "article_clean                 0\n",
      "essay_clean_docs              0\n",
      "essay_clean_spellchecked      0\n",
      "article_clean_docs            0\n",
      "article_clean_spellchecked    0\n",
      "compare1                      0\n",
      "compare2                      0\n",
      "gpt_embedding                 0\n",
      "closest_texts                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_dev['closest_texts'] = df_dev['essay_clean'].map( res )\n",
    "print(df_dev.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "116259e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'data/df_dev.pkl'\n",
    "df_dev.to_pickle(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7a1c762d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['article_id', 'conversation_id', 'speaker_number', 'essay_id',\n",
       "       'speaker_id', 'essay', 'essay_clean', 'split', 'gender', 'education',\n",
       "       'race', 'age', 'income', 'emotion', 'target_encoded', 'target_encoded2',\n",
       "       'compare', 'emotion_count', 'char_length', 'word_length', 'article',\n",
       "       'article_clean', 'essay_clean_docs', 'essay_clean_spellchecked',\n",
       "       'article_clean_docs', 'article_clean_spellchecked', 'compare1',\n",
       "       'compare2', 'gpt_embedding', 'emotion_no_2nd_neut'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "67d320c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3313, 3442, 3131, 2930, 3297, 2964, 3101, 3057, 3215, 3209, 3411, 3226, 3303, 2836, 3143, 2919, 3094, 3051, 3092, 3041, 3076, 3145, 3198, 2972, 3106, 3383, 3174, 3158, 3301, 3304, 3248, 3578, 3088, 3496, 3239, 3236, 3138, 3503, 3398, 3093, 2961, 3032, 3099, 3198, 2906, 2922, 2897, 3201, 3300, 3176, 3368, 2982, 3358, 2995, 2955, 3116, 3228, 3032, 3006, 3178, 3383, 3193, 3050, 3086, 3406, 3327, 3067, 3011, 3051, 3020, 3368, 3264, 3320, 3393, 3292, 3640, 3348, 3241, 3337, 3383, 3050, 3074, 3570, 3543, 3015, 3259, 3436, 3232, 3119, 3230, 3241, 3207, 3207, 3130, 3416, 3257, 3523, 3125, 3135, 3144, 3122, 3409, 3171, 3130, 3227, 3001, 3258, 2760, 3319, 3220, 3113, 3264, 3271, 3459, 3272, 2979, 3626, 3242, 3096, 3179, 3207, 3096, 2917, 3062, 3294, 3102, 3153, 2955, 2957, 3237, 3366, 3103, 3190, 3295, 3151, 3173, 3144, 3211, 3610, 3163, 3150, 3338, 3077, 3403, 3105, 3223, 3135, 2878, 2907, 3278, 3154, 3326, 3386, 3143, 3435, 3410, 3358, 3086, 3043, 2948, 3133, 3537, 3248, 3098, 3147, 3119, 3330, 3370, 3271, 3365, 3500, 3268, 3149, 3091, 3421, 3534, 3471, 3503, 3155, 3019, 3248, 3237, 3261, 3490, 3093, 3001, 3342, 3430, 3134, 3044, 3212, 3404, 2975, 3258, 3164, 3066, 3256, 3190, 3431, 3359, 3523, 3413, 3209, 3039, 2986, 3364, 3146, 3162]\n",
      "[2930, 2964, 2836, 2919, 2972, 2961, 2906, 2922, 2897, 2982, 2995, 2955, 2760, 2979, 2917, 2955, 2957, 2878, 2907, 2948, 2975, 2986]\n",
      "[3578, 3503, 3640, 3570, 3543, 3523, 3626, 3610, 3537, 3534, 3503, 3523]\n"
     ]
    }
   ],
   "source": [
    "# concatenate 30 closest examples for each dev set datapoint and check the total number of tokens\n",
    "def concatenate_few_show_examples( closest_texts ):\n",
    "    ''' Concatenate 30 closest examples with their categories into one string '''\n",
    "    df_ = df_train[ df_train['essay_clean'].isin(closest_texts) ]\n",
    "    example = prompt_one\n",
    "    for text, emo in df_[['essay_clean_spellchecked', 'emotion_no_2nd_neut']].values:\n",
    "        example += f\"\\nText: {text}\\n\\nCategory: {'/'.join(sorted(emo))}.\\n\\n####\\n\"\n",
    "    return example\n",
    "\n",
    "df_dev['closest_texts_concatenated'] = df_dev['closest_texts'].apply( concatenate_few_show_examples )\n",
    "\n",
    "\n",
    "# check that # tokens in concatenated exapmles doesn't exceed ChatGPT's context window size of 4096\n",
    "lengths = [ num_tokens_from_messages([{'role':'user', 'content': example} ]) for example\\\n",
    "            in df_dev['closest_texts_concatenated'].values ]\n",
    "print(lengths)\n",
    "print([l for l in lengths if l <3000])\n",
    "print([l for l in lengths if l > 3500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "86401b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 - Below you are given examples of texts with their most relevant emotion categories. The examples are separated by four hashtags.\n",
      "2 - Each text can belong to one or two most relevant emotion categories from the following list: Sadness, Neutral, Anger, Disgust, Fear, Hope, Surprise, Joy.\n",
      "3 - Your task is to carefully learn from the examples of texts with their categories and then use the acquired knowledge to classify the very last text by selecting the most relevant emotion category from the above list.\n",
      "4 - You may add a second emotion category from the above list ONLY AND ONLY IF it is also relevant to the very last text.\n",
      "5 - Output just the category or categories for the last text and nothing else. If there are two relevant emotion categories: sort them alphabetically, concatenate with a forward slash, and output only them and nothing else.\n",
      "\n",
      "####\n",
      "\n",
      "Text: It breaks my heart to see people living in those conditions. I hope that all the aid that was sent to the island makes it to the people who need it the most. I do not know what I would do it that was my family and I. I would hope that I would do my best, but I can see how depressing and hopeless you could feel having your whole life changed because of a storm and not knowing where your next meal is coming from.\n",
      "\n",
      "Category: Hope/Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Text: I wonder why there aren't more people trying to help these people. I understand Haiti is not the richest nor less corrupt country but surely there must be a way to help. Supplies being looted by crowds is understandable because they are hungry and people need food and water to survive. We must think of other ways to distribute the food and water.\n",
      "\n",
      "Category: Anger.\n",
      "\n",
      "####\n",
      "\n",
      "Text: This was a sad situation. It is unfair for all these people to live in such conflict and persecution fo their beliefs. It makes me very grateful to live somewhere that I have the freedom to believe what I want. People complain so much about America and don't realize how good we have it here. These people are literally dying just for what they believe which is really sad. I feel sad for the families.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Text: Honestly the entire story is just so sad and really highlights how devastating the effects of greed are. It's not enough that our policies and hunger for power wreck human lives, we have to wreck entire environments and species, too. I feel so bad for the animals, and it just goes to show how much worse things must be for the actual humans.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Text: It makes me sad that people have to risk their life to get help. It makes me madder that those people are turned away for their search for a better life. It is human history for people to be able to move around and search for a better life. Now with boarders people are stuck in the place that they are born.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Text: Its really sad when these types of things happen. I feel like we need to do more to help these sort of people. I also understand that they are human like us and they have feelings too. Doctors without Borders does what it can but it can only do so much without external help. The fact that they are displaced by conflict and persecution makes me feel like we need to help countries first.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Text: It hurts my heart to think about all the people who leave the place of their birth only not to find a home that they are looking for. I would love to see the day were people treat all other humans like people no matter how they look and where they are from. I wonder why people can not relate to other people and just help.\n",
      "\n",
      "Category: Hope/Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Text: Wow, hearing about things like this really makes me so grateful to be an American. I'm very happy to live in this beautiful country and I wish people would stop complaining so much about everything they think is wrong here. Just be grateful you're not being used as a human shield. Some of the things going on over there are just atrocious, and as bad as people think it is here it doesn't even hold a candle to that. I am saddened to hear about these families and children being harmed so maliciously.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Text: I feel sad for all the people who are being turned into human shields in Iraq. The article made me think about how good we have it in the United States and things that are happening to these people are only seen in movies. To be shot dead on the spot for protesting or have more than half of your family missing because they were kidnapped would be horrible.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Text: This is so sad. I can't even imagine living and trying to raise my family in a situation like this. These poor people can't even send their kids to school because they have to get up so early and stand in food lines. Or else the kids are too weak and sick from not eating, they can't go to school. Also, the school supplies are so expensive, they can't buy them because they need to buy food.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Text: After reading the article, i can't help but feel bad for the people and children in the camps. I feel bad for them because nobody should have to be living in those type of conditions. Everyone should be able to have shelter, food, and a nice place to sleep on. I feel like these people are almost being treated like dirt and it's very unfair.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Text: I found this to be very sad. These people obviously don't have many options, and they are trapped in a bad situation without any food and with a lot of violence around them. I have heard a lot about this area and the bad things going on there. This is an ongoing situation that shows no signs of improvement, and meanwhile the people continue to suffer and die. Young people are affected as well as women and many innocent people who have nothing to do with the terrorist groups causing all these problems.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Text: This article was just heartbreaking. I just pictured my father working his whole life for us just for a warm and horrible people to come in and tear it down. It is pure hell for everyone living in this war torn area I cant imagine. No older people who worked there life so there familys can be better should be worried about war and losing the family. The doctors have even fled as there is no resources to help people anymore. Only once dialysis center left which will probably close soon for fear of people and lack of resources. Anyone with a chronic disease is just out of luck as medicine is few and aid cant even be reached to most of these people anymore. It is just so sad.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Text: This is a very heartbreaking article. It's hard to read what is happening to people in other parts of the world. I can't believe people would leave their parents and elderly family members behind in a war. It's unimaginable. And to make matters worse, there is hardly any food for them in their homes. They're under constant attack and can't even get basic medications that we take for granted every day here in the US. I truly hope the wars stop and these people can get some assistance rebuilding their lives and homes. More effort needs to go into donating to the charities that help in these areas. I can understand why some would not want to travel and live there, considering there is a high probability of death from an airstrike but the people should at least have basic food items, clothing\n",
      "\n",
      "Category: Hope/Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Text: This article was a little hard to follow as I dont follow or know much about whats going on in the other side of the world. It is so sad to me that a war torn third world country has people living there that are afraid for there lives daily. The humanitarian effort is so noble but so sad they are at the hands of a corrupt government and society. How could a government fail to protect its people and aid workers and let them be brutally attacked and raped at there own hands. Noone should be in a position where the power in the society is evil and able to do what they please with no consequence that is a very scary balance. Something needs to be done to help.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Text: This is a tragic story but it's also what happens in third-world countries where you pull a truck off the side of the road to sell fuel to citizens. The world is an absolutely enormous place--beyond comprehension. And death, suffering, and tragedy occur all the time. I'm not going to worry about the lives of a handful of random people who I didn't know existed until I knew they no longer existed. These people might as well be fictional characters to me. Sure, someone is grieving them somewhere. And this event probably really did happen. But to me it's not real and it truly doesn't matter. And, frankly, despite this modern age's attempt to argue the opposite, I don't think the world is any better a place because I know these people are dead.\n",
      "\n",
      "Category: Anger.\n",
      "\n",
      "####\n",
      "\n",
      "Text: It is a shame that they are going through such hardships I feel bad about the little baby that died and bombs falling on them but that is part of life growing up in an uncivilized world where savages run rampant if they could just get rid of the people and start over maybe just move all the savages out.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Text: After reading the article, the only feelings i can say that i have is one of sadness. It's terrible that these people had this unfortunate hurricane hit them. There was nothing they could have really done and they definitely did not deserve this. The fact that there are little children with no food or water really hurts me. There are most likely animals out there that are in need of food and water as well.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Text: This situation in Haiti is terrible and saddening. no person in this day and age should suffer at the hands of their government while no one does anything to help. It is sad to see such suffering and hungry people. How can a country be that terrible. How does next to nobody help these poor innocent people.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Text: In the 21st century, people are still starving after major disasters. This earthquake destroyed Haiti and in my opinion, there was not enough food that was brought in from other countries. I constantly wonder how this continues to be such a slow, slow process. I have been to Haiti and the country is hard enough just to live without major catastrophic disasters.\n",
      "\n",
      "Category: Neutral.\n",
      "\n",
      "####\n",
      "\n",
      "Text: While we do think about the human suffering caused by war and poverty, we rarely consider the effects these have on animals. It just makes these situations all the more heartbreaking. When I think about animals in zoos - animals that have been removed from their native lands, only to starve to death. I'm suprised more animal rights groups haven't become involved - really, if all those angry vegans out there spent more time helping animals and less time pontificating to the rest of us, they would do far more good.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Text: The article in itself is extremely depressing. Animals starving due to a Country also starving. There's nothing that can be done for these animals as they're just in an unfortunate circumstance. It's astonishing that this is allowed to happen in general though. They are helpless creatures starving to death because nobody is helping them. There should be charities that make this impossible to happen.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Text: This article is so sad I cant believe the mass amounts of lives being taken that is so preventable. I think more aid should be sent and they should be able to sail ships in there territory to help aid these people. It is sad to think people think the chance of death is better than living where they are. The smugglers need to controlled so so many boats arent sent out and it over wales rescue missions. I feel for the parents who send there children on this and the children end up dying i cant imagine. Someday i hope more aid is sent to help countries like this fix the problems at home so so many people dont want to flea\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Text: Hearing about the experiences of refugees is sad but something I have a hard time connecting with. It's distressing to hear about children who are innocent victims of violence in a country or even adults, but it just seems so far away and I Feel so removed from those things and people that it's hard to relate to. I am still sad for them that they have the experiences they have and I am grateful for my life and freedom in America.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Text: This crisis is so tender and near and dear. It is horrifying that such innocent souls are lacking basic nutrition and this is effecting every part of there life. Because they are so week form not eating they can't do much to fend for themselves especially because alot of them are orphaned children. It is horrifying that it is tough for aid to push through to these areas and the further they gain access to the more horrible the sights are. I can't imagine the children longing for there parents they are seperated from and longing for some sort of security in there lives. There food is gone there water is unsafe but it is nice to know that aid workers eventhough it is a tough site to see are remaining to truly help out.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Text: I can't imagine what it would be like to live in a war-torn country. Americans have it so much better than they realize and I don't understand why it's so hard for people to put themselves in others' shoes. I feel so much for this poor man that just wanted a peaceful retirement and to hang out with his family and now he and his wife are basically depriving themselves of food so that they have enough for the kids. It's depressing.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Text: An article like this just make you so glad to live in the united states. Where everything is regulated and we have laws. I can not imagine living in a place where the government and law can do anything they please without consequences. Soldiers raping women burning down houses all with out real cause. Any aid workers and doctors are treated very poorly so theres not enough to go around how does this civilization survive. Crazy how far behind and uncivilized some places still are in 2019. I think more light needs to be shown on this as real people are hurting. Everyone deserves to feel safe in there country.\n",
      "\n",
      "Category: Disgust.\n",
      "\n",
      "####\n",
      "\n",
      "Text: Sometimes living in the United States we forget how a lot of the people of the planet live. I would not think about buying fuel from a truck that stops in my community. We think of gas stations, not thinking that everybody in the world do not have access to a gas station. I feel sorry for the people who died and was hurt in the accident.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Text: Living in a war tore country must be horrible. I feel the pain of all the lost. Having air strikes hit your home has to be horrible and seeing love ones buried under what is left from your home is also horrible. I do not wish this on anybody. I hope that the country can find peace and the people can return to a normal life.\n",
      "\n",
      "Category: Hope/Sadness.\n",
      "\n",
      "####\n",
      "\n",
      "Text: This is such a hard read. I cant imagine living in a war torn place where everyday you fear for your life. How sad these people died such a horrible hard death. The mother and sister have to live and rebuild there life without the kids and husband. How do you even go on after such a thing. There needs to be more aid and relief and stop all the bombing and violence. It is such a silly way to die over nothing.\n",
      "\n",
      "Category: Sadness.\n",
      "\n",
      "####\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_dev['closest_texts_concatenated'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ac55c68d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Hope. Hope\n",
      "Frist iteration: Hope/Joy. Hope/Joy\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Hope/Sadness. Hope/Sadness\n",
      "Frist iteration: Anger/Sadness. Anger/Sadness\n",
      "Processing text 10\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Hope/Sadness. Hope/Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Disgust/Sadness. Disgust/Sadness\n",
      "Frist iteration: Sadness/Neutral. Neutral/Sadness\n",
      "Frist iteration: Hope. Hope\n",
      "Processing text 20\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Hope/Sadness. Hope/Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Disgust. Disgust\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Disgust. Disgust\n",
      "Frist iteration: Anger/Hope. Anger/Hope\n",
      "Processing text 30\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Neutral. Neutral\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Hope/Sadness. Hope/Sadness\n",
      "Frist iteration: Hope/Sadness. Hope/Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Neutral. Neutral\n",
      "Frist iteration: Neutral. Neutral\n",
      "Frist iteration: Neutral. Neutral\n",
      "Processing text 40\n",
      "Frist iteration: Disgust/Sadness. Disgust/Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Anger/Hope. Anger/Hope\n",
      "Frist iteration: Disgust. Disgust\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Processing text 50\n",
      "Frist iteration: Neutral. Neutral\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness/Neutral. Neutral/Sadness\n",
      "Frist iteration: Anger/Disgust. Anger/Disgust\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Anger. Anger\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness/Hope. Hope/Sadness\n",
      "Frist iteration: Hope/Sadness. Hope/Sadness\n",
      "Processing text 60\n",
      "Frist iteration: Anger/Sadness. Anger/Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Neutral. Neutral\n",
      "Frist iteration: Neutral. Neutral\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Processing text 70\n",
      "Frist iteration: Anger/Sadness. Anger/Sadness\n",
      "Frist iteration: Anger/Sadness. Anger/Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Neutral. Neutral\n",
      "Frist iteration: Disgust/Hope. Disgust/Hope\n",
      "Frist iteration: Anger/Sadness. Anger/Sadness\n",
      "Frist iteration: Neutral. Neutral\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Disgust/Sadness. Disgust/Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Processing text 80\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Disgust/Sadness. Disgust/Sadness\n",
      "Frist iteration: Disgust. Disgust\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Anger. Anger\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Disgust. Disgust\n",
      "Processing text 90\n",
      "Frist iteration: Anger/Disgust. Anger/Disgust\n",
      "Frist iteration: Disgust/Sadness. Disgust/Sadness\n",
      "Frist iteration: Anger/Sadness. Anger/Sadness\n",
      "Frist iteration: Fear. Fear\n",
      "Frist iteration: Anger. Anger\n",
      "Frist iteration: Disgust/Sadness. Disgust/Sadness\n",
      "Frist iteration: Neutral. Neutral\n",
      "Frist iteration: Anger. Anger\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Processing text 100\n",
      "Frist iteration: Disgust/Sadness. Disgust/Sadness\n",
      "Frist iteration: Anger/Sadness. Anger/Sadness\n",
      "Frist iteration: Anger. Anger\n",
      "Frist iteration: Disgust/Fear. Disgust/Fear\n",
      "Frist iteration: Hope/Sadness. Hope/Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness/Neutral. Neutral/Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Processing text 110\n",
      "Frist iteration: Anger/Sadness. Anger/Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Disgust. Disgust\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Disgust. Disgust\n",
      "Frist iteration: Anger. Anger\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Anger. Anger\n",
      "Frist iteration: Fear. Fear\n",
      "Processing text 120\n",
      "Frist iteration: Disgust/Surprise. Disgust/Surprise\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness/Hope. Hope/Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Anger/Sadness. Anger/Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Fear/Hope. Fear/Hope\n",
      "Frist iteration: Hope/Sadness. Hope/Sadness\n",
      "Frist iteration: Disgust/Hope. Disgust/Hope\n",
      "Processing text 130\n",
      "Frist iteration: Disgust. Disgust\n",
      "Frist iteration: Hope. Hope\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Disgust/Sadness. Disgust/Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Hope/Sadness. Hope/Sadness\n",
      "Frist iteration: Hope/Sadness. Hope/Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Processing text 140\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Neutral. Neutral\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Disgust/Sadness. Disgust/Sadness\n",
      "Frist iteration: Sadness/Fear. Fear/Sadness\n",
      "Frist iteration: Fear/Disgust. Disgust/Fear\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Fear/Sadness. Fear/Sadness\n",
      "Processing text 150\n",
      "Frist iteration: Neutral. Neutral\n",
      "Frist iteration: Disgust/Sadness. Disgust/Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Disgust. Disgust\n",
      "Frist iteration: Hope. Hope\n",
      "Frist iteration: Neutral. Neutral\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Disgust. Disgust\n",
      "Frist iteration: Anger/Sadness. Anger/Sadness\n",
      "Processing text 160\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness/Hope. Hope/Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Hope. Hope\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Fear. Fear\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Processing text 170\n",
      "Frist iteration: Hope. Hope\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Hope/Sadness. Hope/Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Neutral. Neutral\n",
      "Frist iteration: Sadness/Surprise. Sadness/Surprise\n",
      "Frist iteration: Disgust/Sadness. Disgust/Sadness\n",
      "Frist iteration: Neutral. Neutral\n",
      "Frist iteration: Hope. Hope\n",
      "Processing text 180\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Neutral. Neutral\n",
      "Frist iteration: Disgust/Sadness. Disgust/Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Fear/Neutral. Fear/Neutral\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Disgust. Disgust\n",
      "Frist iteration: Anger/Sadness. Anger/Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Processing text 190\n",
      "Frist iteration: Neutral. Neutral\n",
      "Frist iteration: Neutral. Neutral\n",
      "Frist iteration: Anger. Anger\n",
      "Frist iteration: Disgust. Disgust\n",
      "Frist iteration: Disgust. Disgust\n",
      "Frist iteration: Anger/Sadness. Anger/Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Hope/Sadness. Hope/Sadness\n",
      "Frist iteration: Anger/Disgust. Anger/Disgust\n",
      "Frist iteration: Disgust. Disgust\n",
      "Processing text 200\n",
      "Frist iteration: Anger. Anger\n",
      "Frist iteration: Anger. Anger\n",
      "Frist iteration: Fear. Fear\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Sadness. Sadness\n",
      "Frist iteration: Neutral. Neutral\n",
      "Frist iteration: Fear. Fear\n",
      "Frist iteration: Sadness. Sadness\n",
      "\n",
      "Time elapsed 8.1165 min\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "res   = dict()\n",
    "count = 0\n",
    "for text, example in df_dev[['essay_clean_spellchecked', 'closest_texts_concatenated']].values:\n",
    "    if text in res:\n",
    "        continue\n",
    "    prompt = example + f'\\nText: {text}\\n\\nCategory:'   \n",
    "    try:\n",
    "        res[ text ] = classify_text_few_shot(prompt)\n",
    "    except Exception as e:\n",
    "        print(f'\\nText: {text}\\nError: {e}\\n')\n",
    "                \n",
    "    count += 1    \n",
    "    if count % 10 == 0:\n",
    "        print(f'Processing text {count}')\n",
    "        with open('data/res.pkl', 'wb') as f:\n",
    "            pickle.dump(res, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                        \n",
    "        \n",
    "elapsed = (time.time() - start)/60\n",
    "print(f'\\nTime elapsed {round(elapsed, 4)} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f287b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1180d914",
   "metadata": {},
   "source": [
    "### If a followup question was not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c18f5e72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article_id                    0\n",
      "conversation_id               0\n",
      "speaker_number                0\n",
      "essay_id                      0\n",
      "speaker_id                    0\n",
      "essay                         0\n",
      "essay_clean                   0\n",
      "split                         0\n",
      "gender                        0\n",
      "education                     0\n",
      "race                          0\n",
      "age                           0\n",
      "income                        0\n",
      "emotion                       0\n",
      "emotion_count                 0\n",
      "char_length                   0\n",
      "word_length                   0\n",
      "target_encoded                0\n",
      "article                       0\n",
      "article_clean                 0\n",
      "essay_clean_docs              0\n",
      "essay_clean_spellchecked      0\n",
      "article_clean_docs            0\n",
      "article_clean_spellchecked    0\n",
      "compare1                      0\n",
      "compare2                      0\n",
      "gpt_embedding                 0\n",
      "closest_texts                 0\n",
      "emotion_no_2nd_neut           0\n",
      "closest_texts_concatenated    0\n",
      "pred_all                      0\n",
      "dtype: int64\n",
      "Sadness             95\n",
      "Neutral             19\n",
      "Hope/Sadness        15\n",
      "Disgust             14\n",
      "Anger/Sadness       12\n",
      "Disgust/Sadness     12\n",
      "Anger               10\n",
      "Hope                 7\n",
      "Fear                 5\n",
      "Anger/Disgust        3\n",
      "Neutral/Sadness      3\n",
      "Anger/Hope           2\n",
      "Disgust/Hope         2\n",
      "Disgust/Fear         2\n",
      "Fear/Sadness         2\n",
      "Hope/Joy             1\n",
      "Disgust/Surprise     1\n",
      "Fear/Hope            1\n",
      "Sadness/Surprise     1\n",
      "Fear/Neutral         1\n",
      "Name: pred_all, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# if one label is the output\n",
    "df_dev['pred_all'] = df_dev['essay_clean_spellchecked'].map( res )\n",
    "print(df_dev.isna().sum())\n",
    "print(df_dev['pred_all'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd26486c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    article_id  conversation_id  speaker_number  essay_id  speaker_id  \\\n",
      "26         233               93               1        92          71   \n",
      "\n",
      "                                                essay  \\\n",
      "26  Unfortunately in countries like these the offi...   \n",
      "\n",
      "                                          essay_clean split  gender  \\\n",
      "26  Unfortunately in countries like these the offi...   dev       1   \n",
      "\n",
      "    education  race  age  income    emotion  emotion_count  char_length  \\\n",
      "26          6     2   32   35000  [Disgust]              1          369   \n",
      "\n",
      "    word_length            target_encoded  \\\n",
      "26           72  [0, 1, 0, 0, 0, 0, 0, 0]   \n",
      "\n",
      "                                              article  \\\n",
      "26  Nigeria investigates reports that officials ra...   \n",
      "\n",
      "                                        article_clean  \\\n",
      "26  Nigeria investigates reports that officials ra...   \n",
      "\n",
      "                                     essay_clean_docs  \\\n",
      "26  (Unfortunately, in, countries, like, these, th...   \n",
      "\n",
      "                             essay_clean_spellchecked  \\\n",
      "26  Unfortunately in countries like these the offi...   \n",
      "\n",
      "                                   article_clean_docs  \\\n",
      "26  (Nigeria, investigates, reports, that, officia...   \n",
      "\n",
      "                           article_clean_spellchecked  compare1  compare2  \\\n",
      "26  Nigeria investigates reports that officials ra...      True      True   \n",
      "\n",
      "                                        gpt_embedding  \\\n",
      "26  [0.0027196165174245834, -0.028233595192432404,...   \n",
      "\n",
      "                                        closest_texts  \\\n",
      "26  [Anything fellow human beings are struggling w...   \n",
      "\n",
      "                           closest_texts_concatenated  \\\n",
      "26  \\nText: The things that people do in the name ...   \n",
      "\n",
      "                                          pred_all  \n",
      "26  Yes, I'm sure. The category is Disappointment.  \n"
     ]
    }
   ],
   "source": [
    "print(df_dev[ df_dev['pred_all']==\"Yes, I'm sure. The category is Disappointment.\"])\n",
    "df_dev.at[ 54, 'pred_all' ] = 'Fear'\n",
    "df_dev.at[ 74, 'pred_all' ] = 'Neutral'\n",
    "df_dev.at[ 26, 'pred_all' ] = 'Sadness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d3a87c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sadness             95\n",
       "Neutral             19\n",
       "Hope/Sadness        15\n",
       "Disgust             14\n",
       "Anger/Sadness       12\n",
       "Disgust/Sadness     12\n",
       "Anger               10\n",
       "Hope                 7\n",
       "Fear                 5\n",
       "Anger/Disgust        3\n",
       "Neutral/Sadness      3\n",
       "Anger/Hope           2\n",
       "Disgust/Hope         2\n",
       "Disgust/Fear         2\n",
       "Fear/Sadness         2\n",
       "Hope/Joy             1\n",
       "Disgust/Surprise     1\n",
       "Fear/Hope            1\n",
       "Sadness/Surprise     1\n",
       "Fear/Neutral         1\n",
       "Name: pred_all, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev['pred_all'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a776945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize predictions\n",
    "df_dev['pred_encoded'] = df_dev['pred_all'].apply( lambda x: get_target(x.split('/')) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8b9092aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anger     0.5926    0.4211    0.4923        38\n",
      "     Disgust     0.4412    0.6250    0.5172        24\n",
      "        Fear     0.3636    0.5000    0.4211         8\n",
      "        Hope     0.3214    0.5625    0.4091        16\n",
      "         Joy     0.0000    0.0000    0.0000         2\n",
      "     Neutral     0.6957    0.2963    0.4156        54\n",
      "     Sadness     0.6714    0.9307    0.7801       101\n",
      "    Surprise     0.0000    0.0000    0.0000         3\n",
      "\n",
      "   micro avg     0.5789    0.6260    0.6016       246\n",
      "   macro avg     0.3857    0.4169    0.3794       246\n",
      "weighted avg     0.5957    0.6260    0.5783       246\n",
      " samples avg     0.6178    0.6394    0.6106       246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_dev_encoded      = np.array( df_dev['target_encoded'].values.tolist() )\n",
    "y_dev_pred_encoded = np.array( df_dev['pred_encoded'].values.tolist() )\n",
    "labels = list(label2key.keys())\n",
    "print( classification_report( y_dev_encoded, y_dev_pred_encoded, target_names=labels, digits=4 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cec02f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a78bedb",
   "metadata": {},
   "source": [
    "# Get keywords, title, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38a846ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model          = 'gpt-4'\n",
    "text_col       = 'essay_clean_spellchecked'\n",
    "emotion_col    = 'emotion_no_2nd_neut'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e339aa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your task is to analyze the text delineated with triple backticks below and extract the important keywords and keyphrases. Return your output as one comma separated list.\n",
      "Text: ```This is a sample text``` \n"
     ]
    }
   ],
   "source": [
    "prompt2 = \"\"\"Your task is to analyze the text delineated with triple backticks below and extract \\\n",
    "the important keywords and keyphrases. Return your output as one comma separated list.\n",
    "Text: ```{}``` \"\"\"\n",
    "sample_text = 'This is a sample text'\n",
    "print( prompt2.format(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e37014d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your task is to analyze the text delineated with triple backticks below and provide a good meaningful title for it. Return just the title and nothing else.\n",
      "Text: ```This is a sample text``` \n"
     ]
    }
   ],
   "source": [
    "prompt3 = \"\"\"Your task is to analyze the text delineated with triple backticks below and provide \\\n",
    "a good meaningful title for it. Return just the title and nothing else.\n",
    "Text: ```{}``` \"\"\"\n",
    "sample_text = 'This is a sample text'\n",
    "print( prompt3.format(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3acd375a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your task is to carefully analyze and summarize the text delineated with triple backticks below. Return just the summary and nothing else.\n",
      "Text: ```This is a sample text``` \n"
     ]
    }
   ],
   "source": [
    "prompt4 = \"\"\"Your task is to carefully analyze and summarize the text delineated with triple backticks \\\n",
    "below. Return just the summary and nothing else.\n",
    "Text: ```{}``` \"\"\"\n",
    "sample_text = 'This is a sample text'\n",
    "print( prompt4.format(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdd6574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcf55846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_request(prompt_):\n",
    "    '''Get a response from ChatGPT / GPT-4 API for a specific prompt'''\n",
    "    messages = [\n",
    "            #{ \"role\": \"system\", \"content\": \"You are a helpful emotion classifier.\", },\n",
    "            { \"role\": \"user\", \"content\": prompt_, },\n",
    "            ]\n",
    "    #if not verify_num_tokens(model, messages): return None\n",
    "    return get_response(model, messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a328a3a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text 10\n",
      "Processing text 20\n",
      "Processing text 30\n",
      "Processing text 40\n",
      "Processing text 50\n",
      "Processing text 60\n",
      "Processing text 70\n",
      "Processing text 80\n",
      "Processing text 90\n",
      "Processing text 100\n",
      "Processing text 110\n",
      "Processing text 120\n",
      "Processing text 130\n",
      "Processing text 140\n",
      "Processing text 150\n",
      "Processing text 160\n",
      "Processing text 170\n",
      "Processing text 180\n",
      "Processing text 190\n",
      "Processing text 200\n",
      "Processing text 210\n",
      "Processing text 220\n",
      "Processing text 230\n",
      "Processing text 240\n",
      "Processing text 250\n",
      "Processing text 260\n",
      "Processing text 270\n",
      "Processing text 280\n",
      "Processing text 290\n",
      "Processing text 300\n",
      "Processing text 310\n",
      "Processing text 320\n",
      "Processing text 330\n",
      "Processing text 340\n",
      "Processing text 350\n",
      "Processing text 360\n",
      "Processing text 370\n",
      "Processing text 380\n",
      "Processing text 390\n",
      "Processing text 400\n",
      "Processing text 410\n",
      "Processing text 420\n",
      "Processing text 430\n",
      "Processing text 440\n",
      "Processing text 450\n",
      "Processing text 460\n",
      "Processing text 470\n",
      "Processing text 480\n",
      "Processing text 490\n",
      "Processing text 500\n",
      "Processing text 510\n",
      "Processing text 520\n",
      "Processing text 530\n",
      "Processing text 540\n",
      "Processing text 550\n",
      "Processing text 560\n",
      "Processing text 570\n",
      "Processing text 580\n",
      "Processing text 590\n",
      "Processing text 600\n",
      "Processing text 610\n",
      "Processing text 620\n",
      "Processing text 630\n",
      "Processing text 640\n",
      "Processing text 650\n",
      "Processing text 660\n",
      "Processing text 670\n",
      "Processing text 680\n",
      "Processing text 690\n",
      "Processing text 700\n",
      "Processing text 710\n",
      "Processing text 720\n",
      "Processing text 730\n",
      "Processing text 740\n",
      "Processing text 750\n",
      "Processing text 760\n",
      "\n",
      "Time elapsed 101.6032 min\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#res   = dict()\n",
    "count = 0\n",
    "for text in df_train[text_col].values:\n",
    "    if text in res:\n",
    "        continue\n",
    "    prompt = prompt2.format(text)   \n",
    "    try:\n",
    "        res[ text ] = submit_request( prompt )\n",
    "    except Exception as e:\n",
    "        print(f'\\nText: {text}\\nError: {e}\\n')\n",
    "                \n",
    "    count += 1    \n",
    "    if count % 10 == 0:\n",
    "        print(f'Processing text {count}')                        \n",
    "        \n",
    "elapsed = (time.time() - start)/60\n",
    "print(f'\\nTime elapsed {round(elapsed, 4)} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "627ae4a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'It breaks my heart to see people living in those conditions. I hope that all the aid that was sent to the island makes it to the people who need it the most. I do not know what I would do it that was my family and I. I would hope that I would do my best, but I can see how depressing and hopeless you could feel having your whole life changed because of a storm and not knowing where your next meal is coming from.': 'breaks my heart, people living, conditions, aid, island, need, family, depressing, hopeless, whole life changed, storm, next meal',\n",
       " \"I wonder why there aren't more people trying to help these people. I understand Haiti is not the richest nor less corrupt country but surely there must be a way to help. Supplies being looted by crowds is understandable because they are hungry and people need food and water to survive. We must think of other ways to distribute the food and water.\": 'people, help, Haiti, richest, corrupt country, supplies, looted, crowds, hungry, food, water, survive, distribute',\n",
       " \"After reading the article, you can't help but feel really sad and terrible for the people that were affected by the hurricane. It was a situation that they did not deserve and one that they most likely did not cause but mother nature has other plans for us. I feel bad for all the children as well as animals that are there as well with no shelter or food.\": 'reading, article, sad, terrible, people, affected, hurricane, situation, deserve, mother nature, plans, children, animals, shelter, food',\n",
       " 'It is so sad that someone who had such an amazing story died in such a freak accident. His life was filled with amazing triumphs only for him to die in such a sad way. It is truly heart breaking to think about. He came from nothing and truly got the american dream. He died in such a rare and crazy way that it is so sad.': 'sad, amazing story, freak accident, life, amazing triumphs, die, heart breaking, came from nothing, American dream, rare, crazy way',\n",
       " 'From reading the article, it looks like the world lost a kindhearted and generous person. If no drugs or alcohol were involved in the accident. I wonder what happen to make them crash. I wonder if it was common to be on the boat with no life jacket. The life jacket may not even mattered because of the speed and the rocks.': 'reading, article, world, lost, kindhearted, generous person, drugs, alcohol, accident, crash, boat, life jacket, speed, rocks',\n",
       " \"That's sad. Regardless of what they find out happened, who was controlling what or if they had drugs in their system or whatever, it's sad. I don't know that they will find out anything, i just feel like lots of people will turn this into something it's not. It's unfortunate anytime a young person like this, with the world at their fingertips, loses their life in something that was controllable.\": 'sad, find out, happened, controlling, drugs, system, young person, world, fingertips, loses, life, controllable, unfortunate',\n",
       " 'After reading the article, my reaction is that it is very sad that boys that young have to be put behind bars. I think that children should be able to experience their childhood and have fun at that age. They should not be facing hardships at all. They should be playing with friends and be in school at that age and not locked up behind a cell.': 'reading, article, reaction, sad, boys, young, behind bars, children, experience, childhood, fun, age, facing hardships, playing, friends, school, locked up, cell',\n",
       " 'It sounds like these boys had a really rough life. I do think we all have personal responsibility for our choices at the end of the day though. Even though you might have it rough, ultimately it is up to you to decide to break the law or use drugs or not. So they had free will too and could have exercised that. Regardless, it is still sad that they went through a rough childhood. Nobody should have to endure that and kids are the saddest victims.': 'sounds, boys, rough life, personal responsibility, choices, end of the day, rough, ultimately, decide, break the law, use drugs, free will, exercised, sad, rough childhood, endure, kids, saddest victims',\n",
       " 'This is a tragic and sad story about how some children can experience the foster care system. Shelton bounced from one home to another, getting into trouble along the way, before beginning a life of crime and going to prison as a young adult and then as an adult. Given the way he was raised, it is almost impossible to imagine an alternate ending.': 'tragic, sad story, children, foster care system, Shelton, one home to another, trouble, life of crime, prison, young adult, adult, raised, impossible, alternate ending',\n",
       " \"Hello. I feel really terrible about the current coal mining situation in India. Many lives have been lost, properties destroyed, so many losses for the people of that country. It's really pathetic how the government has failed in their duty to protect the citizens. It's even more worrisome that they have also failed to compensate the victims. It's a pity\": 'coal mining, India, lives lost, properties destroyed, losses, government, duty, protect citizens, compensate, victims, pathetic, worrisome, pity',\n",
       " 'I find it disturbing that thousands of acres of forest land are destroyed to mining, foraging elephants attracted by the crops in the fields often enter villages, resulting in an alarmingly high number of human-elephant conflict situations. This shouldnt be. This is wrong. I mean the selfishness of some people shouldnt be a problem for all': 'disturbing, thousands of acres, forest land, destroyed, mining, foraging elephants, attracted, crops, fields, enter villages, alarmingly high number, human-elephant conflict, wrong, selfishness, problem',\n",
       " \"That's so sad about the situation with the coal and all the wildlife it's misplacing. It was kind of crazy reading the story about having the elephant crash into those people's houses -- i can't imagine having a giant two ton creature come through my wall! I'm glad no one was hurt, but it still sounds pretty scary.\": \"sad, situation, coal, wildlife, misplacing, crazy, reading, story, elephant crash, people's houses, giant, two ton creature, wall, no one hurt, scary\",\n",
       " \"It's very tragic what happened to this woman. It just seems like it was so avoidable. There were so many warning signs that were ignored where people could have intervened and gotten her the help she needed. I just think things like this happen too often where people get swept under the rug and professionals and others overlook what should really be treated as major warning signs. I think lives could be saved if people would be a little more attentive to things like this.\": 'tragic, woman, avoidable, warning signs, ignored, intervened, help, swept under the rug, professionals, major warning signs, lives, saved, attentive',\n",
       " \"That article is so sad. I feel so bad for her, that she wasn't able to get the help that she needed. I also feel bad for her family. I can't imagine how bad they feel and how helpless they felt seeing their family member going through something and not being able to help them. I hope that mental health services improve so that things like that don't continue to happen.\": \"article, sad, feel bad, help, needed, family, imagine, helpless, family member, going through, mental health services, improve, don't continue to happen\",\n",
       " 'I just read a really interesting but depressing article. It was about a woman who lived in the UK. She was the founding editor of Elle magazine. She was only thirty when the magazine started which is crazy to me. Imagine being thirty and running a whole magazine. She suffered from depression all of her life and even wrote a book about it. She was admitted into a mental hospital because she was struggling with her depression. The mental hospital cleared her and let her go. Soon after she walked into the ocean and drowned. It is so sad that she did not get the help she needed. I hope all of our friends know that we are here for them and support them no matter whatthey are going through.': 'interesting, depressing article, woman, UK, founding editor, Elle magazine, thirty, depression, book, mental hospital, struggling, ocean, drowned, help, support, friends',\n",
       " \"After reading the article, i really felt bad for the lady. I felt like she was just trying to get some help for her mental state and people didn't really believe her. I felt like people were just brushing off the fact that she needed help and it was pretty disturbing. I think that society as a whole needs to understand mental health better and how to help people.\": \"reading, article, felt bad, lady, mental state, help, people, didn't believe, brushing off, needed help, disturbing, society, understand, mental health, better\",\n",
       " \"It's sad that people anywhere are still threatened because of their beliefs. I don't understand why any religion is so set against other that they want to hurt, kill and threaten them. How does someone else's belief harm your own? I guess I just don't get why people get so fanatic about religion and ignore parts of the teachings about tolerance, peace and understanding. It seems wrong that people use religion as an excuse for violence.\": 'sad, people, threatened, beliefs, religion, set against, hurt, kill, threaten, belief, harm, fanatic, tolerance, peace, understanding, excuse, violence',\n",
       " \"This was a sad situation. It is unfair for all these people to live in such conflict and persecution fo their beliefs. It makes me very grateful to live somewhere that I have the freedom to believe what I want. People complain so much about America and don't realize how good we have it here. These people are literally dying just for what they believe which is really sad. I feel sad for the families.\": 'sad situation, unfair, conflict, persecution, beliefs, grateful, freedom, America, good, dying, families',\n",
       " \"I was saddened by the content in the article. I do think PTSD is real and is a serious issue. I can't even imagine what those soldiers have to go through, and I hope that my loved ones never find out. I think it's understandable that adjusting back would be difficult. I really think we need to do better taking care of our troops... even in the beginning. Do we really need them? Are we putting their interests at heart, or just our political ones?\": 'saddened, content, article, PTSD, real, serious issue, soldiers, loved ones, adjusting back, difficult, taking care, troops, beginning, interests, heart, political',\n",
       " \"The fact that we don't take care of our veterans is worse than sad. We have a duty to honor them and take care of them. I'm happy to see so many people speaking out and making issues with PTSD more easy to talk about. We can't keep ignoring these issues and pretending that we just can't do anything for our vets. We need to make sure we take more time to work with each vet and get them the help they not only need but deserve!\": 'veterans, take care, duty, honor, PTSD, speaking out, ignoring issues, help, deserve, work with each vet',\n",
       " 'PTSD is a tough problem to have I feel bad for those veterans that have to deal with it they must relive those awful memories over and over again in their mind it can not be easy to live with all the things that they had to go through in the theater of war they need to spend more on mental health for them.': 'PTSD, tough problem, veterans, deal with, relive, awful memories, mind, live with, theater of war, mental health, spend more',\n",
       " \"The sights and sounds of war are horrible and I would never blame a person for having PTSD. I'm happy that the one solider although he has PTSD, he is working though it and wants to show people that now all people with PTSD are dangerous and there is away to heal yourself after being in a such bad of a place.\": 'sights and sounds of war, horrible, PTSD, one solider, working through, show people, not dangerous, heal yourself, bad place',\n",
       " \"I had never considered the zoos in countries like Venezuela. I'm concerned that it seems like they're being fined and punished for their predicament. I think other zoos throughout the world should step up and try to rescue the animals, or at the very least, preserve them for a scientific purpose and euthanize them humanely. Those that are endangered should be removed. It's just a terrible situation for everyone, but the zoo owners and animals aren't at fault, it's the political constraints.\": 'zoos, Venezuela, fined, punished, predicament, rescue animals, scientific purpose, euthanize, humanely, endangered, removed, terrible situation, zoo owners, political constraints',\n",
       " \"I find the article comical. In these places, people are starving to death and the concern of some people is whether zoo animals are getting enough to eat. The zoo animals should be slaughtered to feed people. The horses slaughtered to feed to animals should be fed to people. The animals probably shouldn't be in zoos to begin with, but now that they are they shouldn't come before human needs. That's idiotic. Just butcher the zoo animals, feed them to people, and be done with the problem. That's my opinion.\": 'article comical, starving to death, zoo animals, enough to eat, slaughtered, feed people, horses, human needs, idiotic, butcher, my opinion',\n",
       " 'I just read an article about how animals in Venezuela are starving to death because of the turmoil that is happening in that country. I feel like there should be some kind of action plan in place for animals in countries that are experiencing hardship so that they can be transported to other places in times of crisis. The thought of innocent creatures starving to death in cages really turns my stomach.': 'animals, Venezuela, starving, death, turmoil, country, action plan, countries, experiencing hardship, transported, other places, times of crisis, innocent creatures, cages, turns my stomach'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d184e6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "792 792\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train), len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "356154cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['gpt4_keywords'] = df_train[text_col].map( res )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b403f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "435dbe94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text 10\n",
      "Processing text 20\n",
      "Processing text 30\n",
      "Processing text 40\n",
      "Processing text 50\n",
      "Processing text 60\n",
      "Processing text 70\n",
      "Processing text 80\n",
      "Processing text 90\n",
      "Processing text 100\n",
      "Processing text 110\n",
      "Processing text 120\n",
      "Processing text 130\n",
      "Processing text 140\n",
      "Processing text 150\n",
      "Processing text 160\n",
      "Processing text 170\n",
      "Processing text 180\n",
      "Processing text 190\n",
      "Processing text 200\n",
      "\n",
      "Time elapsed 27.9552 min\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "res2   = dict()\n",
    "count = 0\n",
    "for text in df_dev[text_col].values:\n",
    "    if text in res2:\n",
    "        continue\n",
    "    prompt = prompt2.format(text)   \n",
    "    try:\n",
    "        res2[ text ] = submit_request( prompt )\n",
    "    except Exception as e:\n",
    "        print(f'\\nText: {text}\\nError: {e}\\n')\n",
    "                \n",
    "    count += 1    \n",
    "    if count % 10 == 0:\n",
    "        print(f'Processing text {count}')                        \n",
    "        \n",
    "elapsed = (time.time() - start)/60\n",
    "print(f'\\nTime elapsed {round(elapsed, 4)} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aa71da1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208 208\n"
     ]
    }
   ],
   "source": [
    "print(len(df_dev), len(res2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0ee88e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev['gpt4_keywords'] = df_dev[text_col].map( res2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e11692d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-4'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "87bd66e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['breaks my heart, people living, conditions, aid, island, need, family, depressing, hopeless, whole life changed, storm, next meal',\n",
       "       'people, help, Haiti, richest, corrupt country, supplies, looted, crowds, hungry, food, water, survive, distribute',\n",
       "       'reading, article, sad, terrible, people, affected, hurricane, situation, deserve, mother nature, plans, children, animals, shelter, food',\n",
       "       'sad, amazing story, freak accident, life, amazing triumphs, die, heart breaking, came from nothing, American dream, rare, crazy way',\n",
       "       'reading, article, world, lost, kindhearted, generous person, drugs, alcohol, accident, crash, boat, life jacket, speed, rocks',\n",
       "       'sad, find out, happened, controlling, drugs, system, young person, world, fingertips, loses, life, controllable, unfortunate',\n",
       "       'reading, article, reaction, sad, boys, young, behind bars, children, experience, childhood, fun, age, facing hardships, playing, friends, school, locked up, cell',\n",
       "       'sounds, boys, rough life, personal responsibility, choices, end of the day, rough, ultimately, decide, break the law, use drugs, free will, exercised, sad, rough childhood, endure, kids, saddest victims',\n",
       "       'tragic, sad story, children, foster care system, Shelton, one home to another, trouble, life of crime, prison, young adult, adult, raised, impossible, alternate ending',\n",
       "       'coal mining, India, lives lost, properties destroyed, losses, government, duty, protect citizens, compensate, victims, pathetic, worrisome, pity'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['gpt4_keywords'].values[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb1f7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f1494011",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'data/df_train.pkl'\n",
    "df_train.to_pickle( file )\n",
    "\n",
    "file = 'data/df_dev.pkl'\n",
    "df_dev.to_pickle( file )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a970f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "caae703c",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44813760",
   "metadata": {},
   "source": [
    "Conclusions:\n",
    "* Temperature = 0 consistently outperforms temp = 0.5\n",
    "* Concatenating random examples outperforms concatenating 30 closest examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8449ca2",
   "metadata": {},
   "source": [
    "### Concatenate random ~30 examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd9546a",
   "metadata": {},
   "source": [
    "__Experiment 10__:  __BEST__  \n",
    "Column = 'spellchecked', temperature = 0  \n",
    "No system role, __second Neutral removed__    \n",
    "_Prompt_:  concatentaed examples (no list of instructions)\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       Anger     0.5200    0.3421    0.4127        38\n",
    "     Disgust     0.3846    0.6250    0.4762        24\n",
    "        Fear     0.4375    0.8750    0.5833         8\n",
    "        Hope     0.2667    0.5000    0.3478        16\n",
    "         Joy     0.3333    0.5000    0.4000         2\n",
    "     Neutral     0.7391    0.3148    0.4416        54\n",
    "     Sadness     0.7132    0.9109    0.8000       101\n",
    "    Surprise     0.3333    0.3333    0.3333         3\n",
    "\n",
    "   micro avg     0.5746    0.6260    0.5992       246\n",
    "   macro avg     0.4660    0.5501    0.4744       246\n",
    "weighted avg     0.6113    0.6260    0.5845       246\n",
    " samples avg     0.6170    0.6370    0.6077       246\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe2dd1f",
   "metadata": {},
   "source": [
    "__Experiment 12__  \n",
    "Same as 10, but the example dfs were exploded - to avoid examples with double categories  \n",
    "This is an example of a case when ChatGPT learns one category, outputs one category per essay. Prompt is needed to make sure 2 categories are output when relevant (see Experiment 14)\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       Anger     0.5000    0.3421    0.4063        38\n",
    "     Disgust     0.5000    0.4583    0.4783        24\n",
    "        Fear     0.3000    0.3750    0.3333         8\n",
    "        Hope     0.2500    0.3125    0.2778        16\n",
    "         Joy     0.5000    0.5000    0.5000         2\n",
    "     Neutral     0.6800    0.3148    0.4304        54\n",
    "     Sadness     0.8200    0.8119    0.8159       101\n",
    "    Surprise     0.3333    0.3333    0.3333         3\n",
    "\n",
    "   micro avg     0.6394    0.5407    0.5859       246\n",
    "   macro avg     0.4854    0.4310    0.4469       246\n",
    "weighted avg     0.6461    0.5407    0.5759       246\n",
    " samples avg     0.6394    0.5601    0.5865       246\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3229da",
   "metadata": {},
   "source": [
    "__Experiment 14__\n",
    "Same as 11, but the example dfs were exploded - to avoid examples with double categories  \n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       Anger     0.5600    0.3684    0.4444        38\n",
    "     Disgust     0.5000    0.5833    0.5385        24\n",
    "        Fear     0.2692    0.8750    0.4118         8\n",
    "        Hope     0.2400    0.3750    0.2927        16\n",
    "         Joy     0.0000    0.0000    0.0000         2\n",
    "     Neutral     0.6875    0.2037    0.3143        54\n",
    "     Sadness     0.7788    0.8020    0.7902       101\n",
    "    Surprise     0.0000    0.0000    0.0000         3\n",
    "\n",
    "   micro avg     0.5911    0.5407    0.5648       246\n",
    "   macro avg     0.3794    0.4009    0.3490       246\n",
    "weighted avg     0.6303    0.5407    0.5471       246\n",
    " samples avg     0.6058    0.5601    0.5681       246\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312de0a5",
   "metadata": {},
   "source": [
    "__Experiment 11__:  \n",
    "Column = 'spellchecked', temperature = 0  \n",
    "No system role, __second Neutral removed__    \n",
    "```\n",
    "_Prompt_:  \n",
    "1 - Below you are given examples of essays with categories separated by four hashtags.\n",
    "2 - Each essay has one or two relevant categories from the following list: Sadness, Neutral, Anger, Disgust, Fear, Hope, Surprise, Joy.\n",
    "3 - Your task is to carefully learn from the examples of essays with categories in order to understand what features or words in the essays make them belong to a specific category and then use this knowledge to assign the correct relevant category from the above list to the very last essay.\n",
    "4 - You may add a second category from the above list ONLY AND ONLY IF it is also relevant to the very last essay.\n",
    "5 - Output just the category or categories for the last essay and nothing else. If there are two relevant categories: sort them alphabetically, concatenate with a forward slash, and output only them and nothing else.\n",
    "\n",
    "####\n",
    "\n",
    "+ concatentaed examples\n",
    "\n",
    "Followup:  \n",
    "Are you sure about that? If yes - repeat the same output, if no - change the category, but make sure it's from the list of predefined categories\n",
    "\n",
    "\n",
    "```\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       Anger     0.6154    0.4211    0.5000        38\n",
    "     Disgust     0.4054    0.6250    0.4918        24\n",
    "        Fear     0.2857    0.7500    0.4138         8\n",
    "        Hope     0.2759    0.5000    0.3556        16\n",
    "         Joy     1.0000    0.5000    0.6667         2\n",
    "     Neutral     0.8667    0.2407    0.3768        54\n",
    "     Sadness     0.7154    0.9208    0.8052       101\n",
    "    Surprise     0.0000    0.0000    0.0000         3\n",
    "\n",
    "   micro avg     0.5779    0.6179    0.5972       246\n",
    "   macro avg     0.5206    0.4947    0.4512       246\n",
    "weighted avg     0.6539    0.6179    0.5805       246\n",
    " samples avg     0.6154    0.6346    0.6026       246\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a39e654",
   "metadata": {},
   "source": [
    "__Experiment 5__:  \n",
    "Column = 'spellchecked', temperature = 0  \n",
    "No system role, second Neutral not removed    \n",
    "\n",
    "_Prompt_: concatentaed examples (no list of instructions)\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       Anger     0.5000    0.3421    0.4063        38\n",
    "     Disgust     0.3023    0.5417    0.3881        24\n",
    "        Fear     0.4444    1.0000    0.6154         8\n",
    "        Hope     0.2759    0.5000    0.3556        16\n",
    "         Joy     0.2500    0.5000    0.3333         2\n",
    "     Neutral     0.6667    0.3333    0.4444        54\n",
    "     Sadness     0.7381    0.9208    0.8194       101\n",
    "    Surprise     0.1250    0.3333    0.1818         3\n",
    "\n",
    "   micro avg     0.5516    0.6301    0.5882       246\n",
    "   macro avg     0.4128    0.5589    0.4430       246\n",
    "weighted avg     0.5921    0.6301    0.5827       246\n",
    " samples avg     0.6010    0.6442    0.5986       246\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d3cf08",
   "metadata": {},
   "source": [
    "__Experiment 4__  \n",
    "Column = 'spellchecked', temperature = 0.5  \n",
    "No system role, second Neutral not removed    \n",
    "\n",
    "_Prompt_: concatentaed examples (no list of instructions)\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       Anger     0.5600    0.3684    0.4444        38\n",
    "     Disgust     0.3556    0.6667    0.4638        24\n",
    "        Fear     0.3500    0.8750    0.5000         8\n",
    "        Hope     0.2333    0.4375    0.3043        16\n",
    "         Joy     0.2500    0.5000    0.3333         2\n",
    "     Neutral     0.6538    0.3148    0.4250        54\n",
    "     Sadness     0.7381    0.9208    0.8194       101\n",
    "    Surprise     0.1250    0.3333    0.1818         3\n",
    "\n",
    "   micro avg     0.5493    0.6341    0.5887       246\n",
    "   macro avg     0.4082    0.5521    0.4340       246\n",
    "weighted avg     0.5979    0.6341    0.5846       246\n",
    " samples avg     0.5913    0.6466    0.5929       246\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c97b5d1",
   "metadata": {},
   "source": [
    "__Experiment 3__  \n",
    "Column = 'spellchecked', temperature = 0.5\n",
    "No system role, second Neutral not removed    \n",
    "Same prompt\n",
    "\n",
    "```\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "       Anger     0.5000    0.3421    0.4063        38\n",
    "     Disgust     0.3409    0.6250    0.4412        24\n",
    "        Fear     0.2857    0.7500    0.4138         8\n",
    "        Hope     0.2326    0.6250    0.3390        16\n",
    "         Joy     0.0000    0.0000    0.0000         2\n",
    "     Neutral     0.7037    0.3519    0.4691        54\n",
    "     Sadness     0.6889    0.9208    0.7881       101\n",
    "    Surprise     0.2000    0.3333    0.2500         3\n",
    "\n",
    "   micro avg     0.5199    0.6382    0.5730       246\n",
    "   macro avg     0.3690    0.4935    0.3884       246\n",
    "weighted avg     0.5747    0.6382    0.5709       246\n",
    " samples avg     0.5697    0.6514    0.5841       246\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68050f7",
   "metadata": {},
   "source": [
    "__Experiment 2__  \n",
    "Column = 'spellchecked', temperature = 0  \n",
    "No system role used, second Neutral not removed      \n",
    "Same prompt  \n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       Anger     0.5833    0.3684    0.4516        38\n",
    "     Disgust     0.3684    0.5833    0.4516        24\n",
    "        Fear     0.3810    1.0000    0.5517         8\n",
    "        Hope     0.2143    0.5625    0.3103        16\n",
    "         Joy     0.3333    0.5000    0.4000         2\n",
    "     Neutral     0.6923    0.3333    0.4500        54\n",
    "     Sadness     0.6861    0.9307    0.7899       101\n",
    "    Surprise     0.2000    0.3333    0.2500         3\n",
    "\n",
    "   micro avg     0.5372    0.6463    0.5867       246\n",
    "   macro avg     0.4323    0.5765    0.4569       246\n",
    "weighted avg     0.5912    0.6463    0.5813       246\n",
    " samples avg     0.5865    0.6587    0.5962       246\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0c6fd2",
   "metadata": {},
   "source": [
    "__Experiment 1__  \n",
    "Column = 'spellchecked', temperature = 0  \n",
    "Using system role: { \"role\": \"system\", \"content\": \"You are a helpful emotion classifier.\", }   \n",
    "Second Neutral not removed  \n",
    "\n",
    "_Prompt_  \n",
    "```\n",
    "1 - Below you are given examples of texts with their most relevant emotion categories. The examples are separated by four hashtags.\n",
    "2 - Each text can belong to one or two most relevant emotion categories from the following list: Sadness, Neutral, Anger, Disgust, Fear, Hope, Surprise, Joy.\n",
    "3 - Your task is to classify the last text by selecting the most relevant emotion category from the above list. You may add a second emotion category from the above list ONLY AND ONLY IF it is also relevant to the last text.\n",
    "4 - Before you perform your task, carefully learn from the examples of texts with their categories and then classify the last text based on this acquired knowledge.\n",
    "5 - Output just the category or categories for the last text and nothing else. If there are two relevant emotion categories: sort them alphabetically, concatenate with a forward slash, and output only them and nothing else.\n",
    "\n",
    "+ concatentaed examples\n",
    "```\n",
    "\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       Anger     0.5357    0.3947    0.4545        38\n",
    "     Disgust     0.3182    0.5833    0.4118        24\n",
    "        Fear     0.3200    1.0000    0.4848         8\n",
    "        Hope     0.2286    0.5000    0.3137        16\n",
    "         Joy     0.0000    0.0000    0.0000         2\n",
    "     Neutral     0.6250    0.2778    0.3846        54\n",
    "     Sadness     0.6667    0.9109    0.7699       101\n",
    "    Surprise     0.2000    0.3333    0.2500         3\n",
    "\n",
    "   micro avg     0.5100    0.6220    0.5604       246\n",
    "   macro avg     0.3618    0.5000    0.3837       246\n",
    "weighted avg     0.5524    0.6220    0.5501       246\n",
    " samples avg     0.5481    0.6346    0.5673       246\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b5444b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "539ea22b",
   "metadata": {},
   "source": [
    "### Concatenate closest 30 examples (cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51892f5d",
   "metadata": {},
   "source": [
    "__Experiment 9__  \n",
    "Exactly as experiment 8, but Neutral was removed from coupled emotion categories  \n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       Anger     0.5926    0.4211    0.4923        38\n",
    "     Disgust     0.4412    0.6250    0.5172        24\n",
    "        Fear     0.3636    0.5000    0.4211         8\n",
    "        Hope     0.3214    0.5625    0.4091        16\n",
    "         Joy     0.0000    0.0000    0.0000         2\n",
    "     Neutral     0.6957    0.2963    0.4156        54\n",
    "     Sadness     0.6714    0.9307    0.7801       101\n",
    "    Surprise     0.0000    0.0000    0.0000         3\n",
    "\n",
    "   micro avg     0.5789    0.6260    0.6016       246\n",
    "   macro avg     0.3857    0.4169    0.3794       246\n",
    "weighted avg     0.5957    0.6260    0.5783       246\n",
    " samples avg     0.6178    0.6394    0.6106       246\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abdd6ca",
   "metadata": {},
   "source": [
    "__Experiment 8__  \n",
    "Column = 'essay_clean_spellchecked', tempereture = 0  \n",
    "No system role, second Neutral not removed    \n",
    "Prompt:  \n",
    "```\n",
    "1 - Below you are given examples of texts with their most relevant emotion categories. The examples are separated by four hashtags.\n",
    "2 - Each text can belong to one or two most relevant emotion categories from the following list: Sadness, Neutral, Anger, Disgust, Fear, Hope, Surprise, Joy.\n",
    "3 - Your task is to carefully learn from the examples of texts with their categories and then use the acquired knowledge to classify the very last text by selecting the most relevant emotion category from the above list.\n",
    "4 - You may add a second emotion category from the above list ONLY AND ONLY IF it is also relevant to the very last text.\n",
    "5 - Output just the category or categories for the last text and nothing else. If there are two relevant emotion categories: sort them alphabetically, concatenate with a forward slash, and output only them and nothing else.\n",
    "\n",
    " + concatenated examples\n",
    "```\n",
    "\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       Anger     0.5714    0.4211    0.4848        38\n",
    "     Disgust     0.4688    0.6250    0.5357        24\n",
    "        Fear     0.4000    0.5000    0.4444         8\n",
    "        Hope     0.3333    0.5625    0.4186        16\n",
    "         Joy     0.0000    0.0000    0.0000         2\n",
    "     Neutral     0.7037    0.3519    0.4691        54\n",
    "     Sadness     0.6690    0.9406    0.7819       101\n",
    "    Surprise     0.0000    0.0000    0.0000         3\n",
    "\n",
    "   micro avg     0.5896    0.6423    0.6148       246\n",
    "   macro avg     0.3933    0.4251    0.3918       246\n",
    "weighted avg     0.5978    0.6423    0.5928       246\n",
    " samples avg     0.6298    0.6611    0.6258       246\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0859fad",
   "metadata": {},
   "source": [
    "__Experiment 7__  \n",
    "Column = 'essay_clean', tempereture = 0  \n",
    "No system role, second Neutral not removed      \n",
    "Prompt:  \n",
    "```\n",
    "1 - Below you are given examples of texts with their most relevant emotion categories. The examples are separated by four hashtags.\n",
    "2 - Each text can belong to one or two most relevant emotion categories from the following list: Sadness, Neutral, Anger, Disgust, Fear, Hope, Surprise, Joy.\n",
    "3 - Your task is to carefully learn from the examples of texts with their categories and then use the acquired knowledge to classify the very last text by selecting the most relevant emotion category from the above list.\n",
    "4 - You may add a second emotion category from the above list ONLY AND ONLY IF it is also relevant to the very last text.\n",
    "5 - Output just the category or categories for the last text and nothing else. If there are two relevant emotion categories: sort them alphabetically, concatenate with a forward slash, and output only them and nothing else.\n",
    "\n",
    " + concatenated examples\n",
    "```\n",
    "\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       Anger     0.5517    0.4211    0.4776        38\n",
    "     Disgust     0.4375    0.5833    0.5000        24\n",
    "        Fear     0.4000    0.5000    0.4444         8\n",
    "        Hope     0.3214    0.5625    0.4091        16\n",
    "         Joy     0.0000    0.0000    0.0000         2\n",
    "     Neutral     0.7037    0.3519    0.4691        54\n",
    "     Sadness     0.6738    0.9406    0.7851       101\n",
    "    Surprise     0.0000    0.0000    0.0000         3\n",
    "\n",
    "   micro avg     0.5836    0.6382    0.6097       246\n",
    "   macro avg     0.3860    0.4199    0.3857       246\n",
    "weighted avg     0.5929    0.6382    0.5889       246\n",
    " samples avg     0.6226    0.6538    0.6194       246\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555c6785",
   "metadata": {},
   "source": [
    "__Example 6__  \n",
    "Column = 'essay_clean', tempereture = 0  \n",
    "No system role, second Neutral not removed      \n",
    "_Prompt_: concatenated examples (no list instructions)\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       Anger     0.5357    0.3947    0.4545        38\n",
    "     Disgust     0.4000    0.5000    0.4444        24\n",
    "        Fear     0.5455    0.7500    0.6316         8\n",
    "        Hope     0.2609    0.3750    0.3077        16\n",
    "         Joy     0.0000    0.0000    0.0000         2\n",
    "     Neutral     0.6129    0.3519    0.4471        54\n",
    "     Sadness     0.6741    0.9010    0.7712       101\n",
    "    Surprise     0.3333    0.3333    0.3333         3\n",
    "\n",
    "   micro avg     0.5725    0.6098    0.5906       246\n",
    "   macro avg     0.4203    0.4507    0.4237       246\n",
    "weighted avg     0.5718    0.6098    0.5730       246\n",
    " samples avg     0.6106    0.6130    0.5962       246\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1855e62a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76e64fdf",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57ff31a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length X: 792\n",
      "Total chunks length: 792 \n",
      "\n",
      "Sadness     22\n",
      "Neutral     12\n",
      "Anger        6\n",
      "Disgust      5\n",
      "Hope         3\n",
      "Fear         2\n",
      "Surprise     1\n",
      "Name: emotion, dtype: int64\n",
      "Num tokens: 3480\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Sadness     22\n",
      "Neutral     14\n",
      "Anger        6\n",
      "Disgust      4\n",
      "Surprise     2\n",
      "Hope         2\n",
      "Fear         1\n",
      "Joy          1\n",
      "Name: emotion, dtype: int64\n",
      "Num tokens: 3819\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Sadness     21\n",
      "Neutral     14\n",
      "Anger        5\n",
      "Disgust      4\n",
      "Hope         2\n",
      "Surprise     2\n",
      "Fear         2\n",
      "Joy          1\n",
      "Name: emotion, dtype: int64\n",
      "Num tokens: 3744\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Sadness     21\n",
      "Neutral     14\n",
      "Anger        6\n",
      "Disgust      4\n",
      "Hope         2\n",
      "Fear         2\n",
      "Joy          1\n",
      "Surprise     1\n",
      "Name: emotion, dtype: int64\n",
      "Num tokens: 3946\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Sadness     21\n",
      "Neutral     14\n",
      "Anger        7\n",
      "Disgust      5\n",
      "Hope         2\n",
      "Fear         2\n",
      "Surprise     1\n",
      "Name: emotion, dtype: int64\n",
      "Num tokens: 3801\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Sadness     20\n",
      "Neutral     13\n",
      "Anger        8\n",
      "Disgust      5\n",
      "Hope         2\n",
      "Surprise     2\n",
      "Fear         2\n",
      "Name: emotion, dtype: int64\n",
      "Num tokens: 3777\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Sadness     21\n",
      "Neutral     13\n",
      "Anger        9\n",
      "Disgust      5\n",
      "Fear         2\n",
      "Hope         2\n",
      "Surprise     1\n",
      "Name: emotion, dtype: int64\n",
      "Num tokens: 3844\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Sadness     21\n",
      "Neutral     13\n",
      "Anger        9\n",
      "Disgust      5\n",
      "Fear         2\n",
      "Hope         2\n",
      "Surprise     1\n",
      "Name: emotion, dtype: int64\n",
      "Num tokens: 3611\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Sadness    21\n",
      "Neutral    14\n",
      "Anger       8\n",
      "Disgust     6\n",
      "Fear        2\n",
      "Hope        2\n",
      "Name: emotion, dtype: int64\n",
      "Num tokens: 4086\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Sadness    21\n",
      "Neutral    14\n",
      "Anger       8\n",
      "Disgust     6\n",
      "Hope        2\n",
      "Fear        2\n",
      "Name: emotion, dtype: int64\n",
      "Num tokens: 4222\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Sadness    22\n",
      "Neutral    15\n",
      "Anger       7\n",
      "Disgust     6\n",
      "Fear        2\n",
      "Joy         1\n",
      "Hope        1\n",
      "Name: emotion, dtype: int64\n",
      "Num tokens: 4043\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Sadness    22\n",
      "Neutral    13\n",
      "Anger       7\n",
      "Disgust     6\n",
      "Fear        3\n",
      "Hope        2\n",
      "Name: emotion, dtype: int64\n",
      "Num tokens: 3991\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Sadness     23\n",
      "Neutral     13\n",
      "Anger        7\n",
      "Disgust      6\n",
      "Hope         2\n",
      "Joy          1\n",
      "Surprise     1\n",
      "Fear         1\n",
      "Name: emotion, dtype: int64\n",
      "Num tokens: 3994\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Sadness     21\n",
      "Neutral     13\n",
      "Disgust      8\n",
      "Anger        6\n",
      "Hope         2\n",
      "Fear         1\n",
      "Joy          1\n",
      "Surprise     1\n",
      "Name: emotion, dtype: int64\n",
      "Num tokens: 3800\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Sadness     21\n",
      "Neutral     13\n",
      "Disgust      8\n",
      "Anger        6\n",
      "Hope         2\n",
      "Fear         1\n",
      "Surprise     1\n",
      "Joy          1\n",
      "Name: emotion, dtype: int64\n",
      "Num tokens: 3905\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Sadness     21\n",
      "Neutral     13\n",
      "Anger        6\n",
      "Disgust      6\n",
      "Fear         2\n",
      "Surprise     2\n",
      "Joy          1\n",
      "Name: emotion, dtype: int64\n",
      "Num tokens: 4149\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Sadness     21\n",
      "Neutral     13\n",
      "Disgust      6\n",
      "Anger        6\n",
      "Surprise     2\n",
      "Fear         2\n",
      "Joy          1\n",
      "Name: emotion, dtype: int64\n",
      "Num tokens: 3657\n",
      "\n",
      "===========================================================================\n",
      "\n",
      "Sadness     21\n",
      "Neutral     12\n",
      "Anger        7\n",
      "Disgust      5\n",
      "Fear         2\n",
      "Hope         2\n",
      "Joy          1\n",
      "Surprise     1\n",
      "Name: emotion, dtype: int64\n",
      "Num tokens: 3759\n",
      "\n",
      "===========================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/opt/anaconda3/envs/top/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=18.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# another way to  randomly split the data\n",
    "X = df_train['essay_clean'].values\n",
    "y = ['/'.join(i) for i in df_train['emotion'].values]\n",
    "\n",
    "skf        = StratifiedKFold(n_splits=18, shuffle=True, random_state=random_state)\n",
    "chunks_idx = [test_index for _, test_index in skf.split(X, y)]\n",
    "print('Length X:', len(X))\n",
    "print('Total chunks length:', sum([len(i) for i in chunks_idx]), '\\n')\n",
    "\n",
    "for ch in chunks_idx:\n",
    "    print(df_train.loc[ch].explode('emotion')['emotion'].value_counts())\n",
    "    messages = [ {'role': 'user', 'content': ' '.join(df_train.loc[ch]['essay_clean'].tolist())} ]\n",
    "    num_tokens = num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\")\n",
    "    print('Num tokens:', num_tokens)\n",
    "    print('\\n', '='*75, '\\n', sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a2e75e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
