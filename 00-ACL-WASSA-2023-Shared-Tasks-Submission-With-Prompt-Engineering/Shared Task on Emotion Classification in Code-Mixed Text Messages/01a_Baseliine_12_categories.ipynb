{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "975703f6",
   "metadata": {},
   "source": [
    "# WASSA 2023 Shared Task on Multi-Label and Multi-Class Emotion Classification on Code-Mixed Text Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83e22f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import re, os\n",
    "import time\n",
    "import zipfile\n",
    "from typing import List\n",
    "from copy import deepcopy\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, RidgeClassifierCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "from tqdm.autonotebook import tqdm\n",
    "import tiktoken\n",
    "tqdm.pandas()\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 400)\n",
    "#os.path.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56940aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new new version (Dec 2022)\n",
    "def upsample_all( df_, labels_col='target', random_state=47 ):\n",
    "    '''\n",
    "        Upsample each class in column labels_col of pandas dataframe df_\n",
    "        to the number of data points in majority class\n",
    "    '''\n",
    "    # get sub-dataframes for each class & max length\n",
    "    labels = df_[labels_col].unique()\n",
    "    dframes, df_lengths = dict(), dict()\n",
    "    for i in labels:\n",
    "        temp          = df_[ df_[labels_col] == i ]\n",
    "        dframes[i]    = temp.copy()\n",
    "        df_lengths[i] = len(temp)\n",
    "\n",
    "    max_len = max( list(df_lengths.values()) )\n",
    "    df_lengths = {k: max_len-v for k,v in df_lengths.items()}                     # difference - how many to resample\n",
    "\n",
    "    # upsample with replacement to max length\n",
    "    for i in labels:\n",
    "        if df_lengths[i] == max_len:\n",
    "            dframes[i] = dframes[i].sample( frac=1, random_state=random_state )      # we know it's overrepresented\n",
    "        else:\n",
    "            if len(dframes[i]) >= df_lengths[i]:\n",
    "                replace = False                                                      # enough data points\n",
    "            else:\n",
    "                replace = True\n",
    "            temp = dframes[i].sample( df_lengths[i], replace=replace, random_state=random_state )\n",
    "            dframes[i] = pd.concat( [dframes[i].copy(), temp.copy()] )               # df len + (max_len-df len)\n",
    "            dframes[i] = dframes[i].sample( frac=1, random_state=random_state )      # shuffle\n",
    "\n",
    "    # combine and reshuffle\n",
    "    df_merged = pd.concat( list(dframes.values()) )\n",
    "    df_merged = df_merged.sample( frac=1, random_state=random_state ).reset_index(drop=True)\n",
    "\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bbb2ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'neutral',\n",
       " 1: 'joy',\n",
       " 2: 'trust',\n",
       " 3: 'disgust',\n",
       " 4: 'optimism',\n",
       " 5: 'anticipation',\n",
       " 6: 'sadness',\n",
       " 7: 'fear',\n",
       " 8: 'surprise',\n",
       " 9: 'anger',\n",
       " 10: 'pessimism',\n",
       " 11: 'love'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in the order of decreasing frequency\n",
    "label2key = {\n",
    "    'neutral': 0,\n",
    "    'joy': 1,\n",
    "    'trust': 2,\n",
    "    'disgust': 3,\n",
    "    'optimism': 4,\n",
    "    'anticipation': 5,\n",
    "    'sadness': 6,\n",
    "    'fear': 7,\n",
    "    'surprise': 8,\n",
    "    'anger': 9,\n",
    "    'pessimism': 10,\n",
    "    'love':  11,\n",
    "}\n",
    "key2label = { v: k for k,v in label2key.items()}\n",
    "key2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae0395e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cbdfbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dfc9a3f",
   "metadata": {},
   "source": [
    "# Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1e5c24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9530, 2) (1191, 2)\n"
     ]
    }
   ],
   "source": [
    "file1    = 'data/mcec_train.csv'\n",
    "df_train = pd.read_csv(file1)\n",
    "\n",
    "file2    = 'data/mcec_dev.csv'\n",
    "df_dev   = pd.read_csv(file2)\n",
    "\n",
    "print(df_train.shape, df_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d76d114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral         3262\n",
      "trust           1118\n",
      "joy             1022\n",
      "optimism         880\n",
      "anticipation     832\n",
      "disgust          687\n",
      "sadness          486\n",
      "fear             453\n",
      "anger            226\n",
      "surprise         199\n",
      "love             187\n",
      "pessimism        178\n",
      "Name: Emotion, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes.I am in fyp lab cabin.but fyp presentation...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yar insan ka bcha bn chawliyn na mar :p</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Terai uncle nai kahna hai kai ham nai to bahr ...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yr ajao I m cming in the club</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mje wese Nimra ahmad ka Qur'aan ki aayaat k ba...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Emotion\n",
       "0  Yes.I am in fyp lab cabin.but fyp presentation...  neutral\n",
       "1           Yar insan ka bcha bn chawliyn na mar :p       joy\n",
       "2  Terai uncle nai kahna hai kai ham nai to bahr ...  disgust\n",
       "3                      Yr ajao I m cming in the club  neutral\n",
       "4  Mje wese Nimra ahmad ka Qur'aan ki aayaat k ba...      joy"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train['Emotion'].value_counts())\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ad79270",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['target'] = df_train['Emotion'].map( label2key )\n",
    "df_dev['target']   = df_dev['Emotion'].map( label2key )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3bde67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set b4 upsampling:\n",
      "neutral         3262\n",
      "trust           1118\n",
      "joy             1022\n",
      "optimism         880\n",
      "anticipation     832\n",
      "disgust          687\n",
      "sadness          486\n",
      "fear             453\n",
      "anger            226\n",
      "surprise         199\n",
      "love             187\n",
      "pessimism        178\n",
      "Name: Emotion, dtype: int64\n",
      "\n",
      "Train set after upsampling:\n",
      "fear            3262\n",
      "pessimism       3262\n",
      "anger           3262\n",
      "joy             3262\n",
      "anticipation    3262\n",
      "neutral         3262\n",
      "love            3262\n",
      "surprise        3262\n",
      "optimism        3262\n",
      "disgust         3262\n",
      "trust           3262\n",
      "sadness         3262\n",
      "Name: Emotion, dtype: int64\n",
      "\n",
      "7     3262\n",
      "10    3262\n",
      "9     3262\n",
      "1     3262\n",
      "5     3262\n",
      "0     3262\n",
      "11    3262\n",
      "8     3262\n",
      "4     3262\n",
      "3     3262\n",
      "2     3262\n",
      "6     3262\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('\\nTrain set b4 upsampling:\\n', df_train['Emotion'].value_counts(), sep='')\n",
    "df_train = upsample_all( df_train.copy(), labels_col='target', random_state=random_state )\n",
    "print('\\nTrain set after upsampling:\\n', df_train['Emotion'].value_counts(), '\\n\\n', \n",
    "       df_train['target'].value_counts(), sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f3ff39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of datasets:  (39144,) (39144,) (1191,) (1191,)\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train['Text'].values\n",
    "y_train = df_train['target'].values\n",
    "\n",
    "X_dev = df_dev['Text'].values\n",
    "y_dev = df_dev['target'].values\n",
    "\n",
    "X_train, y_train = sklearn.utils.shuffle( X_train, y_train, random_state=random_state, ) \n",
    "print( 'Shape of datasets: ', X_train.shape, y_train.shape, X_dev.shape, y_dev.shape, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ca84cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e08e5dd",
   "metadata": {},
   "source": [
    "# Strong Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3541e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_params_svm = {\n",
    "    \n",
    "    'C': 1.0,                      # default=1.0\n",
    "    'kernel': 'rbf',               # default=’rbf’, {‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}\n",
    "    'degree': 3,                   # default=3, degree for polynomial f(x)\n",
    "    'tol': 1e-3,                   # stopping criteria, default=1e-3\n",
    "    'gamma': 'scale',               # default=’scale’, kernel coeff for ‘rbf’, ‘poly’ and ‘sigmoid’\n",
    "                                   # 'scale' => 1 / (n_features * X.var()), ‘auto’ => 1 / n_features\n",
    "    'coef0': 0.0,                  # default=0.0, independent term in kernel function in ‘poly’ and ‘sigmoid’\n",
    "    'shrinking': True,             # default=True'\n",
    "    'cache_size': 200,             # default=200,   size of the kernel cache (in MB)\n",
    "    'decision_function_shape': 'ovr',    # default=’ovr’, {‘ovo’, ‘ovr’}, multiclass => always 'ovo'\n",
    "    'break_ties': False,           # default=False, for decision_function_shape='ovr' and num classes>2 (longer)\n",
    "    'max_iter': -1,                # default=-1,    limit on iterations\n",
    "    'class_weight': 'balanced',          # default=None,  dict or ‘balanced'\n",
    "    'probability': True,\n",
    "    'verbose': 0,\n",
    "    'random_state': random_state,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df367a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_params_xgb = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.3,                                 # eta\n",
    "    'objective': 'multi:softmax',                         # multi:softmax, multi:softprob, rank:pairwise\n",
    "    'eval_metric': 'merror',                              # multiclass - merror, mlogloss\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',                                  # gbtree, dart\n",
    "    'tree_method': 'auto',                                # auto, exact, approx, hist and gpu_hist\n",
    "    'importance_type': 'gain',                            # default“gain”,“weight”,“cover”,“total_gain”,“total_cover”\n",
    "    'gamma': 0,                                           # larger - more conservative, [0, inf]\n",
    "    'reg_alpha': 0,                                       # L1 reg., larger - more conservative\n",
    "    'reg_lambda': 1,                                      # L2 rreg., larger - more conservative\n",
    "    'sampling_method': 'uniform',                         # uniform, gradient_based\n",
    "    'max_delta_step': 1,                                  # 1-10\n",
    "    'min_child_weight': 1,\n",
    "    'subsample': 1.0,                                     # 0-1    \n",
    "    'colsample_bylevel': 1.0,                             # 0-1\n",
    "    'colsample_bynode': 1.0,                              # optimized for higher recall\n",
    "    'colsample_bytree': 1.0,                              # 0-1  \n",
    "    'seed': 2,\n",
    "    'num_class': 12,\n",
    "    #'use_label_encoder': False,\n",
    "    'random_state': random_state,\n",
    "    'n_jobs': -1,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e92e4649",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_params = {\n",
    "    'max_df': 1.0,\n",
    "    'min_df': 1,\n",
    "    'analyzer': 'char',\n",
    "    'ngram_range': (1,5),\n",
    "    'binary': True,\n",
    "    'stop_words': 'english',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6fe842a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/opt/anaconda3/envs/top/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:550: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, binary=True,\n",
       "                                 ngram_range=(1, 5), stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;clf&#x27;, LogisticRegression(max_iter=500))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char&#x27;, binary=True,\n",
       "                                 ngram_range=(1, 5), stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;clf&#x27;, LogisticRegression(max_iter=500))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char&#x27;, binary=True, ngram_range=(1, 5),\n",
       "                stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=500)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 TfidfVectorizer(analyzer='char', binary=True,\n",
       "                                 ngram_range=(1, 5), stop_words='english')),\n",
       "                ('clf', LogisticRegression(max_iter=500))])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer( **vect_params )\n",
    "#vectorizer = CountVectorizer( **vect_params )\n",
    "\n",
    "#clf = SVC( **clf_params_svm )\n",
    "#clf = XGBClassifier( **clf_params_xgb )\n",
    "clf = LogisticRegression(max_iter=500)\n",
    "#clf = MultinomialNB()\n",
    "\n",
    "model = Pipeline( steps=[('vect', vectorizer), ('clf', clf)] )\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a18eef8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['neutral', 'joy', 'trust', 'disgust', 'optimism', 'anticipation', 'sadness', 'fear', 'surprise', 'anger', 'pessimism', 'love']\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_dev   = model.predict(X_dev)\n",
    "\n",
    "# add prediction to dataframe\n",
    "df_dev['clf_pred'] = y_pred_dev\n",
    "df_dev['clf_pred_emotion'] = df_dev['clf_pred'].map( key2label )\n",
    "\n",
    "# labels for classification report\n",
    "labels = list(label2key.keys())\n",
    "print('Labels:', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cfd5f419",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer:\n",
      "TfidfVectorizer(analyzer='char', binary=True, ngram_range=(1, 5),\n",
      "                stop_words='english')\n",
      "\n",
      "Classifier:\n",
      "LogisticRegression(max_iter=500)\n",
      "\n",
      "\n",
      "TRAINSET\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral     0.9813    0.9307    0.9553      3262\n",
      "         joy     0.9845    0.9905    0.9875      3262\n",
      "       trust     0.9791    0.9752    0.9771      3262\n",
      "     disgust     0.9887    0.9960    0.9924      3262\n",
      "    optimism     0.9705    0.9880    0.9792      3262\n",
      "anticipation     0.9790    0.9865    0.9827      3262\n",
      "     sadness     0.9945    0.9994    0.9969      3262\n",
      "        fear     0.9939    0.9988    0.9963      3262\n",
      "    surprise     0.9988    1.0000    0.9994      3262\n",
      "       anger     0.9997    1.0000    0.9998      3262\n",
      "   pessimism     0.9982    1.0000    0.9991      3262\n",
      "        love     0.9969    1.0000    0.9985      3262\n",
      "\n",
      "    accuracy                         0.9888     39144\n",
      "   macro avg     0.9888    0.9888    0.9887     39144\n",
      "weighted avg     0.9888    0.9888    0.9887     39144\n",
      "\n",
      "DEVSET\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral     0.7173    0.7062    0.7117       388\n",
      "         joy     0.7910    0.8092    0.8000       131\n",
      "       trust     0.6565    0.6880    0.6719       125\n",
      "     disgust     0.6000    0.6372    0.6180       113\n",
      "    optimism     0.6640    0.7545    0.7064       110\n",
      "anticipation     0.5321    0.6170    0.5714        94\n",
      "     sadness     0.6515    0.6935    0.6719        62\n",
      "        fear     0.6200    0.5962    0.6078        52\n",
      "    surprise     0.8095    0.4857    0.6071        35\n",
      "       anger     0.8182    0.5143    0.6316        35\n",
      "   pessimism     0.6500    0.4483    0.5306        29\n",
      "        love     0.9091    0.5882    0.7143        17\n",
      "\n",
      "    accuracy                         0.6809      1191\n",
      "   macro avg     0.7016    0.6282    0.6536      1191\n",
      "weighted avg     0.6875    0.6809    0.6804      1191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print classification reports\n",
    "print('Vectorizer:\\n', model['vect'], '\\n', sep='')\n",
    "print('Classifier:\\n', model['clf'], '\\n', sep='')\n",
    "\n",
    "print('\\nTRAINSET')\n",
    "print( classification_report( y_train, y_pred_train, target_names=labels, digits=4 ) )\n",
    "\n",
    "print('DEVSET')\n",
    "print( classification_report( y_dev, y_pred_dev, target_names=labels, digits=4 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f693b1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "cbbe0979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create zip file for submission\n",
    "file     = 'data/results.csv'\n",
    "zip_file = 'data/results.zip'\n",
    "\n",
    "with open(file, 'w', encoding='utf-8') as f:\n",
    "    f.write( '\\n'.join(df_dev['pred_emotion'].tolist()) )\n",
    "\n",
    "with zipfile.ZipFile(zip_file, \"w\", compression=zipfile.ZIP_STORED) as zf:        # , compression=zipfile.ZIP_DEFLATED\n",
    "    zf.write( file )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c74cdd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e3c932f",
   "metadata": {},
   "source": [
    "## APPENDIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1805,
   "id": "168d8251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST THRESHOLD - DEV SET (IRRELEVANT)\n",
    "res_dev = []\n",
    "for i in range(1,100):\n",
    "    threshold = i/100\n",
    "    y_pred_dev_encoded = convert_preds(y_pred_dev_probas, threshold=threshold)\n",
    "    clf_rep_dev = classification_report( y_dev_encoded, y_pred_dev_encoded, target_names=labels, output_dict=True )\n",
    "    res_dev.append([ clf_rep_dev['macro avg']['f1-score'],  clf_rep_dev['micro avg']['f1-score'],\n",
    "                     clf_rep_dev['macro avg']['precision'],  clf_rep_dev['micro avg']['precision'],\n",
    "                     clf_rep_dev['macro avg']['recall'],  clf_rep_dev['micro avg']['recall'], threshold\n",
    "                   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c96e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted( res_dev, key=lambda x: x[0], reverse=True )[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d9c264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0026756a",
   "metadata": {},
   "source": [
    "## All results below are on the dataset that was not upsampled\n",
    "\n",
    "### Log of some best results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270d3b76",
   "metadata": {},
   "source": [
    "__XGBoost__ (micro, macro F1 score)\n",
    "\n",
    "__analyzer='char'__:\n",
    "* tfidf, binary=False, ngram(1,5), min_df=7, 'english': __0.7053, 0.6758__ (0.9792, 0.9866)    # more overfit   # F1 micro = 0.71, but F1 macro = 0.66 when min_df=8\n",
    "* increasing num estimators to 150 improves F1 macro to 0.6773, but trainin F1 becomes (0.9973, 0.9983) \n",
    "* count, binary=False, ngram(1,5), min_df=1, 'english': 0.6683, 0.6342 (0.9338, 0.9528)\n",
    "\n",
    "__analyzer='word'__:\n",
    "* tfidf, binary=False, ngram(1,1), min_df=1, 'english': 0.5189, 0.4503\n",
    "* tfidf, binary=False, ngram(1,1), min_df=1, None: 0.5281, 0.4528\n",
    "* tfidf - increasing word ngram_range has no effect\n",
    "* tfidf, binary=False, ngram(1,1), min_df=5, 'english': 0.5323, 0.4680\n",
    "* count - much worse: 0.4794, 0.3641\n",
    "\n",
    "Changing HPs for XGBClassifier didn't have any effect\n",
    "\n",
    "__SVC__ results w/out ANY HP fine-tuning (using the best features from XGB) - 0.6952, 0.6678 (training 0.9562, 0.9731!). Least overfit\n",
    "\n",
    "__RandomForest__'s results w/out ANY HP fine-tuning were close (0.68, 0.65), but the training F1 was 0.9997 both. Overfit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bfb023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best XGB\n",
    "clf_params_xgb_word = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.3,                                 # eta\n",
    "    'objective': 'multi:softmax',                         # multi:softmax, multi:softprob, rank:pairwise\n",
    "    'eval_metric': 'merror',                              # multiclass - merror, mlogloss\n",
    "    'base_score': 0.5,\n",
    "    'booster': 'gbtree',                                  # gbtree, dart\n",
    "    'tree_method': 'auto',                                # auto, exact, approx, hist and gpu_hist\n",
    "    'importance_type': 'gain',                            # default“gain”,“weight”,“cover”,“total_gain”,“total_cover”\n",
    "    'gamma': 0,                                           # larger - more conservative, [0, inf]\n",
    "    'reg_alpha': 0,                                       # L1 reg., larger - more conservative\n",
    "    'reg_lambda': 1,                                      # L2 rreg., larger - more conservative\n",
    "    'sampling_method': 'uniform',                         # uniform, gradient_based\n",
    "    'max_delta_step': 1,                                  # 1-10\n",
    "    'min_child_weight': 1,\n",
    "    'subsample': 1.0,                                     # 0-1    \n",
    "    'colsample_bylevel': 1.0,                             # 0-1\n",
    "    'colsample_bynode': 1.0,                              # optimized for higher recall\n",
    "    'colsample_bytree': 1.0,                              # 0-1  \n",
    "    'seed': 2,\n",
    "    'num_class': 12,\n",
    "    #'use_label_encoder': False,\n",
    "    'random_state': random_state, # 47\n",
    "    'n_jobs': -1,    \n",
    "}\n",
    "\n",
    "vect_params = {\n",
    "    'max_df': 1.0,\n",
    "    'min_df': 7,\n",
    "    'analyzer': 'char',\n",
    "    'ngram_range': (1,5),\n",
    "    'binary': False,\n",
    "    'stop_words': 'english',\n",
    "}\n",
    "\n",
    "TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829d70dc",
   "metadata": {},
   "source": [
    "### Best XGBClassifier results\n",
    "Note: no grid search or cross-validation - the results of this classifier were not intended for official submission.\n",
    "```\n",
    "Vectorizer:\n",
    "TfidfVectorizer(analyzer='char', min_df=7, ngram_range=(1, 5),\n",
    "                stop_words='english')\n",
    "\n",
    "Classifier:\n",
    "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
    "              colsample_bylevel=1.0, colsample_bynode=1.0, colsample_bytree=1.0,\n",
    "              early_stopping_rounds=None, enable_categorical=False,\n",
    "              eval_metric='merror', feature_types=None, gamma=0, gpu_id=None,\n",
    "              grow_policy=None, importance_type='gain',\n",
    "              interaction_constraints=None, learning_rate=0.3, max_bin=None,\n",
    "              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=1,\n",
    "              max_depth=6, max_leaves=None, min_child_weight=1, missing=nan,\n",
    "              monotone_constraints=None, n_estimators=100, n_jobs=-1,\n",
    "              num_class=12, num_parallel_tree=None, objective='multi:softmax', ...)\n",
    "\n",
    "\n",
    "TRAINSET\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     neutral     0.9471    0.9985    0.9721      3262\n",
    "         joy     0.9921    0.9883    0.9902      1022\n",
    "       trust     0.9963    0.9589    0.9772      1118\n",
    "     disgust     1.0000    0.9403    0.9692       687\n",
    "    optimism     0.9953    0.9727    0.9839       880\n",
    "anticipation     1.0000    0.9387    0.9684       832\n",
    "     sadness     1.0000    0.9897    0.9948       486\n",
    "        fear     1.0000    0.9691    0.9843       453\n",
    "    surprise     1.0000    1.0000    1.0000       199\n",
    "       anger     1.0000    1.0000    1.0000       226\n",
    "   pessimism     1.0000    1.0000    1.0000       178\n",
    "        love     1.0000    1.0000    1.0000       187\n",
    "\n",
    "    accuracy                         0.9792      9530\n",
    "   macro avg     0.9942    0.9797    0.9867      9530\n",
    "weighted avg     0.9802    0.9792    0.9792      9530\n",
    "\n",
    "DEVSET\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     neutral     0.5908    0.9227    0.7203       388\n",
    "         joy     0.8450    0.8321    0.8385       131\n",
    "       trust     0.7895    0.6000    0.6818       125\n",
    "     disgust     0.8133    0.5398    0.6489       113\n",
    "    optimism     0.8193    0.6182    0.7047       110\n",
    "anticipation     0.6912    0.5000    0.5802        94\n",
    "     sadness     0.8696    0.6452    0.7407        62\n",
    "        fear     0.9000    0.5192    0.6585        52\n",
    "    surprise     0.8500    0.4857    0.6182        35\n",
    "       anger     1.0000    0.4857    0.6538        35\n",
    "   pessimism     1.0000    0.3793    0.5500        29\n",
    "        love     0.9091    0.5882    0.7143        17\n",
    "\n",
    "    accuracy                         0.7053      1191\n",
    "   macro avg     0.8398    0.5930    0.6758      1191\n",
    "weighted avg     0.7519    0.7053    0.6992      1191\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc71308",
   "metadata": {},
   "source": [
    "## With Upsampling\n",
    "* Upsampled XGB - similar / slightly less than non-upsampled XGB\n",
    "* Upsampled LogisticRegression - close to XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27995476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
