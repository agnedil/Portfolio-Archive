{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4181b00f",
   "metadata": {},
   "source": [
    "# ChatGPT API: Few-Shot Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975703f6",
   "metadata": {},
   "source": [
    "## The Association for Computational Linguistics\n",
    "## WASSA 2023 Shared Task on Multi-Label and Multi-Class Emotion Classification on Code-Mixed Text Messages\n",
    "See more details [here](https://codalab.lisn.upsaclay.fr/competitions/10864#learn_the_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83e22f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vb/p2r9brhx2335cwnww04p9w180000gn/T/ipykernel_39502/495498401.py:19: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import re, os\n",
    "import time\n",
    "import zipfile, pickle\n",
    "from typing import List\n",
    "from copy import deepcopy\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, RidgeClassifierCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "from openai.embeddings_utils import cosine_similarity\n",
    "from tqdm.autonotebook import tqdm\n",
    "import random\n",
    "import tiktoken\n",
    "import backoff\n",
    "tqdm.pandas()\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 400)\n",
    "#os.path.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91371be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\"):\n",
    "    '''Return number of tokens used in a list of messages for ChatGPT'''\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        #print(\"Warning: model not found. Using cl100k_base encoding.\")\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    if model == \"gpt-3.5-turbo\":\n",
    "        #print(\"Warning: gpt-3.5-turbo may change over time. Returning num tokens assuming gpt-3.5-turbo-0301.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0301\")\n",
    "    elif model == \"gpt-4\":\n",
    "        #print(\"Warning: gpt-4 may change over time. Returning num tokens assuming gpt-4-0314.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-4-0314\")\n",
    "    elif model == \"gpt-3.5-turbo-0301\":\n",
    "        tokens_per_message = 4  # every message follows <|start|>{role/name}\\n{content}<|end|>\\n\n",
    "        tokens_per_name = -1  # if there's a name, the role is omitted\n",
    "    elif model == \"gpt-4-0314\":\n",
    "        tokens_per_message = 3\n",
    "        tokens_per_name = 1\n",
    "    else:\n",
    "        raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not implemented for model {model}. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\")\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22f43ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'neutral',\n",
       " 1: 'joy',\n",
       " 2: 'trust',\n",
       " 3: 'disgust',\n",
       " 4: 'optimism',\n",
       " 5: 'anticipation',\n",
       " 6: 'sadness',\n",
       " 7: 'fear',\n",
       " 8: 'surprise',\n",
       " 9: 'anger',\n",
       " 10: 'pessimism',\n",
       " 11: 'love'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in the order of decreasing frequency\n",
    "label2key = {\n",
    "    'neutral': 0,\n",
    "    'joy': 1,\n",
    "    'trust': 2,\n",
    "    'disgust': 3,\n",
    "    'optimism': 4,\n",
    "    'anticipation': 5,\n",
    "    'sadness': 6,\n",
    "    'fear': 7,\n",
    "    'surprise': 8,\n",
    "    'anger': 9,\n",
    "    'pessimism': 10,\n",
    "    'love':  11,\n",
    "}\n",
    "key2label = { v: k for k,v in label2key.items()}\n",
    "key2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae0395e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cbdfbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dfc9a3f",
   "metadata": {},
   "source": [
    "# Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1e5c24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9530, 5) (1191, 13) (1191, 1) (1191, 1)\n"
     ]
    }
   ],
   "source": [
    "file1    = 'data/mcec_train_translated.pkl'\n",
    "df_train = pd.read_pickle(file1)\n",
    "\n",
    "file2    = 'data/df_dev_100_closest_GptEmbeddings.pkl'\n",
    "df_dev   = pd.read_pickle(file2)\n",
    "\n",
    "file3    = 'data/mcec_test.csv'\n",
    "df_test  = pd.read_csv(file3)\n",
    "\n",
    "file4    = 'data/sample_submission/predictions_MCEC.csv'\n",
    "sample_submission = pd.read_csv(file4)\n",
    "\n",
    "print(df_train.shape, df_dev.shape, df_test.shape, sample_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a0b1d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['target'] = df_train['emotion'].map( label2key )\n",
    "df_dev['target']   = df_dev['emotion'].map( label2key )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d76d114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral         3262\n",
      "trust           1118\n",
      "joy             1022\n",
      "optimism         880\n",
      "anticipation     832\n",
      "disgust          687\n",
      "sadness          486\n",
      "fear             453\n",
      "anger            226\n",
      "surprise         199\n",
      "love             187\n",
      "pessimism        178\n",
      "Name: emotion, dtype: int64 \n",
      "\n",
      "0     3262\n",
      "2     1118\n",
      "1     1022\n",
      "4      880\n",
      "5      832\n",
      "3      687\n",
      "6      486\n",
      "7      453\n",
      "9      226\n",
      "8      199\n",
      "11     187\n",
      "10     178\n",
      "Name: target, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>translated_hi</th>\n",
       "      <th>translated_ur</th>\n",
       "      <th>gpt_embedding</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes.I am in fyp lab cabin.but fyp presentation...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Yes.i am in fyp lab cabin.but fyp presentation...</td>\n",
       "      <td>Y. Um in Fap Lab Cabin. Butt Fap Presentations...</td>\n",
       "      <td>[-0.005477939732372761, -0.01738985814154148, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yar insan ka bcha bn chawliyn na mar :p</td>\n",
       "      <td>joy</td>\n",
       "      <td>Dude become a child of a human being, do not die.</td>\n",
       "      <td>Dude human beings do not die: P: P</td>\n",
       "      <td>[0.0006696455529890954, -0.006965265609323978,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Terai uncle nai kahna hai kai ham nai to bahr ...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>Your Uncle Nai says that we had sent out money</td>\n",
       "      <td>Your Ankali says that we sent out money and wa...</td>\n",
       "      <td>[0.021171217784285545, -0.02109299972653389, 0...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yr ajao I m cming in the club</td>\n",
       "      <td>neutral</td>\n",
       "      <td>YR AJAO I'M Coming in the Club</td>\n",
       "      <td>Yer organs were the club</td>\n",
       "      <td>[-0.010511564090847969, -0.02738134376704693, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mje wese Nimra ahmad ka Qur'aan ki aayaat k ba...</td>\n",
       "      <td>joy</td>\n",
       "      <td>Mje wes nimra ahmad ka qur'aan ki aayaat k bar...</td>\n",
       "      <td>Mje Wese Nimra Ahmad Ka Qur'aan Ki Aayaaat K B...</td>\n",
       "      <td>[-0.0016743674641475081, -0.021855581551790237...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  emotion  \\\n",
       "0  Yes.I am in fyp lab cabin.but fyp presentation...  neutral   \n",
       "1           Yar insan ka bcha bn chawliyn na mar :p       joy   \n",
       "2  Terai uncle nai kahna hai kai ham nai to bahr ...  disgust   \n",
       "3                      Yr ajao I m cming in the club  neutral   \n",
       "4  Mje wese Nimra ahmad ka Qur'aan ki aayaat k ba...      joy   \n",
       "\n",
       "                                       translated_hi  \\\n",
       "0  Yes.i am in fyp lab cabin.but fyp presentation...   \n",
       "1  Dude become a child of a human being, do not die.   \n",
       "2     Your Uncle Nai says that we had sent out money   \n",
       "3                     YR AJAO I'M Coming in the Club   \n",
       "4  Mje wes nimra ahmad ka qur'aan ki aayaat k bar...   \n",
       "\n",
       "                                       translated_ur  \\\n",
       "0  Y. Um in Fap Lab Cabin. Butt Fap Presentations...   \n",
       "1                 Dude human beings do not die: P: P   \n",
       "2  Your Ankali says that we sent out money and wa...   \n",
       "3                           Yer organs were the club   \n",
       "4  Mje Wese Nimra Ahmad Ka Qur'aan Ki Aayaaat K B...   \n",
       "\n",
       "                                       gpt_embedding  target  \n",
       "0  [-0.005477939732372761, -0.01738985814154148, ...       0  \n",
       "1  [0.0006696455529890954, -0.006965265609323978,...       1  \n",
       "2  [0.021171217784285545, -0.02109299972653389, 0...       3  \n",
       "3  [-0.010511564090847969, -0.02738134376704693, ...       0  \n",
       "4  [-0.0016743674641475081, -0.021855581551790237...       1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train['emotion'].value_counts(), '\\n')\n",
    "print(df_train['target'].value_counts())\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1742539f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral         388\n",
      "joy             131\n",
      "trust           125\n",
      "disgust         113\n",
      "optimism        110\n",
      "anticipation     94\n",
      "sadness          62\n",
      "fear             52\n",
      "surprise         35\n",
      "anger            35\n",
      "pessimism        29\n",
      "love             17\n",
      "Name: emotion, dtype: int64 \n",
      "\n",
      "0     388\n",
      "1     131\n",
      "2     125\n",
      "3     113\n",
      "4     110\n",
      "5      94\n",
      "6      62\n",
      "7      52\n",
      "8      35\n",
      "9      35\n",
      "10     29\n",
      "11     17\n",
      "Name: target, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>target</th>\n",
       "      <th>gtp_translated</th>\n",
       "      <th>translated_hi</th>\n",
       "      <th>translated_ur</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>gpt_pred</th>\n",
       "      <th>gpt_pred_num</th>\n",
       "      <th>gpt_translated2</th>\n",
       "      <th>gpt_translated2_corrected</th>\n",
       "      <th>gpt_embedding</th>\n",
       "      <th>closest_texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tension lene ki koi baat ni</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>There's no need to take tension.</td>\n",
       "      <td>There is nothing to take tension</td>\n",
       "      <td>Any talk of taking tangoes</td>\n",
       "      <td>Tension lene ki koi baat ni</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>There's no need to worry.</td>\n",
       "      <td>There's no need to worry.</td>\n",
       "      <td>[-0.00021548081713262945, 0.005029499996453524...</td>\n",
       "      <td>[Tension na lo hi jaw ga, O nahi yar tension n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Main ghar punch gya hun or ab spny laga hun</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>I have reached home and now I am going to sleep.</td>\n",
       "      <td>I have gone home punch and now I am Sapni</td>\n",
       "      <td>I have gone home punch and now dreams</td>\n",
       "      <td>Main ghar punch gya hun or ab spny laga hun</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>I have reached home and now I am going to sleep.</td>\n",
       "      <td>I have reached home and now I am going to sleep.</td>\n",
       "      <td>[-0.0010164333507418633, -0.013282055966556072...</td>\n",
       "      <td>[Main tu ghar hi rehta main kahan ja skta, Ghr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nai mje nai mili mail..mene check ki ti</td>\n",
       "      <td>pessimism</td>\n",
       "      <td>10</td>\n",
       "      <td>I didn't receive any mail, I had checked.</td>\n",
       "      <td>Nai Maje Nai Mile Mail .. I checked</td>\n",
       "      <td>Ni Ni Ni Mille Mail</td>\n",
       "      <td>Nai mje nai mili mail .. mene check ki ti</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>I didn't receive any new mail. I had checked.</td>\n",
       "      <td>I didn't receive any new mail. I had checked.</td>\n",
       "      <td>[-0.010691414587199688, -0.01292553823441267, ...</td>\n",
       "      <td>[Nai yar mje to pta e nai kuch, Mjhe tu ni lgt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yr us din mai pura din bzy rahe vo mujy awne h...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>3</td>\n",
       "      <td>That day, they were busy all day and not givin...</td>\n",
       "      <td>YR Us Din Mai Pura Din Bzy Rahe Vo Mujy Awne H...</td>\n",
       "      <td>Yr us din mai pura din bzy rahe vo mujy awne h...</td>\n",
       "      <td>Yr us din mai pura din bzy rahe vo mujy awne h...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>I was busy the whole day on that day, they wer...</td>\n",
       "      <td>I was busy the whole day on that day, they wer...</td>\n",
       "      <td>[0.009936108253896236, -0.016926730051636696, ...</td>\n",
       "      <td>[Yr masla pta kia ha. Yad ha tm log us din upa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lakin wo abhe dar dar ka chalata ha</td>\n",
       "      <td>fear</td>\n",
       "      <td>7</td>\n",
       "      <td>But he still walks cautiously.</td>\n",
       "      <td>But it still moves at the rate</td>\n",
       "      <td>But Wu runs the cedar</td>\n",
       "      <td>Lakin wo abhe dar dar ka chalata ha</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>But he still walks with fear and hesitation.</td>\n",
       "      <td>But he still walks with fear and hesitation.</td>\n",
       "      <td>[0.019262924790382385, -0.0011249196249991655,...</td>\n",
       "      <td>[Pata nahe ab kahan chala gea hai kamina, Han ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    emotion  target  \\\n",
       "0                        Tension lene ki koi baat ni    neutral       0   \n",
       "1        Main ghar punch gya hun or ab spny laga hun    neutral       0   \n",
       "2            Nai mje nai mili mail..mene check ki ti  pessimism      10   \n",
       "3  Yr us din mai pura din bzy rahe vo mujy awne h...    disgust       3   \n",
       "4                Lakin wo abhe dar dar ka chalata ha       fear       7   \n",
       "\n",
       "                                      gtp_translated  \\\n",
       "0                   There's no need to take tension.   \n",
       "1   I have reached home and now I am going to sleep.   \n",
       "2          I didn't receive any mail, I had checked.   \n",
       "3  That day, they were busy all day and not givin...   \n",
       "4                     But he still walks cautiously.   \n",
       "\n",
       "                                       translated_hi  \\\n",
       "0                   There is nothing to take tension   \n",
       "1          I have gone home punch and now I am Sapni   \n",
       "2                Nai Maje Nai Mile Mail .. I checked   \n",
       "3  YR Us Din Mai Pura Din Bzy Rahe Vo Mujy Awne H...   \n",
       "4                     But it still moves at the rate   \n",
       "\n",
       "                                       translated_ur  \\\n",
       "0                         Any talk of taking tangoes   \n",
       "1              I have gone home punch and now dreams   \n",
       "2                                Ni Ni Ni Mille Mail   \n",
       "3  Yr us din mai pura din bzy rahe vo mujy awne h...   \n",
       "4                              But Wu runs the cedar   \n",
       "\n",
       "                                          text_clean  gpt_pred  gpt_pred_num  \\\n",
       "0                        Tension lene ki koi baat ni   neutral             1   \n",
       "1        Main ghar punch gya hun or ab spny laga hun   neutral             1   \n",
       "2          Nai mje nai mili mail .. mene check ki ti   neutral             1   \n",
       "3  Yr us din mai pura din bzy rahe vo mujy awne h...  negative             0   \n",
       "4                Lakin wo abhe dar dar ka chalata ha   neutral             1   \n",
       "\n",
       "                                     gpt_translated2  \\\n",
       "0                          There's no need to worry.   \n",
       "1   I have reached home and now I am going to sleep.   \n",
       "2      I didn't receive any new mail. I had checked.   \n",
       "3  I was busy the whole day on that day, they wer...   \n",
       "4       But he still walks with fear and hesitation.   \n",
       "\n",
       "                           gpt_translated2_corrected  \\\n",
       "0                          There's no need to worry.   \n",
       "1   I have reached home and now I am going to sleep.   \n",
       "2      I didn't receive any new mail. I had checked.   \n",
       "3  I was busy the whole day on that day, they wer...   \n",
       "4       But he still walks with fear and hesitation.   \n",
       "\n",
       "                                       gpt_embedding  \\\n",
       "0  [-0.00021548081713262945, 0.005029499996453524...   \n",
       "1  [-0.0010164333507418633, -0.013282055966556072...   \n",
       "2  [-0.010691414587199688, -0.01292553823441267, ...   \n",
       "3  [0.009936108253896236, -0.016926730051636696, ...   \n",
       "4  [0.019262924790382385, -0.0011249196249991655,...   \n",
       "\n",
       "                                       closest_texts  \n",
       "0  [Tension na lo hi jaw ga, O nahi yar tension n...  \n",
       "1  [Main tu ghar hi rehta main kahan ja skta, Ghr...  \n",
       "2  [Nai yar mje to pta e nai kuch, Mjhe tu ni lgt...  \n",
       "3  [Yr masla pta kia ha. Yad ha tm log us din upa...  \n",
       "4  [Pata nahe ab kahan chala gea hai kamina, Han ...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_dev['emotion'].value_counts(), '\\n')\n",
    "print(df_dev['target'].value_counts())\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "070f02be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# light text cleaning (should I use clean regex for better accuracy?)\n",
    "pad_punct    = re.compile('([^a-zA-Z ]+)')\n",
    "multi_spaces = re.compile('\\s{2,}')\n",
    "#clean        = re.compile('[^a-zA-Z0-9,.?!\\'\\s]+')\n",
    "\n",
    "def clean_text(s):\n",
    "    s = s.replace('\\n', ' ')\n",
    "    s = pad_punct.sub(r' \\1 ', s)\n",
    "    #s = clean.sub(' ', s)\n",
    "    s = multi_spaces.sub(' ', s)\n",
    "    return s.strip()\n",
    "\n",
    "df_train['text_clean'] = df_train['text'].apply( clean_text )\n",
    "df_dev['text_clean']   = df_dev['text'].apply( clean_text )\n",
    "df_test['text_clean']  = df_test['Text'].apply( clean_text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6fbd6e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2382 2206\n",
      "(9530, 7)\n",
      "(8151, 7)\n"
     ]
    }
   ],
   "source": [
    "# remove overlap with validation sets\n",
    "val_sets = df_dev['text_clean'].tolist() + df_test['text_clean'].tolist()\n",
    "print(len(val_sets), len(set(val_sets)))\n",
    "\n",
    "print(df_train.shape)\n",
    "df_train = df_train[ ~df_train['text_clean'].isin(val_sets) ]\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1293d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6167, 7)\n"
     ]
    }
   ],
   "source": [
    "# remove duplicates from train set\n",
    "df_train = df_train.drop_duplicates(subset=['text_clean', 'emotion'])\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e7a589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "396d0fce",
   "metadata": {},
   "source": [
    "# ChatGPT API: Few-Shot Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbd7a6f",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38ce6dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'disgust', 'joy', 'anticipation', 'sadness', 'fear', 'surprise', 'optimism', 'pessimism', 'neutral', 'anger', 'trust', 'love'}\n"
     ]
    }
   ],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model          = 'gpt-3.5-turbo'\n",
    "labels_set     = { 'neutral', 'joy', 'trust', 'disgust', 'optimism', 'anticipation', 'sadness', 'fear',\n",
    "                   'surprise', 'anger', 'pessimism', 'love', }\n",
    "clean = re.compile(r'[^a-zA-Z ]+')\n",
    "multi_spaces = re.compile('\\s{2,}')\n",
    "print(labels_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0555031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_label(label_):\n",
    "    '''\n",
    "       Verify if label_ contains any of the categories\n",
    "       from the predefined set of labels\n",
    "    '''\n",
    "    label_ = clean.sub(' ', label_)\n",
    "    label_ = multi_spaces.sub(' ', label_).lower().split()\n",
    "    res    = [i for i in label_ if i in labels_set]\n",
    "    res    = list(set(res))\n",
    "    return '/'.join(res) if res else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e974a736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_num_tokens(model, messages):\n",
    "    '''Check that there is enough tokens available for a ChatGPT repsonse'''\n",
    "    num_tokens_tiktoken = num_tokens_from_messages(messages, model)\n",
    "    if num_tokens_tiktoken > 4080:\n",
    "        print(f'Number of tokens is {num_tokens_tiktoken} which exceeds 4080')        \n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "@backoff.on_exception(backoff.expo, openai.error.RateLimitError, max_time=10)\n",
    "def get_response(model, messages, temperature=0, max_tokens=None):\n",
    "    '''Send request, return reponse'''\n",
    "    response  = openai.ChatCompletion.create(\n",
    "        model = model,\n",
    "        messages = messages,\n",
    "        temperature = temperature,        # range(0,2), the more the less deterministic / focused\n",
    "        top_p = 1,                        # top probability mass, e.g. 0.1 = only tokens from top 10% proba mass\n",
    "        n = 1,                            # number of chat completions\n",
    "        #max_tokens = max_tokens,          # tokens to return\n",
    "        stream = False,        \n",
    "        stop=None,                        # sequence to stop generation (new line, end of text, etc.)\n",
    "        )\n",
    "    content = response['choices'][0]['message']['content'].strip()\n",
    "    #num_tokens_api = response['usage']['prompt_tokens']\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8705cd7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b3db4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fe932b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cfa8807",
   "metadata": {},
   "source": [
    "## Approach 3: concatenate the closest few shot examples using the ChatGPT chat mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1439cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learn from the following examples of texts with assigned categories. Using this knowledge, select the most relevant category for the very last text below from the following list of categories: neutral, joy, trust, disgust, optimism, anticipation, sadness, fear, surprise, anger, pessimism, love. Output only one most relevant category for the very last text below.\n",
      "Are you sure about that? If yes, output the same category, if no change the category\n"
     ]
    }
   ],
   "source": [
    "model          = 'gpt-3.5-turbo'\n",
    "embedding_type = 'gpt_embedding'\n",
    "initial_prompt = 'Learn from the following examples of texts with assigned categories. ' +\\\n",
    "                 'Using this knowledge, select the most relevant category for the very last text below ' +\\\n",
    "                 'from the following list of categories: neutral, joy, trust, disgust, optimism, ' +\\\n",
    "                 'anticipation, sadness, fear, surprise, anger, pessimism, love. ' +\\\n",
    "                 'Output only one most relevant category for the very last text below.'\n",
    "print(initial_prompt)\n",
    "\n",
    "# Using followup questions improves the reponse. but ChatGPT can change its mind too easily sometimes\n",
    "followup1 = 'Are you sure about that? If yes, output the same category, if no change the category'\n",
    "print(followup1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1aa8345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using top_n closest embeddings, create ChatGPT messages object (alternating user (text)/assistant(category) Q&As)\n",
    "def create_messages(df_, closest_texts, top_n=100 ):\n",
    "    df_temp = df_[ df_['text'].isin(closest_texts[:top_n]) ]    \n",
    "    text0, emotion0 = df_temp[['text', 'emotion']].values[0]\n",
    "    messages = [ { \"role\": \"system\", \"content\": \"You are a helpful text classifier.\", },\n",
    "                 { \"role\": \"user\", \"content\": initial_prompt + f' Text: {text0}', },\n",
    "                 { \"role\": \"assistant\", \"content\": f'Category: {emotion0}', }\n",
    "               ]    \n",
    "    for text, emotion in df_temp[['text', 'emotion']].values[1:]:                  # emotion instead of target here\n",
    "        messages += [\n",
    "            { \"role\": \"user\", \"content\": f'Text: {text}', },\n",
    "            { \"role\": \"assistant\", \"content\": f'Category: {emotion}', }\n",
    "        ]\n",
    "    while num_tokens_from_messages(messages) > 4000:\n",
    "        messages = messages[:-2]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3744ffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text_few_shot3(text_, messages_, model):\n",
    "    '''Classify text_ using prompt_ and ChatGPT API'''\n",
    "    messages_ = deepcopy(messages_)\n",
    "    messages_ += [\n",
    "        { \"role\": \"user\", \"content\": f'Text: {text_}', },\n",
    "    ]\n",
    "    while num_tokens_from_messages(messages_) > 4080:\n",
    "        messages_ = messages_[:-2] + [messages_[-1]]\n",
    "    if not verify_num_tokens(model, messages_): return None\n",
    "    label_    = get_response(model, messages_)\n",
    "    old_label = label_\n",
    "    label_    = verify_label(label_)        # get just the category if response is too long\n",
    "        \n",
    "    # if label not found in response text - second, extended chat\n",
    "    if label_ is None:\n",
    "        messages_ += [\n",
    "            { \"role\": \"assistant\", \"content\": old_label, },\n",
    "            { \"role\": \"user\", \"content\": followup1, }\n",
    "            ]        \n",
    "        label_    = get_response(model, messages_)\n",
    "        old_label = label_\n",
    "        label_    = verify_label(label_)        # get just the category if response is too long\n",
    "            \n",
    "    return label_ if label_ is not None else old_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a77fe38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a helpful text classifier.'},\n",
       " {'role': 'user',\n",
       "  'content': 'Learn from the following examples of texts with assigned categories. Using this knowledge, select the most relevant category for the very last text below from the following list of categories: neutral, joy, trust, disgust, optimism, anticipation, sadness, fear, surprise, anger, pessimism, love. Output only one most relevant category for the very last text below. Text: Yr us k bahi bhr chala gaya na'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Yr masla pta kia ha. Yad ha tm log us din upar aie tha to papa bol raha tha gusa kr raha tha. To mja yaken kr us din papa pe bht gusa aya ka humari jaha bni hue ha waha to kam se kam rehna dae. Aksar esa hta ha mra ya arslan ka koe dost milnae a jae to papa dant ke bhej deta ha.'},\n",
       " {'role': 'assistant', 'content': 'Category: anger'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: O ja yar tujy btya tu tha k tm a jana pr tun pata nahibkahan gya tha'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Haha hmri to tymng chnge hti rrhti r kbi pura pura dn ni jti ... pr ab grmi hny lgi hy to lyt b jjna shru ho gy hai ... phly mausam thk tha to ni ja ri thi ... ulti khopri fit hy un me to ... '},\n",
       " {'role': 'assistant', 'content': 'Category: joy'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Mein is puri story mein ek cheez pe bht heran hui t k haya ne jo oot pataang form fill kiya th sabanji uni k liye, usay prh k jahan jese shakky aadmi ne shak k bjaye muskuranay pe iktafa kiya!! Herat h =-O :D wrna mje to pakka yaqeen th wo ab is k liye b haya ko check krega k kahin wo waqai drink or smoke to nhi krti, huhhh.. Koi baeed b nhi t wese :/ =P'},\n",
       " {'role': 'assistant', 'content': 'Category: surprise'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Daikha tha  main NY nai mil raha  tha  udar  sy b yara,,,'},\n",
       " {'role': 'assistant', 'content': 'Category: fear'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Tmhe to bnda mzk mn b nai khe skta ku ke tm to sch mn hi khana pina shuru kr daite ho..'},\n",
       " {'role': 'assistant', 'content': 'Category: disgust'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: yar wo may be aik do din mein uet to milne ka soch rha tha ,'},\n",
       " {'role': 'assistant', 'content': 'Category: optimism'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Tu na b bdlta tO kOi bat nai the apni trf sy tO tuny jwb dy hi dia na..ab chahy bdl k dy ya wsy dy..'},\n",
       " {'role': 'assistant', 'content': 'Category: disgust'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: wo chahy apny gr gxa tha tjhe khud daikhna chahye tha.\\nor uper sy bl rha tha k papa ny daikha bs thk h. kya mtlb?\\ntu abi b cheat krny k chkrn ma h?'},\n",
       " {'role': 'assistant', 'content': 'Category: disgust'}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how one messages object looks\n",
    "c = df_dev['closest_texts'].values[3]\n",
    "create_messages(df_train, c, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f81661",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text 10. Time elapsed: 0.3015 min\n",
      "Processing text 20. Time elapsed: 0.5234 min\n",
      "Processing text 30. Time elapsed: 0.736 min\n",
      "Processing text 40. Time elapsed: 0.9475 min\n",
      "Processing text 50. Time elapsed: 1.1958 min\n",
      "Processing text 60. Time elapsed: 1.4382 min\n",
      "Processing text 70. Time elapsed: 1.6765 min\n",
      "Processing text 80. Time elapsed: 2.4385 min\n",
      "Processing text 90. Time elapsed: 2.6749 min\n",
      "Processing text 100. Time elapsed: 2.9093 min\n",
      "Processing text 110. Time elapsed: 3.1551 min\n",
      "Processing text 120. Time elapsed: 3.3923 min\n",
      "Processing text 130. Time elapsed: 3.6347 min\n",
      "Processing text 140. Time elapsed: 3.8446 min\n",
      "Processing text 150. Time elapsed: 4.1023 min\n",
      "Processing text 160. Time elapsed: 4.319 min\n",
      "Processing text 170. Time elapsed: 4.5679 min\n",
      "Processing text 180. Time elapsed: 4.7884 min\n",
      "Processing text 190. Time elapsed: 5.1195 min\n",
      "Processing text 200. Time elapsed: 5.3379 min\n",
      "Processing text 210. Time elapsed: 6.0717 min\n",
      "Processing text 220. Time elapsed: 6.297 min\n",
      "Processing text 230. Time elapsed: 7.024 min\n",
      "Processing text 240. Time elapsed: 7.2629 min\n",
      "Processing text 250. Time elapsed: 7.5343 min\n",
      "Processing text 260. Time elapsed: 8.2765 min\n",
      "Processing text 270. Time elapsed: 8.502 min\n",
      "Processing text 280. Time elapsed: 8.7401 min\n",
      "Processing text 290. Time elapsed: 9.0294 min\n",
      "Processing text 300. Time elapsed: 9.299 min\n",
      "Processing text 310. Time elapsed: 9.5226 min\n",
      "Processing text 320. Time elapsed: 9.7769 min\n",
      "Processing text 330. Time elapsed: 10.0086 min\n",
      "Processing text 340. Time elapsed: 10.2479 min\n",
      "Processing text 350. Time elapsed: 10.4783 min\n",
      "Processing text 360. Time elapsed: 10.7389 min\n",
      "Processing text 370. Time elapsed: 10.9526 min\n"
     ]
    }
   ],
   "source": [
    "# this simple iteration is faster than pandas df with tqdm\n",
    "model = 'gpt-3.5-turbo'\n",
    "start = time.time()\n",
    "res   = dict()\n",
    "count = 0\n",
    "for t, closest in df_dev[['text', 'closest_texts']].values:\n",
    "    if t in res:\n",
    "        continue\n",
    "    messages = create_messages(df_train, closest, top_n=100)\n",
    "    try:\n",
    "        res[ t ] = classify_text_few_shot3(t, messages, model)\n",
    "    except openai.error.RateLimitError:\n",
    "        print(f'\\nText: {t}.\\nRate limit error\\n')\n",
    "    except Exception as e:\n",
    "        print(f'\\nText: {t}\\nError: {e}\\n')\n",
    "                \n",
    "    count += 1    \n",
    "    if count % 10 == 0:\n",
    "        print(f'Processing text {count}. Time elapsed: {round((time.time()-start)/60, 4)} min')\n",
    "        with open('data/res.pkl', 'wb') as f:\n",
    "            pickle.dump(res, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                        \n",
    "        \n",
    "elapsed = (time.time() - start)/60\n",
    "print(f'\\nTime elapsed {round(elapsed, 4)} min')\n",
    "#file = 'data/res.pkl'\n",
    "#with open(file, 'rb') as f:\n",
    "#    res2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74eea6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text                         0\n",
      "emotion                      0\n",
      "target                       0\n",
      "gtp_translated               0\n",
      "translated_hi                0\n",
      "translated_ur                0\n",
      "text_clean                   0\n",
      "gpt_pred                     0\n",
      "gpt_pred_num                 0\n",
      "gpt_translated2              0\n",
      "gpt_translated2_corrected    0\n",
      "gpt_embedding                0\n",
      "closest_texts                0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "neutral                                                                                                                                                                                                                                                                                             375\n",
       "trust                                                                                                                                                                                                                                                                                               211\n",
       "joy                                                                                                                                                                                                                                                                                                 130\n",
       "anticipation                                                                                                                                                                                                                                                                                        114\n",
       "optimism                                                                                                                                                                                                                                                                                             98\n",
       "sadness                                                                                                                                                                                                                                                                                              58\n",
       "disgust                                                                                                                                                                                                                                                                                              40\n",
       "fear                                                                                                                                                                                                                                                                                                 39\n",
       "anger                                                                                                                                                                                                                                                                                                37\n",
       "pessimism                                                                                                                                                                                                                                                                                            22\n",
       "surprise                                                                                                                                                                                                                                                                                             16\n",
       "love                                                                                                                                                                                                                                                                                                 13\n",
       "Yes, the category is confusion.                                                                                                                                                                                                                                                                       5\n",
       "Yes, the category is correct.                                                                                                                                                                                                                                                                         4\n",
       "Yes, the category is curiosity.                                                                                                                                                                                                                                                                       3\n",
       "I am not sure about the category. Can you please provide more context or information?                                                                                                                                                                                                                 2\n",
       "I apologize for the mistake. The correct category for the previous text is \"warning\".                                                                                                                                                                                                                 2\n",
       "I am not sure about the category of this text as it is incomplete and doesn't convey any clear meaning.                                                                                                                                                                                               1\n",
       "Yes, the category is advice.                                                                                                                                                                                                                                                                          1\n",
       "I am an AI language model and I do not have any context about the conversation. Based on the text alone, the category seems to be \"curiosity\".                                                                                                                                                        1\n",
       "Yes, the category is regret.                                                                                                                                                                                                                                                                          1\n",
       "I am an AI language model and I do not have any context about the conversation. Based on the given text, I provided the most appropriate category. However, if the category is incorrect, please let me know the correct category and I will update my response.                                      1\n",
       "Yes, the category is uncertainty.                                                                                                                                                                                                                                                                     1\n",
       "Yes, the category is excitement.                                                                                                                                                                                                                                                                      1\n",
       "I apologize for the mistake. Based on the text \"Oye hoye seasonal flu or anything serious ?\", the category should be concern.                                                                                                                                                                         1\n",
       "Yes, the category is concern.                                                                                                                                                                                                                                                                         1\n",
       "Yes, the category is still encouragement.                                                                                                                                                                                                                                                             1\n",
       "No, I am not sure about that. Can you please provide me with more context so that I can categorize it accurately?                                                                                                                                                                                     1\n",
       "I apologize for the mistake. Based on the text, the category should be \"appreciation\".                                                                                                                                                                                                                1\n",
       "Yes, the category is disappointment.                                                                                                                                                                                                                                                                  1\n",
       "I apologize for the mistake. Based on the given text, I cannot determine the category.                                                                                                                                                                                                                1\n",
       "No, I am not sure about that. Please provide me with the category.                                                                                                                                                                                                                                    1\n",
       "I am an AI language model and I cannot be sure about the context of the conversation. Based on the given text, the category seems to be \"disappointment\".                                                                                                                                             1\n",
       "I am an AI language model and I do not have any memory of previous conversations. Therefore, I cannot be sure about the context of the conversation. Please provide more information or context so that I can understand and respond appropriately.                                                   1\n",
       "I apologize for the mistake. As an AI language model, I do not have the context of the conversation and sometimes I may not be able to understand the intent behind the text. Can you please provide me with more information or context so that I can provide you with an appropriate response?      1\n",
       "I apologize for the mistake. The category for the previous text is \"curiosity\".                                                                                                                                                                                                                       1\n",
       "I apologize for the mistake. Based on the given text, the category is \"curiosity\".                                                                                                                                                                                                                    1\n",
       "No, changing the category to \"uncertainty\".                                                                                                                                                                                                                                                           1\n",
       "I am sure that the category is gratitude.                                                                                                                                                                                                                                                             1\n",
       "Name: gpt_pred, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev['gpt_pred'] = df_dev['text'].map( res )\n",
    "print(df_dev.isna().sum())\n",
    "df_dev['gpt_pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "78b619e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    848\n",
       "0    343\n",
       "Name: gpt_pred_binary, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev['gpt_pred_target'] = df_dev['gpt_pred'].apply( lambda x: label2key.get(x) )\n",
    "print(df_dev['gpt_pred_target'].isna().sum())\n",
    "df_dev['gpt_pred_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d6c99482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5948    0.5258    0.5581       388\n",
      "           1     0.7830    0.8269    0.8044       803\n",
      "\n",
      "    accuracy                         0.7288      1191\n",
      "   macro avg     0.6889    0.6763    0.6813      1191\n",
      "weighted avg     0.7217    0.7288    0.7241      1191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_dev      = df_dev['target'].values\n",
    "y_dev_pred = df_dev['gpt_pred_target'].values\n",
    "print( classification_report( y_dev, y_dev_pred, digits=4 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8def9da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d7dc948",
   "metadata": {},
   "source": [
    "## Approach 2: concatenate random few shot examples using the ChatGPT chat mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9a1e88",
   "metadata": {},
   "source": [
    "Split df into n random chunks to be used as few-shot examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f6cc3c7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "[3276, 3350, 3424, 3554, 3229, 3153, 3260, 3487, 3364, 3365, 3709, 3762, 3400, 3387, 3440, 3391, 3424, 3327, 3546, 3423, 3485, 3484, 3543, 3349, 3414, 3372, 3678, 3399, 3280, 3190, 3375, 3327, 3381, 3527, 3335, 3470, 3383, 3494, 3549, 3502, 3499, 3454, 3436, 3261, 3324, 3311, 3371, 3271, 3568, 3475, 3273, 3229, 3403, 3705, 3208, 3326, 3203, 3250, 3275, 3261, 3324, 2279]\n"
     ]
    }
   ],
   "source": [
    "# divide df into n chunks - this allows for 3k to 3.8k tokens per example\n",
    "n          = 100\n",
    "key2label = { 0: 'neutral', 1: 'emotional', }\n",
    "examples  = []\n",
    "chunks = [ df_train.sample(frac=1, random_state=random_state).iloc[i:i+n] for i in range(0, df_train.shape[0], n) ]\n",
    "for ch in chunks:\n",
    "    example = []\n",
    "    for text, target in ch[['text', 'target']].values:\n",
    "        example += [\n",
    "            { \"role\": \"user\", \"content\": f'Text: {text}', },\n",
    "            { \"role\": \"assistant\", \"content\": f'Category: {key2label[target]}', }\n",
    "        ]\n",
    "    examples.append(example)\n",
    "        \n",
    "lengths = [ num_tokens_from_messages(example) for example in examples ]\n",
    "print(len(lengths))\n",
    "print(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5f382578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Text: kiu yar a jana mza aye ga!?'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: Mujhe msg oe msg kr rhi he'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: ma ab tk k exprnce k hwly sy bl rha hn. life to pta h bht h'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user', 'content': \"Text: Mene jannat k pattay prh liya atlast :')\"},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Or wo achi khaasi intelligent t tbi itni okhi paheli boojh li t :P'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Tm logo  ka off ho gaixa hn aur tm ne rida ki pic daekane the . ...,'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Pehla name mera e c jinna nu pta a,par mainu ki pta a, ae mainu nai pts'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user', 'content': 'Text: Mjy sirf y mila h A jao g'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Pata chl gya ha. Zaheer ha. Medicine ka keh rha ha.'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user', 'content': 'Text: Hy , chali gai ho hostal se ya abi nai'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: Tm e calculate kr k bta do'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: QqHahahahaha shabash practice karo .... Aglay 3 saal yehi karna hai :P '},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: yr band h wo log publicty krny k lyai jarhy hain sary lake city wapda town etc'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: hahhahahahha :-D to dua e ulti krr lia krro :-P '},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: Evening hours mei soo gaya tha :p '},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: subha me ne ami k sath bank jana h free ho kr clg chalo ga tery sath ..'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Ramzan me ai this call us ki LST time mar GI phir WO shayad,'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: Phr kehti Allah hfz mne kaha Allah hfz'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: pti job to dekhi jay ge lekin study b jari rkh '},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: yar pakistan st.\\nka kuch kr k tou nai ana tha ?? quiz tou ni aj ?'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Hawn naa n mera group partner ak larka hy he is damn genius par uska half face khrab hy right side scary birth marks n wo cosmo plastic surgery krwata hy tw he cant speak properly \\npar uska artifical inteligence ka project yar im amazed to c neuro computer pay banaya usny human brain feelings k change hony sy clours on paper change n abstract art banta'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Is waqt bechare idps sub se zyada tap rhe hn ge halat dekh k'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: R u coming to my office?'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user', 'content': 'Text: jaldi aa na phr khana b khana ha'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: Nhi you have to come to us'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user', 'content': 'Text: Mje laga ap bizi ho jo reply nai kiyaa'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: Yar plz ksi tarha cancel karwa .'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: Ok . i am ready for that'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: Oye, madam aa gai class mein?'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: To n ana kb tk h'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Sir comment likh b phir mitta dia k mazeed depress kia kerna khud ko b orr tujhe b.'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: Ok. Wasy monday off hota hy papa ka !'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user', 'content': 'Text: Nai pgl..koi masla nai..le ao usko..'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: Swift aap Sargodha sae hi lae gi'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Usna aik status dia hai iss liye poch rha tha ...\\nKhair kia krta rha Sara din?'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user', 'content': 'Text: OK mae internet sae dekh or btata hoon'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Wo waly msg send krny hain ... Jo khud type kiye tum ny .. Okay. '},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Mushaf part 1,part 2 yun kr k dhoonda Kar nq'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: end pa hassan k baad roll no and section mention krna ha'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user', 'content': 'Text: Gari ghr hai le lain key usmain se'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Um.. Yar i remember kbi tha wahan pay.. Let me google branches'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: Ohh asha g yeh bi ha '},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Tusday tk krde\\nMain kiwain wadawan jado agla bnda ae kh dawe k mra ae kam aik bnda 35 ch kr rya a pr tu mra pakka expert aen islai de rya wan ab 45 pe mana hai wo b last main tje 2500 dedunga tu bs krwa ache bnde se'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Faizi bhaaaaaaaaaiiii  oa wo kashif ka bhateja tera bara fan, dp p comments hain j :>'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Haaan yeh b haii abb mamla to bht nazuk haiii'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Usy kahun ga cs dept p oficial kam ha hum dunu ko is lye aj hum ni asakty..'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: rizwan aya h???\\nusy keh dain zra puch ay ik mint\\nOth jay to msg karin.  Istri lani !!\\nHstl nikal jna h ab yhan sy tm logo ny???\\nOayyy umer ka rzlt???'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: oee aur kitna late?? :P ... Chal agar mai jaa raha hoon GA kal to tujhay Bata doon GA...'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Hahaha ghar se nikal de ga tera aba . 3 ki krni ha mene birthday wese b :D '},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: Kahen b yr dor chlty hn'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Ramadan k baad se meri waist 34 ho gae he\\nPhle 32 ti'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: Han kiya hoa koi masla ha kiya'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Shukar wali bat he \\t Nankana sb. Colege ka bhai hspitl ha . Tamardari k ly rokna. '},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user', 'content': 'Text: No you have to tell them'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Then u hav to purchase a cd for anti virus. Uss mein free b hotay hain kafi. Try that baby'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Hahaha \\nWo jese bht Moti thi na experience tha usay'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: Itni jaldi ja ke kya kare gye. '},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Meray whatsapp pe apka yehi number aa ra hai... doosra nahin'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user', 'content': 'Text: Skyp py ao phr btata hu'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Us k bd din me bhr h0tel me khana kha lyn gye f0trus phr lyn gy'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user', 'content': 'Text: To dare kis bat ke :D'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: Han parha ha muje buht pasand ha :),'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: I have reached the destination,  I repeat I have reached the destination,  where are you?'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Ok ma b dost k gar hn, abi. . . . Jhor town me. . . . Wo bike pe muje site pe chor dy ga tb bhai ko bula ln ga'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: I phne ke sheshkay lea ja raha ha :-P '},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Office. Aur zaheer log keh rhy hn chalain biliard khelny'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user', 'content': 'Text: Yr nechay hi parha howa ha'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: tn to serious e ly gya ha chwl.....mazak kr raha tha yar....ahhaha ro naaa'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: Insha Allah aaj majlis ho gi'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: InshALLAH baba kal uni bhejti. Wo kia bt kar k ayn?'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Han vo thk he lkn aj ke date mn vo aw jane chahiye.. '},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: Oh okay chalo IA thek hojayega :)'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Main apni presentation send kr ryan,tusi v send kro'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: Pta nai. Us ka ab reply be nai a rha.'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: Wese kis k sath jane ka irada ha :-P'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Yar programming ka lecture sahi Tara pata nai chalta'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user', 'content': 'Text: ghnty tk aa jana ghr mama bula rhi hn'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Matlab rubber ka hard pipe, zahir hai koi pipe chahiye cylinderical stiff jisay roller bnaen friction wala'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: OK abhi mae perh raha hoon Raat ko Bta doon ga'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: nae yrrr halat se tang aa gai hn'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: Ok. Me Wahin Admin K Samane Hun.'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Yr jb paper deny jao ge to result pata kr k ana mera'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: Han bs fridy ko clash ata ha.'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Lkn mujy to khana b bnana awta he vo b achee wala..'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: Sae he bai tu jan gia guru ko'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: hahaha...itna h pyar rha to gya ku ni...isld..saly ghar bth k bten h sb krty han'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: Yar is lye ke kal me ghar ja rha hu'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user', 'content': 'Text: N ambreen ko F de dia ha sir atif ne:@@'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Mam mehwish ik mail hmari management ko b kar deti to shayad un ko kuch hosh a jata'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: Daikh lo yr \\nBta daina na.'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: Usy kahye ga bt kry mjhse jb ay to'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': \"Text: Han but helpless hu na thats why you couldn't hear my voice :D \"},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Han yar 1 bachi teray bhai ko bri pyari lagi..'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Hahahaahah bohat mushkil say  ....mai nay ir maahi nay milkay maza aagaya '},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Salam\\nG achhaa ho gaya.\\nits the best I could deliver'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: khiar woooo tooo khd ko fkhti ni'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user',\n",
       "  'content': 'Text: Teri marzi ha. Me to tmhy 100 bar keh chuka hn'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: han mri sis k achay e agye mrkx'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'},\n",
       " {'role': 'user', 'content': 'Text: Yr wo thek rhe ga hmare kam k mtabik'},\n",
       " {'role': 'assistant', 'content': 'Category: emotional'},\n",
       " {'role': 'user', 'content': 'Text: O nahi yar mujy tu nahi mila wo'},\n",
       " {'role': 'assistant', 'content': 'Category: neutral'}]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how one example looks\n",
    "examples[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2d95ec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text_few_shot2(text_, messages_, model):\n",
    "    '''Classify text_ using prompt_ and ChatGPT API'''\n",
    "    messages_ = deepcopy(messages_)\n",
    "    messages_ += [\n",
    "        { \"role\": \"user\", \"content\": f'Text: {text_}', },\n",
    "    ]\n",
    "    if not verify_num_tokens(model, messages_): return None\n",
    "    label_    = get_response(model, messages_)\n",
    "    old_label = label_\n",
    "    label_    = verify_label(label_)        # get just the category if response is too long\n",
    "        \n",
    "    # if label not found in response text - second, extended chat\n",
    "    if label_ is None:\n",
    "        messages_ += [\n",
    "            { \"role\": \"assistant\", \"content\": old_label, },\n",
    "            { \"role\": \"user\", \"content\": followup1, }\n",
    "            ]        \n",
    "        label_    = get_response(model, messages_)\n",
    "        old_label = label_\n",
    "        label_    = verify_label(label_)        # get just the category if response is too long\n",
    "            \n",
    "    return label_ if label_ is not None else old_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "23cc902e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text 10; example 9. Time elapsed: 0.2034 min\n",
      "Processing text 20; example 19. Time elapsed: 0.3919 min\n",
      "Processing text 30; example 29. Time elapsed: 0.5834 min\n",
      "Processing text 40; example 39. Time elapsed: 0.7687 min\n",
      "Processing text 50; example 49. Time elapsed: 0.9588 min\n",
      "Processing text 60; example 59. Time elapsed: 1.1971 min\n",
      "Processing text 70; example 7. Time elapsed: 1.409 min\n",
      "Processing text 80; example 17. Time elapsed: 1.6186 min\n",
      "Processing text 90; example 27. Time elapsed: 1.8049 min\n",
      "Processing text 100; example 37. Time elapsed: 2.0017 min\n",
      "Processing text 110; example 47. Time elapsed: 2.1894 min\n",
      "Processing text 120; example 57. Time elapsed: 2.3815 min\n",
      "Processing text 130; example 5. Time elapsed: 2.5695 min\n",
      "Processing text 140; example 15. Time elapsed: 2.7638 min\n",
      "Processing text 150; example 25. Time elapsed: 2.9498 min\n",
      "Processing text 160; example 35. Time elapsed: 3.1631 min\n",
      "Processing text 170; example 45. Time elapsed: 3.4141 min\n",
      "Processing text 180; example 55. Time elapsed: 3.7554 min\n",
      "Processing text 190; example 3. Time elapsed: 3.9429 min\n",
      "Processing text 200; example 13. Time elapsed: 4.1376 min\n",
      "Processing text 210; example 23. Time elapsed: 4.3597 min\n",
      "Processing text 220; example 33. Time elapsed: 4.5491 min\n",
      "Processing text 230; example 43. Time elapsed: 4.7338 min\n",
      "Processing text 240; example 53. Time elapsed: 4.9189 min\n",
      "Processing text 250; example 1. Time elapsed: 5.1207 min\n",
      "Processing text 260; example 11. Time elapsed: 5.3034 min\n",
      "Processing text 270; example 21. Time elapsed: 5.5149 min\n",
      "Processing text 280; example 31. Time elapsed: 5.7044 min\n",
      "Processing text 290; example 41. Time elapsed: 5.887 min\n",
      "Processing text 300; example 51. Time elapsed: 6.0798 min\n",
      "Processing text 310; example 61. Time elapsed: 6.2642 min\n",
      "Processing text 320; example 9. Time elapsed: 6.4502 min\n",
      "Processing text 330; example 19. Time elapsed: 6.6506 min\n",
      "Processing text 340; example 29. Time elapsed: 6.8541 min\n",
      "Processing text 350; example 39. Time elapsed: 7.0395 min\n",
      "Processing text 360; example 49. Time elapsed: 7.3332 min\n",
      "Processing text 370; example 59. Time elapsed: 7.513 min\n",
      "Processing text 380; example 7. Time elapsed: 7.7275 min\n",
      "Processing text 390; example 17. Time elapsed: 7.9173 min\n",
      "Processing text 400; example 27. Time elapsed: 8.1013 min\n",
      "Processing text 410; example 37. Time elapsed: 8.3013 min\n",
      "Processing text 420; example 47. Time elapsed: 8.4898 min\n",
      "Processing text 430; example 57. Time elapsed: 8.6901 min\n",
      "Processing text 440; example 5. Time elapsed: 8.8708 min\n",
      "Processing text 450; example 15. Time elapsed: 9.0604 min\n",
      "Processing text 460; example 25. Time elapsed: 9.2481 min\n",
      "Processing text 470; example 35. Time elapsed: 9.4376 min\n",
      "Processing text 480; example 45. Time elapsed: 9.6999 min\n",
      "Processing text 490; example 55. Time elapsed: 9.9496 min\n",
      "Processing text 500; example 3. Time elapsed: 10.1271 min\n",
      "Processing text 510; example 13. Time elapsed: 10.3138 min\n",
      "Processing text 520; example 23. Time elapsed: 10.4932 min\n",
      "Processing text 530; example 33. Time elapsed: 10.6941 min\n",
      "Processing text 540; example 43. Time elapsed: 10.9104 min\n",
      "Processing text 550; example 53. Time elapsed: 11.0887 min\n",
      "Processing text 560; example 1. Time elapsed: 11.3887 min\n",
      "Processing text 570; example 11. Time elapsed: 11.5906 min\n",
      "Processing text 580; example 21. Time elapsed: 11.7825 min\n",
      "Processing text 590; example 31. Time elapsed: 11.9647 min\n",
      "Processing text 600; example 41. Time elapsed: 12.1648 min\n",
      "Processing text 610; example 51. Time elapsed: 12.3709 min\n",
      "Processing text 620; example 61. Time elapsed: 12.5809 min\n",
      "Processing text 630; example 9. Time elapsed: 12.7758 min\n",
      "Processing text 640; example 19. Time elapsed: 12.9753 min\n",
      "Processing text 650; example 29. Time elapsed: 13.1708 min\n",
      "Processing text 660; example 39. Time elapsed: 13.3694 min\n",
      "Processing text 670; example 49. Time elapsed: 13.5778 min\n",
      "Processing text 680; example 59. Time elapsed: 13.8767 min\n",
      "Processing text 690; example 7. Time elapsed: 14.0882 min\n",
      "Processing text 700; example 17. Time elapsed: 14.4176 min\n",
      "Processing text 710; example 27. Time elapsed: 14.6036 min\n",
      "Processing text 720; example 37. Time elapsed: 14.7964 min\n",
      "Processing text 730; example 47. Time elapsed: 14.9822 min\n",
      "Processing text 740; example 57. Time elapsed: 15.2726 min\n",
      "Processing text 750; example 5. Time elapsed: 15.4664 min\n",
      "Processing text 760; example 15. Time elapsed: 15.6515 min\n",
      "Processing text 770; example 25. Time elapsed: 15.8409 min\n",
      "Processing text 780; example 35. Time elapsed: 16.0297 min\n",
      "Processing text 790; example 45. Time elapsed: 16.2164 min\n",
      "Processing text 800; example 55. Time elapsed: 16.4052 min\n",
      "Processing text 810; example 3. Time elapsed: 16.6231 min\n",
      "Processing text 820; example 13. Time elapsed: 16.82 min\n",
      "Processing text 830; example 23. Time elapsed: 17.0112 min\n",
      "Processing text 840; example 33. Time elapsed: 17.2032 min\n",
      "Processing text 850; example 43. Time elapsed: 17.417 min\n",
      "Processing text 860; example 53. Time elapsed: 17.6284 min\n",
      "Processing text 870; example 1. Time elapsed: 17.8139 min\n",
      "Processing text 880; example 11. Time elapsed: 18.0128 min\n",
      "Processing text 890; example 21. Time elapsed: 18.2005 min\n",
      "Processing text 900; example 31. Time elapsed: 18.3885 min\n",
      "Processing text 910; example 41. Time elapsed: 18.584 min\n",
      "Processing text 920; example 51. Time elapsed: 18.8016 min\n",
      "Processing text 930; example 61. Time elapsed: 18.9982 min\n",
      "Processing text 940; example 9. Time elapsed: 19.1818 min\n",
      "Processing text 950; example 19. Time elapsed: 19.3821 min\n",
      "Processing text 960; example 29. Time elapsed: 19.571 min\n",
      "Processing text 970; example 39. Time elapsed: 19.7593 min\n",
      "Processing text 980; example 49. Time elapsed: 19.9419 min\n",
      "Processing text 990; example 59. Time elapsed: 20.1515 min\n",
      "Processing text 1000; example 7. Time elapsed: 20.3524 min\n",
      "Processing text 1010; example 17. Time elapsed: 20.5718 min\n",
      "Processing text 1020; example 27. Time elapsed: 20.7815 min\n",
      "Processing text 1030; example 37. Time elapsed: 20.9784 min\n",
      "Processing text 1040; example 47. Time elapsed: 21.1688 min\n",
      "Processing text 1050; example 57. Time elapsed: 21.3682 min\n",
      "Processing text 1060; example 5. Time elapsed: 21.5567 min\n",
      "Processing text 1070; example 15. Time elapsed: 21.7432 min\n",
      "Processing text 1080; example 25. Time elapsed: 21.939 min\n",
      "Processing text 1090; example 35. Time elapsed: 22.1368 min\n",
      "Processing text 1100; example 45. Time elapsed: 22.4372 min\n",
      "Processing text 1110; example 55. Time elapsed: 22.6254 min\n",
      "Processing text 1120; example 3. Time elapsed: 22.8275 min\n",
      "Processing text 1130; example 13. Time elapsed: 23.0142 min\n",
      "Processing text 1140; example 23. Time elapsed: 23.2053 min\n",
      "Processing text 1150; example 33. Time elapsed: 23.4134 min\n",
      "\n",
      "Time elapsed 23.4134 min\n"
     ]
    }
   ],
   "source": [
    "start  = time.time()\n",
    "res    = dict()\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "for t in df_dev['text'].tolist():\n",
    "    if t in res:\n",
    "        continue\n",
    "    if count2 >= len(examples):\n",
    "        count2 = 0\n",
    "    messages = examples[ count2 ]\n",
    "    count2 += 1\n",
    "    try:\n",
    "        res[ t ] = classify_text_few_shot2(t, messages, model)\n",
    "    except openai.error.RateLimitError:\n",
    "        print(f'\\nText: {t}.\\nRate limit error\\n')\n",
    "    except Exception as e:\n",
    "        print(f'\\nText: {t}\\nError: {e}\\n')\n",
    "                \n",
    "    count1 += 1    \n",
    "    if count1 % 10 == 0:\n",
    "        print(f'Processing text {count1}; example {count2-1}. Time elapsed: {round((time.time()-start)/60, 4)} min')\n",
    "        with open('data/res.pkl', 'wb') as f:\n",
    "            pickle.dump(res, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                        \n",
    "        \n",
    "elapsed = (time.time() - start)/60\n",
    "print(f'\\nTime elapsed {round(elapsed, 4)} min')\n",
    "#file = 'data/res.pkl'\n",
    "#with open(file, 'rb') as f:\n",
    "#    res2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "72e17653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotional                                       808\n",
       "neutral                                         382\n",
       "Yes, I'm sure. The category is motivational.      1\n",
       "Name: gpt_pred, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev['gpt_pred'] = df_dev['text'].map( res )\n",
    "df_dev['gpt_pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c68a4eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    809\n",
       "0    382\n",
       "Name: gpt_pred_binary, dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev['gpt_pred_binary'] = df_dev['gpt_pred'].apply( lambda x: 0 if x=='neutral' else 1 )\n",
    "df_dev['gpt_pred_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a046484f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4895    0.4820    0.4857       388\n",
      "           1     0.7515    0.7572    0.7543       803\n",
      "\n",
      "    accuracy                         0.6675      1191\n",
      "   macro avg     0.6205    0.6196    0.6200      1191\n",
      "weighted avg     0.6662    0.6675    0.6668      1191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_dev      = df_dev['target'].values\n",
    "y_dev_pred = df_dev['gpt_pred_binary'].values\n",
    "print( classification_report( y_dev, y_dev_pred, digits=4 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c8b232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abd1c938",
   "metadata": {},
   "source": [
    "## Binary approach 1: concatenate random few-shot examples into one long string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8c50ae",
   "metadata": {},
   "source": [
    "Example prompt:\n",
    "```\n",
    "Message: Support has been terrible for 2 weeks...\n",
    "Sentiment: Negative\n",
    "###\n",
    "Message: I love your API, it is simple and so fast!\n",
    "Sentiment: Positive\n",
    "###\n",
    "Message: GPT-J has been released 2 months ago.\n",
    "Sentiment: Neutral\n",
    "###\n",
    "Message: The reactivity of your team has been amazing, thanks!\n",
    "Sentiment:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10db0b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 116049\n",
      "Avg tokens per msg: 18.817739581644236\n",
      "Avg messages per window size: 217.66695102930657\n"
     ]
    }
   ],
   "source": [
    "# total tokens in training set\n",
    "messages = [{ 'role': 'user', 'content': ' '.join(df_train['text_clean'].tolist()) }]\n",
    "total_tokens        = num_tokens_from_messages(messages)\n",
    "avg_tokens_per_msg  = total_tokens / df_train.shape[0]\n",
    "msg_per_window_size = 4096 /  avg_tokens_per_msg\n",
    "print('Total tokens:', total_tokens)\n",
    "print('Avg tokens per msg:', avg_tokens_per_msg)\n",
    "print('Avg messages per window size:', msg_per_window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be0223d",
   "metadata": {},
   "source": [
    "Split df into n random chunks to be used as few-shot examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "27291532",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3472, 3690, 3662, 3346, 3394, 3608, 3630, 3805, 4022, 3726, 3590, 3530, 3729, 3633, 3722, 3633, 3795, 3630, 3613, 3808, 3540, 3380, 3597, 3528, 3697, 3586, 3634, 3586, 3825, 3750, 3782, 3620, 3472, 3519, 3542, 3583, 3794, 3416, 3455, 3977, 3427, 3476, 3302, 3400, 3531, 2424]\n"
     ]
    }
   ],
   "source": [
    "# divide df into n chunks - this allows for 3k to 3.8k tokens per example\n",
    "n         = 135\n",
    "key2label = { 0: 'neutral', 1: 'emotional', }\n",
    "examples  = []\n",
    "chunks  = [ df_train.sample(frac=1, random_state=random_state).iloc[i:i+n] for i in range(0, df_train.shape[0], n) ]\n",
    "for ch in chunks:\n",
    "    example = ''\n",
    "    for text, target in ch[['text', 'target']].values:\n",
    "        example += f'Message: {text}.\\nCategory: {key2label[target]}.\\n####\\n'\n",
    "    examples.append(example)\n",
    "        \n",
    "lengths = [ num_tokens_from_messages([{'role':'user', 'content': example} ]) for example in examples ]\n",
    "print(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bc82bbb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ae25f515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: Yr jtni jldi ml jaye utna acha he....\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Haha mei kahan se sweet hun :p.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Han abi kuch theek hy shop pr ly kr gya tha.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: I think .. he made his own slides....\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Plz give me bike keys. I m in office.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Teri do Aakhiyaan Wich Dubb Mrya,.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Haha ni wo boy ni smjy g q k wo khud boy ho g.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Mera Sirf DataStructure Ka Pta Chala Hai. & Your?.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Salam Faiza Baaji\n",
      "How are you  ... \n",
      "Plz take a  good care of urself. \n",
      "Aur jo treat meri taraf due hai uska kiya karna hai?  :-).\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Sir transport dept walay recomendation letter mang rahay han....\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Yar  Maine fee a hi tak Jamaica nahi krai 2000 fine ho gear hai to fine maaf kra sakta hai.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Ok. U already hav the slides and book.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Mera ab 7 strt hOna ha.. :).\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Han half say bhi thori kam hai as compared to uol.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Tues ko classes wasey bhi 4 hai i think srf pori class k sath celebrate karengy nd enjoybhi.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: kha sy betha or kha pr utra?.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Oky bro... Best of luck jani for ms.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: abhi nhi bnani 4:30 se bnana!!.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Wait ma uni wapis a raha ho puhanch kr btata ho.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Winedt is better than lyx. Now m using winedtDrivinDriving.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Time anay pay sab ka pta chl hi jata ha maza to tb ha k time say phlay pta ho sb.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Dont worry I m CR . I will adjust u in any group..\n",
      "Category: emotional.\n",
      "####\n",
      "Message: tu facebook e na open kr.....\n",
      "Category: neutral.\n",
      "####\n",
      "Message: G g MASHALLAH  pass ho gya.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: ay meri sheeeooo loat k aja bin tere her matm her khushi adhuri h.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Surly i'll cm nd w8ng u.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Sir babar ka email id send kro plz.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Q k ap k bohat se ase kaam han jo me ne nahi ki'ye..\n",
      "Category: emotional.\n",
      "####\n",
      "Message: irsa.. roz USB lena bhul jatu hun, kl le ana mene mbyl me copy krni hn cheezen..\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Em scared yar yh ni hona tha,.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: mera mood ku kharab ho ga.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Han yar kal jana hy zaroor.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: bhai coal ma c+\n",
      "multi ma b+ lag gya ha..\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Main to khta hun k bna lo mood ab .\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Or agar kii teri waja sai kholai ga website par acount to os kai aik click ka.5 rs or roz kai 150 .\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Yr sftwre eng ka scop ziada he ya cs ka.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Oka will wait for ur call.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Yaar admin officekay samnay abbasi. Jaa rahay hain .\n",
      "Category: neutral.\n",
      "####\n",
      "Message: First time in life mujy pucit ki credibility par doubt ho rha ha k koi hosh hi nai in ko.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Han kya sen ha hstel ka.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Pehly apni information jo us din unhun ny puchi age city language etc wo send kr du us k bad jb chahu msg send dr du.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: HAYE BHT STUDYYYYYY ki AJJJJ tooo.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Jani phr me b to hr time he ap se contact krta hn na.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Yaar apnay Abba ko masjid chownk roki.... Kajorien unkay hath ghar bhejwadien.... .\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Hahaha thaik a tn kera shadi karwni wa charater lose wa.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Uncle ko bta dena m n Jana hai.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Pas koi atm nae hai apke?.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: to kia side ln tmhry jesi ni.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Shit yar ma ny timetable dykha e nai tha ... Mari bht important class hy 2 bjy ma ja raha hun university ...  .\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Xheikh Fawad Ahmad Hasan Sahi ????? ????.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Han ab to tu esa hi boly ga na.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Hmmmm yahan b yehi haal pata ha factory baich di.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Hellooooo koi hai begam main agya hellooooooooo charta yi khazi? .\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Meanwhile get ready your system and Skype.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Wasy yeh apki food ha :P.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Ok I will send it to you in a few minutes.The slides include portions from the given slides aong with lot of additional data collected by me.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: O sory yar main ny jo baqi msg tmhain send kiye hain wo usko krny thy jo university aye thy sory.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Hudi apni trf se likh k send kr alehda alehda ese alhaty jatay.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Suree :p bad may phas jaon hain :p.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Programning ki assginmt strt.ki ha koa ?.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: nbeta assingmnt mili hai labmi lambi.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: To kya hua 2 mint ka kam hai keh do.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: hahhahahaha apni guarantee py e khany hain bhai :-D :-P .\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Mtlb ka hamare tarf hamare hostel..\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Mosam change ki wajah se bukhaar.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Hmmm wo to kbi poori nai hui ji khana b khaya.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Please find below a bit of a new one.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Oye uni me zong k signal ate hain.. ?.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Mery to mind ma he nai tha :-(.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Tmharay bai hain to karcha lia karo na unka apna gar ha agr to pirr.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: yar core 2 due tak bhai bna bnaya mily ga aram sy 8 mein acha best.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: I was a lil busy... bht saray guest though kab say I was waitin for 18th :( sorry for being late.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: uuuuuu hme bhuuuuUUUl gayeee.... ye sb khaya kese geya tmse.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Us per jb 10k tk ho jaye ga to wo withdraw krwa kr or apny pas se 10k dal kr tmhy account bna du ga.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Hm tw 13 bachy hai interior k????????.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Shayad settings mein koi backup ka chakkar chalana paray ga\n",
      "Mainay kabhi iOS sahi tarha use hi nahin kiya\n",
      "Kaisay bataon?.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Ghar me or koi nai ha is lye muje lazmi jana hu ga..\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Idhar bhi yehi haal hai...uni mai sale mehnga bht dete hain.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Is lia 3:30 tak chuty ho gahy gi.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: chl phr share kr lty hn. what say.?.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Yar tm mere group me hti maza ata :-P.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: rayaan kah raa hy dado k pass rakhwa dain keyss abi hmm nikaly wy.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: U r responsible fr it got it.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Gas kitni dair k liye khuli the.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: G abi kia aur ab lhr jane lga hn.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Ok mje b kal kr dena phr.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: hain mjhe adat nh zada dair rukny ki.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Mjay smjh ne ara kis k group main jau , to bs iswaja abi kisi group main ne hu.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: you mean ye shain A rab hmari school friend hai????.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: U ko pta b sub, phr b keh rhi.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Thaik a hun fr ki karna a.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: You are invited to a small treat by me on the occasion of Getting Elected CR on Monday Venue will be informed later plz confirm your presence by a text or call. \"\"Dont bring anyone else\"\".\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Us ko phr ap kud samja le warna ?.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Yr plzz mere liye 2nd row me jaga zaroor rakh lena nd boyz ki taraf wali seat na rakhna plzz! Mje thori si der ho jae gi cx of traffic!,.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Han, kaha to h wo ek namuna th, jiske baareek beeni.. Hd t wese :).\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Hahaha lhr ma tym hta ha ap k liye u knw naa.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Tu fikr na kr wo dost hi ha mera .wo dy dy ga jitny ma boloon ga ..\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Fahad ne baray nmbr maray hein.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Haha acha mery sony per keh rhi ho.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Gray clor m ha car mamu ne btya ha.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Nhe yr brish bht ho rhe m nhe a rha.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Yaar me ajau na lab me? .\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Ni nxt wek se jyn ge :-) new no.ab on kia ha...is lye cntct ni kr sake :-).\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Thanx jani.Abi tk tu ni lagi\n",
      "Kuch peenay ko dil kr rha hau\n",
      "Kia peena ha?\n",
      "Jani jb bhok lgy to btana\n",
      "Q ab kia hwa?.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Han umeed ha :-P oka dne hua bta dunga :-P.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Have they returned???what is their feedback???.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Yar bc tum log late krwao ge .\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Or eshal kase ha?adeil bhai ksy han.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: w.a fit bhai ap sunaen. Alhamdullah...achi guzri .Ap ki eid kaisay guzri.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Wohi ker rha hun is waqt.12 tk btaunga.light nai a rhi thi subha charging khatam thi laptop ki.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Same here.... me bhii Facebook p post aur comment bohat kam krta hon..\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Matlb k sindh k under ata ha wo area..\n",
      "Category: neutral.\n",
      "####\n",
      "Message: complier download k liye link de,.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Hahahaha... ap ne Monday ko uni ana hai ?.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: han han flat to mil jyn gy...wahan...area acha ha...lkn bc comsats dkhen tw aaaa k....pind ma ha...fctry area ma.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: nhi ji itni easy bi nhi ha!!.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Han mujy to itnaaa gussa hi awta he thora thora to awta hi nai he.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: pupho trf axa hn dawat par.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: meri d ma enrol ho gyi ha ccn.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: mam iqra sy pouch ly na.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: saly location change ki ja rahy ho parking ki trf a registr ly kr.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Yaar maliya or Hajra ko kiya tha basit nay baki ghar ghar..... .\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Ok bro wo maire pass hai thnks.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Thanks for infom but i cant , becouz kal mn ne choti marni hy muje nankana sahib jana hy or mondy ko wapisi ho gi. .\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Hahahha keh deta hoon sbko fikr na kr.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Msg pary bgr del nahi ho sakta..\n",
      "Category: neutral.\n",
      "####\n",
      "Message: kch nh. khtm kr is bt ko. ye chlta rhy ga sari zindgi.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Vo keh rai hay sir ko call kr k kaho k humne krwai hn assignmnts.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Fazan main 10 minute bad guliana say niklon ga. .\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Main ne to kuch kaha he ni yr.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: Main chutti hi nahi karti :-D.\n",
      "Category: emotional.\n",
      "####\n",
      "Message: O yar tm nay kn sa jok aj sunaia tha. .\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Sir ne pprs nai check kiye..me abi udr e thi.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Tu b usy msg kar dy k mery 7 a jaye.\n",
      "Category: neutral.\n",
      "####\n",
      "Message: Oye apna roll no btaa PUCIT ka,,,.\n",
      "Category: emotional.\n",
      "####\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f184a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text_few_shot(prompt_):\n",
    "    '''Classify text_ using prompt_ and ChatGPT API'''\n",
    "        \n",
    "    # compose messages and check num_tokens\n",
    "    messages = [\n",
    "            #{ \"role\": \"system\", \"content\": \"You are a very accurate text classifier.\", },\n",
    "            { \"role\": \"user\", \"content\": prompt_, },\n",
    "            ]\n",
    "    if not verify_num_tokens(model, messages): return None\n",
    "    label_    = get_response(model, messages)\n",
    "    old_label = label_\n",
    "    label_    = verify_label(label_)        # get just the category if response is too long\n",
    "        \n",
    "    # if label not found in response text - second, extended chat\n",
    "    if label_ is None:\n",
    "        messages += [\n",
    "            { \"role\": \"assistant\", \"content\": old_label, },\n",
    "            { \"role\": \"user\", \"content\": followup1, }\n",
    "            ]        \n",
    "        label_    = get_response(model, messages)        \n",
    "        old_label = label_\n",
    "        label_    = verify_label(label_)        # get just the category if response is too long\n",
    "            \n",
    "    return label_ if label_ is not None else old_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "77ebd510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time elapsed 0.1439 min\n"
     ]
    }
   ],
   "source": [
    "start  = time.time()\n",
    "#res    = dict()\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "for t in df_dev['text'].tolist():\n",
    "    if t in res:\n",
    "        continue\n",
    "    if count2 >= len(examples):\n",
    "        count2 = 0\n",
    "    prompt = examples[ count2 ] + f'\\nMessage: {t}.\\nCategory:'\n",
    "    count2 += 1\n",
    "    try:\n",
    "        res[ t ] = classify_text_few_shot(prompt)\n",
    "    except openai.error.RateLimitError:\n",
    "        print(f'\\nText: {t}.\\nRate limit error\\n')\n",
    "    except Exception as e:\n",
    "        print(f'\\nText: {t}\\nError: {e}\\n')\n",
    "                \n",
    "    count1 += 1    \n",
    "    if count1 % 10 == 0:\n",
    "        print(f'Processing text {count1}; example {count2-1}')\n",
    "        with open('data/res.pkl', 'wb') as f:\n",
    "            pickle.dump(res, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                        \n",
    "        \n",
    "elapsed = (time.time() - start)/60\n",
    "print(f'\\nTime elapsed {round(elapsed, 4)} min')\n",
    "#file = 'data/res.pkl'\n",
    "#with open(file, 'rb') as f:\n",
    "#    res2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c30275ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotional                                        715\n",
       "neutral                                          470\n",
       "Yes, I'm sure. The category is motivational.       1\n",
       "Yes, I'm sure. The category is offensive.          1\n",
       "Yes, I'm sure. The category is inappropriate.      1\n",
       "Yes, the category is offensive.                    1\n",
       "Yes, I'm sure. The category is positive.           1\n",
       "Yes, I'm sure. The category is humorous.           1\n",
       "Name: gpt_pred, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev['gpt_pred'] = df_dev['text'].map( res )\n",
    "df_dev['gpt_pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "be7210fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    721\n",
       "0    470\n",
       "Name: gpt_pred_binary, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev['gpt_pred_binary'] = df_dev['gpt_pred'].apply( lambda x: 0 if x=='neutral' else 1 )\n",
    "df_dev['gpt_pred_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f20f04d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4723    0.5722    0.5175       388\n",
      "           1     0.7698    0.6912    0.7283       803\n",
      "\n",
      "    accuracy                         0.6524      1191\n",
      "   macro avg     0.6211    0.6317    0.6229      1191\n",
      "weighted avg     0.6729    0.6524    0.6597      1191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_dev      = df_dev['target'].values\n",
    "y_dev_pred = df_dev['gpt_pred_binary'].values\n",
    "print( classification_report( y_dev, y_dev_pred, digits=4 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b6bb97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550cce9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4ef8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e3c932f",
   "metadata": {},
   "source": [
    "## APPENDIX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d693df45",
   "metadata": {},
   "source": [
    "### Prompts and results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e983feb9",
   "metadata": {},
   "source": [
    "__Experiment 1__  \n",
    "Split the training set into random non-stratified 62 chunks, each 100 examples long (this allows not to exceed the ChatGPT window size of 4096 tokens). Convert the 100 examples in each chunk into the messages object containing alternating user(text) and assistant (category) chat utterances. Iterate over chunks and dev set single examples and for each dev set example use the next message; the dev sety example is added as the next user utterance for few-shot learning - ChatGPT to respond with an assitant utterance containing the category.\n",
    "```\n",
    "\n",
    "```\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a583d8af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac7ecba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318d7203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
